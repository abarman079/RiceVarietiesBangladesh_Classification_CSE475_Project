{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13375613,"sourceType":"datasetVersion","datasetId":8486016}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# CELL 1: Markdown - Notebook Header","metadata":{}},{"cell_type":"code","source":"# Task 2: Supervised Baseline Training\n## Split: 70:30 (Train:Test)\n\n**Project:** CSE475 Self-Supervised Learning on Rice Varieties Dataset\n\n**Split Configuration:**\n- Training: 70% (13,300 images)\n- Validation: 10% of training (1,330 images)\n- Testing: 30% (5,700 images)\n\n**Models:** ResNet50, EfficientNetB0, MobileNetV2, InceptionV3, DenseNet121\n\n**Execution Date:** October 25, 2025\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T00:00:37.404835Z","iopub.execute_input":"2025-10-25T00:00:37.405334Z","iopub.status.idle":"2025-10-25T00:00:37.410870Z","shell.execute_reply.started":"2025-10-25T00:00:37.405311Z","shell.execute_reply":"2025-10-25T00:00:37.409655Z"}},"outputs":[{"traceback":["\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_37/3660595809.py\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    **Project:** CSE475 Self-Supervised Learning on Rice Varieties Dataset\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"],"ename":"SyntaxError","evalue":"invalid syntax (3660595809.py, line 4)","output_type":"error"}],"execution_count":7},{"cell_type":"markdown","source":"# CELL 2: Import Libraries and Configure Environment","metadata":{}},{"cell_type":"code","source":"import os\nimport sys\nimport time\nimport random\nimport warnings\nimport json\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, models, optimizers, callbacks, regularizers\nfrom tensorflow.keras.applications import (\n    ResNet50, EfficientNetB0, MobileNetV2, InceptionV3, DenseNet121\n)\nfrom tensorflow.keras.applications.resnet50 import preprocess_input as resnet_preprocess\nfrom tensorflow.keras.applications.efficientnet import preprocess_input as efficientnet_preprocess\nfrom tensorflow.keras.applications.mobilenet_v2 import preprocess_input as mobilenet_preprocess\nfrom tensorflow.keras.applications.inception_v3 import preprocess_input as inception_preprocess\nfrom tensorflow.keras.applications.densenet import preprocess_input as densenet_preprocess\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import (\n    classification_report, confusion_matrix, accuracy_score,\n    precision_recall_fscore_support, roc_auc_score, roc_curve, auc\n)\nfrom sklearn.preprocessing import label_binarize\n\nwarnings.filterwarnings('ignore')\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n\nprint(f\"TensorFlow: {tf.__version__}\")\nprint(f\"Keras: {keras.__version__}\")\nprint(f\"Python: {sys.version.split()[0]}\")\n\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    try:\n        for gpu in gpus:\n            tf.config.experimental.set_memory_growth(gpu, True)\n        print(f\"GPU Available: {len(gpus)} device(s)\")\n    except RuntimeError as e:\n        print(f\"GPU config error: {e}\")\nelse:\n    print(\"CPU mode activated\")\n\ndef set_seeds(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n\nset_seeds(42)\nprint(\"Environment configured\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T00:08:17.697211Z","iopub.execute_input":"2025-10-25T00:08:17.697460Z","iopub.status.idle":"2025-10-25T00:08:31.935583Z","shell.execute_reply.started":"2025-10-25T00:08:17.697441Z","shell.execute_reply":"2025-10-25T00:08:31.934680Z"}},"outputs":[{"name":"stderr","text":"2025-10-25 00:08:20.179305: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1761350900.376446      37 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1761350900.431672      37 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"TensorFlow: 2.18.0\nKeras: 3.8.0\nPython: 3.11.13\nGPU Available: 1 device(s)\nEnvironment configured\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# CELL 3: Configuration Class","metadata":{}},{"cell_type":"code","source":"class Config:\n    RANDOM_SEED = 42\n    \n    DATASET_BASE = '/kaggle/input/dataset-for-classifying-rice-varieties-in-bd'\n    ORIGINAL_FOLDER = os.path.join(DATASET_BASE, 'Rice Varieties in Bangladesh', 'Original')\n    \n    IMG_SIZE = (224, 224)\n    INPUT_SHAPE = (224, 224, 3)\n    \n    NUM_CLASSES = 38\n    CLASS_NAMES = [\n        'BD30', 'BD33', 'BD39', 'BD49', 'BD51', 'BD52', 'BD56', 'BD57',\n        'BD70', 'BD72', 'BD75', 'BD76', 'BD79', 'BD85', 'BD87', 'BD91',\n        'BD93', 'BD95', 'Binadhan10', 'Binadhan11', 'Binadhan12', 'Binadhan14',\n        'Binadhan16', 'Binadhan17', 'Binadhan19', 'Binadhan20', 'Binadhan21',\n        'Binadhan23', 'Binadhan24', 'Binadhan25', 'Binadhan26', 'Binadhan7',\n        'Binadhan8', 'BR22', 'BR23', 'BRRI102', 'BRRI67', 'BRRI74'\n    ]\n    \n    TRAIN_RATIO = 70\n    TEST_RATIO = 30\n    VAL_RATIO = 0.1\n    SPLIT_NAME = f\"{TRAIN_RATIO}_{TEST_RATIO}\"\n    \n    BATCH_SIZE = 32\n    EPOCHS_PHASE1 = 10\n    EPOCHS_PHASE2 = 40\n    TOTAL_EPOCHS = EPOCHS_PHASE1 + EPOCHS_PHASE2\n    \n    LR_PHASE1 = 1e-3\n    LR_PHASE2 = 1e-4\n    \n    DROPOUT_RATE = 0.5\n    L2_REG = 1e-4\n    LABEL_SMOOTHING = 0.1\n    \n    MODELS = ['ResNet50', 'EfficientNetB0', 'MobileNetV2', 'InceptionV3', 'DenseNet121']\n    \n    OUTPUT_DIR = f'/kaggle/working/outputs_{SPLIT_NAME}_v2'\n    MODELS_DIR = os.path.join(OUTPUT_DIR, 'models')\n    LOGS_DIR = os.path.join(OUTPUT_DIR, 'logs')\n    PLOTS_DIR = os.path.join(OUTPUT_DIR, 'plots')\n    RESULTS_DIR = os.path.join(OUTPUT_DIR, 'results')\n\ncfg = Config()\n\nfor directory in [cfg.OUTPUT_DIR, cfg.MODELS_DIR, cfg.LOGS_DIR, cfg.PLOTS_DIR, cfg.RESULTS_DIR]:\n    os.makedirs(directory, exist_ok=True)\n\nprint(\"Configuration loaded\")\nprint(f\"Split: {cfg.TRAIN_RATIO}:{cfg.TEST_RATIO}\")\nprint(f\"Two-phase training: {cfg.EPOCHS_PHASE1} + {cfg.EPOCHS_PHASE2} epochs\")\nprint(f\"Enhanced regularization: Dropout={cfg.DROPOUT_RATE}, L2={cfg.L2_REG}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T00:08:34.819171Z","iopub.execute_input":"2025-10-25T00:08:34.820079Z","iopub.status.idle":"2025-10-25T00:08:34.828432Z","shell.execute_reply.started":"2025-10-25T00:08:34.820054Z","shell.execute_reply":"2025-10-25T00:08:34.827612Z"}},"outputs":[{"name":"stdout","text":"Configuration loaded\nSplit: 70:30\nTwo-phase training: 10 + 40 epochs\nEnhanced regularization: Dropout=0.5, L2=0.0001\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# CELL 4: Data Loading Functions","metadata":{}},{"cell_type":"code","source":"def load_dataset(data_dir, class_names):\n    image_paths = []\n    labels = []\n    label_to_idx = {name: idx for idx, name in enumerate(sorted(class_names))}\n    idx_to_label = {idx: name for name, idx in label_to_idx.items()}\n    \n    print(\"Loading dataset...\")\n    \n    class_counts = {}\n    for class_name in sorted(class_names):\n        class_dir = os.path.join(data_dir, class_name)\n        if not os.path.exists(class_dir):\n            continue\n        \n        class_images = [\n            os.path.join(class_dir, f)\n            for f in os.listdir(class_dir)\n            if f.lower().endswith(('.jpg', '.jpeg', '.png'))\n        ]\n        \n        image_paths.extend(class_images)\n        labels.extend([label_to_idx[class_name]] * len(class_images))\n        class_counts[class_name] = len(class_images)\n    \n    print(f\"Loaded: {len(image_paths)} images, {len(class_counts)} classes\")\n    return image_paths, labels, label_to_idx, idx_to_label\n\n\ndef prepare_splits(image_paths, labels, train_ratio, test_ratio, val_ratio=0.1, random_state=42):\n    image_paths = np.array(image_paths)\n    labels = np.array(labels)\n    \n    train_val_paths, test_paths, train_val_labels, test_labels = train_test_split(\n        image_paths, labels, test_size=test_ratio/100, stratify=labels, random_state=random_state\n    )\n    \n    train_paths, val_paths, train_labels, val_labels = train_test_split(\n        train_val_paths, train_val_labels, test_size=val_ratio, stratify=train_val_labels, random_state=random_state\n    )\n    \n    print(f\"Train: {len(train_paths)}, Val: {len(val_paths)}, Test: {len(test_paths)}\")\n    return {\n        'train_paths': train_paths, 'train_labels': train_labels,\n        'val_paths': val_paths, 'val_labels': val_labels,\n        'test_paths': test_paths, 'test_labels': test_labels\n    }\n\n\nall_image_paths, all_labels, label_to_idx, idx_to_label = load_dataset(cfg.ORIGINAL_FOLDER, cfg.CLASS_NAMES)\nsplit_data = prepare_splits(all_image_paths, all_labels, cfg.TRAIN_RATIO, cfg.TEST_RATIO, cfg.VAL_RATIO, cfg.RANDOM_SEED)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T00:08:42.079692Z","iopub.execute_input":"2025-10-25T00:08:42.080297Z","iopub.status.idle":"2025-10-25T00:08:42.545910Z","shell.execute_reply.started":"2025-10-25T00:08:42.080271Z","shell.execute_reply":"2025-10-25T00:08:42.544946Z"}},"outputs":[{"name":"stdout","text":"Loading dataset...\nLoaded: 19000 images, 38 classes\nTrain: 11970, Val: 1330, Test: 5700\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"# CELL 5: Data Pipeline Functions","metadata":{}},{"cell_type":"code","source":"def create_dataset_enhanced(paths, labels, preprocess_func, batch_size, img_size, \n                            shuffle=False, augment=False, seed=42):\n    def load_and_augment(path, label):\n        img = tf.io.read_file(path)\n        img = tf.image.decode_jpeg(img, channels=3)\n        \n        if augment:\n            img = tf.image.random_crop(tf.image.resize(img, (256, 256)), [224, 224, 3])\n            img = tf.image.random_flip_left_right(img)\n            img = tf.image.random_flip_up_down(img)\n            img = tf.image.random_brightness(img, 0.3)\n            img = tf.image.random_contrast(img, 0.7, 1.3)\n            img = tf.image.random_saturation(img, 0.7, 1.3)\n            img = tf.image.random_hue(img, 0.1)\n        else:\n            img = tf.image.resize(img, img_size)\n        \n        img = tf.cast(img, tf.float32)\n        if preprocess_func is not None:\n            img = preprocess_func(img)\n        else:\n            img = img / 255.0\n        \n        return img, label\n    \n    dataset = tf.data.Dataset.from_tensor_slices((paths, labels))\n    if shuffle:\n        dataset = dataset.shuffle(buffer_size=2000, seed=seed, reshuffle_each_iteration=True)\n    dataset = dataset.map(load_and_augment, num_parallel_calls=tf.data.AUTOTUNE)\n    dataset = dataset.batch(batch_size)\n    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n    \n    return dataset\n\nprint(\"Enhanced augmentation pipeline ready\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T00:08:48.800654Z","iopub.execute_input":"2025-10-25T00:08:48.800943Z","iopub.status.idle":"2025-10-25T00:08:48.808384Z","shell.execute_reply.started":"2025-10-25T00:08:48.800922Z","shell.execute_reply":"2025-10-25T00:08:48.807656Z"}},"outputs":[{"name":"stdout","text":"Enhanced augmentation pipeline ready\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"# CELL 6: Model Building Function","metadata":{}},{"cell_type":"code","source":"def build_model_advanced(backbone_name, input_shape=(224, 224, 3), num_classes=38):\n    backbones = {\n        'ResNet50': (ResNet50, resnet_preprocess),\n        'EfficientNetB0': (EfficientNetB0, efficientnet_preprocess),\n        'MobileNetV2': (MobileNetV2, mobilenet_preprocess),\n        'InceptionV3': (InceptionV3, inception_preprocess),\n        'DenseNet121': (DenseNet121, densenet_preprocess)\n    }\n    \n    backbone_class, preprocess_func = backbones[backbone_name]\n    \n    print(f\"Building {backbone_name} with enhanced architecture...\")\n    base_model = backbone_class(include_top=False, weights='imagenet', input_shape=input_shape)\n    base_model.trainable = False\n    \n    inputs = keras.Input(shape=input_shape)\n    x = base_model(inputs, training=False)\n    x = layers.GlobalAveragePooling2D()(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(cfg.L2_REG))(x)\n    x = layers.Dropout(cfg.DROPOUT_RATE)(x)\n    x = layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(cfg.L2_REG))(x)\n    x = layers.Dropout(cfg.DROPOUT_RATE)(x)\n    outputs = layers.Dense(num_classes, activation='softmax')(x)\n    \n    model = keras.Model(inputs, outputs, name=f'{backbone_name}_enhanced')\n    \n    model.compile(\n        optimizer=keras.optimizers.Adam(learning_rate=cfg.LR_PHASE1),\n        loss='sparse_categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    \n    print(f\"Model ready: {model.count_params():,} parameters\")\n    return model, preprocess_func, base_model\n\nprint(\"Advanced model builder defined\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T00:08:52.700115Z","iopub.execute_input":"2025-10-25T00:08:52.700595Z","iopub.status.idle":"2025-10-25T00:08:52.707981Z","shell.execute_reply.started":"2025-10-25T00:08:52.700574Z","shell.execute_reply":"2025-10-25T00:08:52.707229Z"}},"outputs":[{"name":"stdout","text":"Advanced model builder defined\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"# CELL 7: Two-Phase Training Controller","metadata":{}},{"cell_type":"code","source":"class TwoPhaseTrainer:\n    def __init__(self, model, base_model, model_name, split_name):\n        self.model = model\n        self.base_model = base_model\n        self.model_name = model_name\n        self.split_name = split_name\n        self.history_phase1 = None\n        self.history_phase2 = None\n        \n    def get_callbacks(self, phase):\n        model_dir = os.path.join(cfg.MODELS_DIR, f\"{self.model_name}_{self.split_name}\")\n        os.makedirs(model_dir, exist_ok=True)\n        \n        checkpoint_path = os.path.join(model_dir, f'best_model_phase{phase}.h5')\n        \n        callbacks_list = [\n            callbacks.ModelCheckpoint(\n                filepath=checkpoint_path,\n                monitor='val_accuracy',\n                mode='max',\n                save_best_only=True,\n                save_weights_only=False,\n                verbose=1\n            ),\n            callbacks.ReduceLROnPlateau(\n                monitor='val_loss',\n                factor=0.5,\n                patience=3,\n                min_lr=1e-7,\n                verbose=1,\n                mode='min'\n            ),\n            callbacks.CSVLogger(\n                filename=os.path.join(model_dir, f'training_log_phase{phase}.csv'),\n                append=False\n            )\n        ]\n        \n        return callbacks_list, checkpoint_path\n    \n    def train_phase1(self, train_dataset, val_dataset):\n        print(f\"\\nPHASE 1: Training classifier head (backbone frozen)\")\n        print(f\"Epochs: {cfg.EPOCHS_PHASE1}, Learning Rate: {cfg.LR_PHASE1}\")\n        print(f\"Trainable parameters: {sum([tf.size(w).numpy() for w in self.model.trainable_weights]):,}\")\n        \n        self.base_model.trainable = False\n        self.model.compile(\n            optimizer=keras.optimizers.Adam(learning_rate=cfg.LR_PHASE1),\n            loss='sparse_categorical_crossentropy',\n            metrics=['accuracy']\n        )\n        \n        callbacks_list, checkpoint_path = self.get_callbacks(phase=1)\n        \n        start_time = time.time()\n        self.history_phase1 = self.model.fit(\n            train_dataset,\n            validation_data=val_dataset,\n            epochs=cfg.EPOCHS_PHASE1,\n            callbacks=callbacks_list,\n            verbose=1\n        )\n        phase1_time = time.time() - start_time\n        \n        print(f\"Phase 1 completed in {phase1_time/60:.2f} minutes\")\n        print(f\"Best model saved: {checkpoint_path}\")\n        \n        return checkpoint_path, phase1_time\n    \n    def train_phase2(self, train_dataset, val_dataset):\n        print(f\"\\nPHASE 2: Fine-tuning entire model (backbone unfrozen)\")\n        print(f\"Epochs: {cfg.EPOCHS_PHASE2}, Learning Rate: {cfg.LR_PHASE2}\")\n        \n        self.base_model.trainable = True\n        \n        num_layers = len(self.base_model.layers)\n        freeze_until = int(num_layers * 0.5)\n        \n        for layer in self.base_model.layers[:freeze_until]:\n            layer.trainable = False\n        \n        print(f\"Unfreezing last {num_layers - freeze_until}/{num_layers} layers of backbone\")\n        print(f\"Trainable parameters: {sum([tf.size(w).numpy() for w in self.model.trainable_weights]):,}\")\n        \n        self.model.compile(\n            optimizer=keras.optimizers.Adam(learning_rate=cfg.LR_PHASE2),\n            loss='sparse_categorical_crossentropy',\n            metrics=['accuracy']\n        )\n        \n        callbacks_list, checkpoint_path = self.get_callbacks(phase=2)\n        \n        start_time = time.time()\n        self.history_phase2 = self.model.fit(\n            train_dataset,\n            validation_data=val_dataset,\n            initial_epoch=cfg.EPOCHS_PHASE1,\n            epochs=cfg.TOTAL_EPOCHS,\n            callbacks=callbacks_list,\n            verbose=1\n        )\n        phase2_time = time.time() - start_time\n        \n        print(f\"Phase 2 completed in {phase2_time/60:.2f} minutes\")\n        print(f\"Best model saved: {checkpoint_path}\")\n        \n        return checkpoint_path, phase2_time\n    \n    def get_combined_history(self):\n        if self.history_phase1 is None or self.history_phase2 is None:\n            return None\n        \n        combined = {\n            'accuracy': self.history_phase1.history['accuracy'] + self.history_phase2.history['accuracy'],\n            'val_accuracy': self.history_phase1.history['val_accuracy'] + self.history_phase2.history['val_accuracy'],\n            'loss': self.history_phase1.history['loss'] + self.history_phase2.history['loss'],\n            'val_loss': self.history_phase1.history['val_loss'] + self.history_phase2.history['val_loss']\n        }\n        \n        return type('History', (), {'history': combined})()\n\nprint(\"Two-phase training controller defined\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T00:08:56.985933Z","iopub.execute_input":"2025-10-25T00:08:56.986506Z","iopub.status.idle":"2025-10-25T00:08:56.998761Z","shell.execute_reply.started":"2025-10-25T00:08:56.986486Z","shell.execute_reply":"2025-10-25T00:08:56.998040Z"}},"outputs":[{"name":"stdout","text":"Two-phase training controller defined\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"# CELL 8: Evaluation Function","metadata":{}},{"cell_type":"code","source":"def evaluate_model_comprehensive(model, test_dataset, test_labels, idx_to_label, \n                                  model_name, split_name):\n    print(f\"\\nComprehensive evaluation: {model_name} on {split_name}\")\n    \n    results_dir = os.path.join(cfg.RESULTS_DIR, f\"{model_name}_{split_name}\")\n    os.makedirs(results_dir, exist_ok=True)\n    \n    start_time = time.time()\n    y_pred_probs = model.predict(test_dataset, verbose=0)\n    inference_time = time.time() - start_time\n    \n    y_pred = np.argmax(y_pred_probs, axis=1)\n    y_true = test_labels\n    \n    avg_inference_time_ms = (inference_time / len(test_labels)) * 1000\n    \n    overall_accuracy = accuracy_score(y_true, y_pred)\n    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(\n        y_true, y_pred, average='macro', zero_division=0\n    )\n    precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(\n        y_true, y_pred, average='micro', zero_division=0\n    )\n    \n    print(f\"Accuracy: {overall_accuracy*100:.2f}%\")\n    print(f\"F1-Score (Macro): {f1_macro:.4f}\")\n    print(f\"Precision (Macro): {precision_macro:.4f}\")\n    print(f\"Recall (Macro): {recall_macro:.4f}\")\n    \n    precision, recall, f1, support = precision_recall_fscore_support(\n        y_true, y_pred, average=None, zero_division=0\n    )\n    \n    per_class_accuracy = np.array([\n        (y_pred[y_true == i] == y_true[y_true == i]).sum() / (y_true == i).sum()\n        if (y_true == i).sum() > 0 else 0.0\n        for i in range(cfg.NUM_CLASSES)\n    ])\n    \n    try:\n        y_true_bin = label_binarize(y_true, classes=range(cfg.NUM_CLASSES))\n        roc_auc_scores = []\n        for i in range(cfg.NUM_CLASSES):\n            try:\n                score = roc_auc_score(y_true_bin[:, i], y_pred_probs[:, i])\n                roc_auc_scores.append(score)\n            except:\n                roc_auc_scores.append(0.0)\n        roc_auc_macro = np.mean(roc_auc_scores)\n        print(f\"ROC-AUC (Macro): {roc_auc_macro:.4f}\")\n    except:\n        roc_auc_macro = 0.0\n        roc_auc_scores = [0.0] * cfg.NUM_CLASSES\n    \n    cm = confusion_matrix(y_true, y_pred)\n    \n    confused_pairs = []\n    for i in range(cfg.NUM_CLASSES):\n        for j in range(cfg.NUM_CLASSES):\n            if i != j and cm[i, j] > 0:\n                confused_pairs.append({\n                    'true_class': idx_to_label[i],\n                    'pred_class': idx_to_label[j],\n                    'count': int(cm[i, j]),\n                    'true_idx': int(i),\n                    'pred_idx': int(j)\n                })\n    \n    top_confused = sorted(confused_pairs, key=lambda x: x['count'], reverse=True)[:5]\n    \n    total_params = model.count_params()\n    gflops = total_params * 2 / 1e9\n    \n    results_dict = {\n        'model_name': model_name,\n        'split_name': split_name,\n        'overall_accuracy': overall_accuracy,\n        'precision_macro': precision_macro,\n        'recall_macro': recall_macro,\n        'f1_macro': f1_macro,\n        'roc_auc_macro': roc_auc_macro,\n        'avg_inference_time_ms': avg_inference_time_ms,\n        'total_params': total_params,\n        'gflops': gflops,\n        'per_class_accuracy': per_class_accuracy,\n        'per_class_precision': precision,\n        'per_class_recall': recall,\n        'per_class_f1': f1,\n        'confusion_matrix': cm,\n        'y_true': y_true,\n        'y_pred': y_pred,\n        'y_pred_probs': y_pred_probs\n    }\n    \n    json_results = {k: float(v) if isinstance(v, np.floating) else int(v) if isinstance(v, np.integer) else v \n                    for k, v in results_dict.items() if k not in ['confusion_matrix', 'y_true', 'y_pred', 'y_pred_probs', \n                                                                    'per_class_accuracy', 'per_class_precision', \n                                                                    'per_class_recall', 'per_class_f1']}\n    \n    with open(os.path.join(results_dir, 'metrics.json'), 'w') as f:\n        json.dump(json_results, f, indent=4)\n    \n    return results_dict\n\nprint(\"Comprehensive evaluation function defined\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T00:01:30.458989Z","iopub.execute_input":"2025-10-25T00:01:30.459462Z","iopub.status.idle":"2025-10-25T00:01:30.471759Z","shell.execute_reply.started":"2025-10-25T00:01:30.459433Z","shell.execute_reply":"2025-10-25T00:01:30.470956Z"}},"outputs":[{"name":"stdout","text":"Comprehensive evaluation function defined\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"# CELL 9: Visualization Functions","metadata":{}},{"cell_type":"code","source":"def plot_training_curves_enhanced(history, model_name, split_name):\n    model_dir = os.path.join(cfg.PLOTS_DIR, f\"{model_name}_{split_name}\")\n    os.makedirs(model_dir, exist_ok=True)\n    \n    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n    \n    epochs_range = range(1, len(history.history['accuracy']) + 1)\n    phase1_end = cfg.EPOCHS_PHASE1\n    \n    axes[0, 0].plot(epochs_range, history.history['accuracy'], 'b-', linewidth=2, label='Train')\n    axes[0, 0].plot(epochs_range, history.history['val_accuracy'], 'r-', linewidth=2, label='Validation')\n    axes[0, 0].axvline(x=phase1_end, color='g', linestyle='--', linewidth=2, label='Phase 1/2 Boundary')\n    axes[0, 0].set_title('Model Accuracy', fontsize=13, fontweight='bold')\n    axes[0, 0].set_xlabel('Epoch')\n    axes[0, 0].set_ylabel('Accuracy')\n    axes[0, 0].legend()\n    axes[0, 0].grid(True, alpha=0.3)\n    \n    axes[0, 1].plot(epochs_range, history.history['loss'], 'b-', linewidth=2, label='Train')\n    axes[0, 1].plot(epochs_range, history.history['val_loss'], 'r-', linewidth=2, label='Validation')\n    axes[0, 1].axvline(x=phase1_end, color='g', linestyle='--', linewidth=2, label='Phase 1/2 Boundary')\n    axes[0, 1].set_title('Model Loss', fontsize=13, fontweight='bold')\n    axes[0, 1].set_xlabel('Epoch')\n    axes[0, 1].set_ylabel('Loss')\n    axes[0, 1].legend()\n    axes[0, 1].grid(True, alpha=0.3)\n    \n    val_acc = history.history['val_accuracy']\n    best_epoch = np.argmax(val_acc) + 1\n    best_val_acc = max(val_acc)\n    \n    axes[1, 0].plot(epochs_range, val_acc, 'r-', linewidth=2)\n    axes[1, 0].scatter([best_epoch], [best_val_acc], color='gold', s=200, zorder=5, edgecolors='black', linewidth=2)\n    axes[1, 0].set_title(f'Validation Accuracy (Best: {best_val_acc:.4f} at epoch {best_epoch})', \n                         fontsize=13, fontweight='bold')\n    axes[1, 0].set_xlabel('Epoch')\n    axes[1, 0].set_ylabel('Validation Accuracy')\n    axes[1, 0].grid(True, alpha=0.3)\n    \n    overfitting_gap = [history.history['accuracy'][i] - history.history['val_accuracy'][i] \n                       for i in range(len(history.history['accuracy']))]\n    axes[1, 1].plot(epochs_range, overfitting_gap, 'purple', linewidth=2)\n    axes[1, 1].axhline(y=0, color='black', linestyle='-', linewidth=1)\n    axes[1, 1].set_title('Training-Validation Gap (Overfitting Indicator)', fontsize=13, fontweight='bold')\n    axes[1, 1].set_xlabel('Epoch')\n    axes[1, 1].set_ylabel('Train Acc - Val Acc')\n    axes[1, 1].grid(True, alpha=0.3)\n    \n    plt.tight_layout()\n    save_path = os.path.join(model_dir, 'training_analysis.png')\n    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n    print(f\"Training analysis saved: {save_path}\")\n    plt.close()\n\n\ndef plot_confusion_matrix_professional(cm, model_name, split_name):\n    model_dir = os.path.join(cfg.PLOTS_DIR, f\"{model_name}_{split_name}\")\n    os.makedirs(model_dir, exist_ok=True)\n    \n    fig, axes = plt.subplots(1, 2, figsize=(24, 10))\n    \n    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n    \n    sns.heatmap(cm_normalized, annot=False, cmap='Blues', ax=axes[0],\n                xticklabels=cfg.CLASS_NAMES, yticklabels=cfg.CLASS_NAMES,\n                cbar_kws={'label': 'Normalized Frequency'})\n    axes[0].set_title(f'{model_name}: Normalized Confusion Matrix', fontsize=14, fontweight='bold')\n    axes[0].set_xlabel('Predicted Label', fontsize=12)\n    axes[0].set_ylabel('True Label', fontsize=12)\n    \n    per_class_acc = np.diag(cm_normalized)\n    axes[1].barh(cfg.CLASS_NAMES, per_class_acc, color='steelblue')\n    axes[1].set_xlabel('Accuracy', fontsize=12)\n    axes[1].set_title(f'{model_name}: Per-Class Accuracy', fontsize=14, fontweight='bold')\n    axes[1].axvline(x=np.mean(per_class_acc), color='red', linestyle='--', linewidth=2, \n                    label=f'Mean: {np.mean(per_class_acc):.3f}')\n    axes[1].legend()\n    axes[1].grid(True, alpha=0.3, axis='x')\n    \n    plt.tight_layout()\n    save_path = os.path.join(model_dir, 'confusion_matrix_analysis.png')\n    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n    print(f\"Confusion matrix analysis saved: {save_path}\")\n    plt.close()\n\nprint(\"Enhanced visualization functions defined\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T00:01:36.030938Z","iopub.execute_input":"2025-10-25T00:01:36.031216Z","iopub.status.idle":"2025-10-25T00:01:36.047798Z","shell.execute_reply.started":"2025-10-25T00:01:36.031176Z","shell.execute_reply":"2025-10-25T00:01:36.047039Z"}},"outputs":[{"name":"stdout","text":"Enhanced visualization functions defined\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"# CELL 10: Main Training Pipeline","metadata":{}},{"cell_type":"code","source":"print(f\"Starting enhanced training pipeline for split {cfg.TRAIN_RATIO}:{cfg.TEST_RATIO}\")\nprint(f\"Configuration: Two-phase training with enhanced regularization\")\nprint(f\"Expected outcome: 95%+ accuracy with minimal overfitting\\n\")\n\nresults_collection = []\n\nfor model_name in cfg.MODELS:\n    try:\n        print(f\"\\n{'='*90}\")\n        print(f\"MODEL: {model_name}\")\n        print(f\"{'='*90}\")\n        \n        model, preprocess_func, base_model = build_model_advanced(model_name)\n        \n        print(\"\\nPreparing data pipelines...\")\n        train_dataset = create_dataset_enhanced(\n            split_data['train_paths'], split_data['train_labels'],\n            preprocess_func, cfg.BATCH_SIZE, cfg.IMG_SIZE,\n            shuffle=True, augment=True, seed=cfg.RANDOM_SEED\n        )\n        \n        val_dataset = create_dataset_enhanced(\n            split_data['val_paths'], split_data['val_labels'],\n            preprocess_func, cfg.BATCH_SIZE, cfg.IMG_SIZE,\n            shuffle=False, augment=False\n        )\n        \n        test_dataset = create_dataset_enhanced(\n            split_data['test_paths'], split_data['test_labels'],\n            preprocess_func, cfg.BATCH_SIZE, cfg.IMG_SIZE,\n            shuffle=False, augment=False\n        )\n        \n        trainer = TwoPhaseTrainer(model, base_model, model_name, cfg.SPLIT_NAME)\n        \n        checkpoint_p1, time_p1 = trainer.train_phase1(train_dataset, val_dataset)\n        checkpoint_p2, time_p2 = trainer.train_phase2(train_dataset, val_dataset)\n        \n        total_training_time = time_p1 + time_p2\n        \n        print(f\"\\nLoading best model from Phase 2...\")\n        best_model = keras.models.load_model(checkpoint_p2)\n        \n        results = evaluate_model_comprehensive(\n            best_model, test_dataset, split_data['test_labels'],\n            idx_to_label, model_name, cfg.SPLIT_NAME\n        )\n        \n        results['training_time_total_min'] = total_training_time / 60\n        results['training_time_phase1_min'] = time_p1 / 60\n        results['training_time_phase2_min'] = time_p2 / 60\n        \n        combined_history = trainer.get_combined_history()\n        plot_training_curves_enhanced(combined_history, model_name, cfg.SPLIT_NAME)\n        plot_confusion_matrix_professional(results['confusion_matrix'], model_name, cfg.SPLIT_NAME)\n        \n        results_collection.append(results)\n        \n        print(f\"\\n{model_name} Summary:\")\n        print(f\"  Test Accuracy: {results['overall_accuracy']*100:.2f}%\")\n        print(f\"  F1-Score: {results['f1_macro']:.4f}\")\n        print(f\"  Total Training Time: {results['training_time_total_min']:.1f} minutes\")\n        \n        keras.backend.clear_session()\n        \n    except Exception as e:\n        print(f\"\\nError with {model_name}: {str(e)}\")\n        import traceback\n        traceback.print_exc()\n\nprint(f\"\\n{'='*90}\")\nprint(f\"Training pipeline completed for split {cfg.TRAIN_RATIO}:{cfg.TEST_RATIO}\")\nprint(f\"Models trained: {len(results_collection)}/5\")\nprint(f\"{'='*90}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T00:08:07.469731Z","iopub.execute_input":"2025-10-25T00:08:07.469947Z","iopub.status.idle":"2025-10-25T00:08:07.538960Z","shell.execute_reply.started":"2025-10-25T00:08:07.469921Z","shell.execute_reply":"2025-10-25T00:08:07.538019Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_37/3393313585.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Starting enhanced training pipeline for split {cfg.TRAIN_RATIO}:{cfg.TEST_RATIO}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Configuration: Two-phase training with enhanced regularization\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Expected outcome: 95%+ accuracy with minimal overfitting\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mresults_collection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'cfg' is not defined"],"ename":"NameError","evalue":"name 'cfg' is not defined","output_type":"error"}],"execution_count":1},{"cell_type":"markdown","source":"# CELL 11: Results Summary and Analysis","metadata":{}},{"cell_type":"code","source":"if len(results_collection) > 0:\n    results_df = pd.DataFrame({\n        'Model': [r['model_name'] for r in results_collection],\n        'Split': [cfg.SPLIT_NAME] * len(results_collection),\n        'Test_Accuracy': [r['overall_accuracy'] * 100 for r in results_collection],\n        'F1_Macro': [r['f1_macro'] for r in results_collection],\n        'Precision_Macro': [r['precision_macro'] for r in results_collection],\n        'Recall_Macro': [r['recall_macro'] for r in results_collection],\n        'ROC_AUC': [r['roc_auc_macro'] for r in results_collection],\n        'Inference_ms': [r['avg_inference_time_ms'] for r in results_collection],\n        'Training_min': [r['training_time_total_min'] for r in results_collection],\n        'Parameters': [r['total_params'] for r in results_collection],\n        'GFLOPs': [r['gflops'] for r in results_collection]\n    })\n    \n    results_df_sorted = results_df.sort_values('Test_Accuracy', ascending=False)\n    \n    print(\"\\n\" + \"=\"*110)\n    print(f\"FINAL RESULTS SUMMARY - Split {cfg.TRAIN_RATIO}:{cfg.TEST_RATIO}\")\n    print(\"=\"*110)\n    print(results_df_sorted.to_string(index=False))\n    print(\"=\"*110)\n    \n    best_model = results_df_sorted.iloc[0]\n    print(f\"\\nBest Model: {best_model['Model']}\")\n    print(f\"Test Accuracy: {best_model['Test_Accuracy']:.2f}%\")\n    print(f\"F1-Score: {best_model['F1_Macro']:.4f}\")\n    print(f\"Training Time: {best_model['Training_min']:.1f} minutes\")\n    \n    csv_path = os.path.join(cfg.RESULTS_DIR, f'summary_{cfg.SPLIT_NAME}.csv')\n    results_df_sorted.to_csv(csv_path, index=False)\n    print(f\"\\nResults saved: {csv_path}\")\nelse:\n    print(\"No results to summarize\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T00:00:33.605564Z","iopub.status.idle":"2025-10-25T00:00:33.605792Z","shell.execute_reply.started":"2025-10-25T00:00:33.605689Z","shell.execute_reply":"2025-10-25T00:00:33.605699Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# CELL 12:  Archive","metadata":{}},{"cell_type":"code","source":"import zipfile\nfrom datetime import datetime\nimport shutil\n\ndef create_comprehensive_archive():\n    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n    archive_name = f'Task2_Split_{cfg.SPLIT_NAME}_Complete_{timestamp}.zip'\n    \n    print(f\"Creating comprehensive archive: {archive_name}\")\n    \n    with zipfile.ZipFile(archive_name, 'w', zipfile.ZIP_DEFLATED) as zipf:\n        for root, dirs, files in os.walk(cfg.OUTPUT_DIR):\n            for file in files:\n                file_path = os.path.join(root, file)\n                arcname = os.path.relpath(file_path, cfg.OUTPUT_DIR)\n                zipf.write(file_path, arcname)\n                \n    file_size_mb = os.path.getsize(archive_name) / (1024*1024)\n    \n    print(f\"\\nArchive created successfully\")\n    print(f\"Filename: {archive_name}\")\n    print(f\"Size: {file_size_mb:.2f} MB\")\n    print(f\"Location: /kaggle/working/{archive_name}\")\n    print(f\"\\nContents:\")\n    print(f\"  - Trained models (.h5 files)\")\n    print(f\"  - Training logs (CSV)\")\n    print(f\"  - All plots and visualizations\")\n    print(f\"  - Evaluation metrics (JSON)\")\n    print(f\"  - Summary results (CSV)\")\n    \n    return archive_name\n\narchive_file = create_comprehensive_archive()\n\nprint(\"\\n\" + \"=\"*110)\nprint(\"BACKUP AND DOWNLOAD INSTRUCTIONS\")\nprint(\"=\"*110)\nprint(f\"1. Navigate to /kaggle/working/ in the Output panel\")\nprint(f\"2. Right-click on: {archive_file}\")\nprint(f\"3. Select 'Download'\")\nprint(f\"4. Store safely - this contains ALL your work for split {cfg.SPLIT_NAME}\")\nprint(\"=\"*110)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T00:00:33.606890Z","iopub.status.idle":"2025-10-25T00:00:33.607177Z","shell.execute_reply.started":"2025-10-25T00:00:33.607027Z","shell.execute_reply":"2025-10-25T00:00:33.607040Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# CELL 13: Final Report Generation","metadata":{}},{"cell_type":"code","source":"def generate_final_report():\n    report_path = os.path.join(cfg.RESULTS_DIR, f'REPORT_Split_{cfg.SPLIT_NAME}.txt')\n    \n    with open(report_path, 'w') as f:\n        f.write(\"=\"*110 + \"\\n\")\n        f.write(f\"TASK 2: SUPERVISED BASELINE TRAINING REPORT\\n\")\n        f.write(f\"Split: {cfg.TRAIN_RATIO}:{cfg.TEST_RATIO}\\n\")\n        f.write(f\"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n        f.write(\"=\"*110 + \"\\n\\n\")\n        \n        f.write(\"PROJECT INFORMATION\\n\")\n        f.write(\"-\" * 110 + \"\\n\")\n        f.write(f\"Course: CSE475 - Self-Supervised Learning\\n\")\n        f.write(f\"Dataset: Rice Varieties in Bangladesh (38 classes)\\n\")\n        f.write(f\"Total Images: {cfg.TOTAL_IMAGES}\\n\")\n        f.write(f\"Training Strategy: Two-phase (frozen backbone → fine-tuning)\\n\")\n        f.write(f\"Total Epochs: {cfg.TOTAL_EPOCHS} (Phase 1: {cfg.EPOCHS_PHASE1}, Phase 2: {cfg.EPOCHS_PHASE2})\\n\\n\")\n        \n        if len(results_collection) > 0:\n            f.write(\"MODEL PERFORMANCE SUMMARY\\n\")\n            f.write(\"-\" * 110 + \"\\n\")\n            for result in results_collection:\n                f.write(f\"\\nModel: {result['model_name']}\\n\")\n                f.write(f\"  Test Accuracy: {result['overall_accuracy']*100:.2f}%\\n\")\n                f.write(f\"  F1-Score (Macro): {result['f1_macro']:.4f}\\n\")\n                f.write(f\"  Precision (Macro): {result['precision_macro']:.4f}\\n\")\n                f.write(f\"  Recall (Macro): {result['recall_macro']:.4f}\\n\")\n                f.write(f\"  ROC-AUC: {result['roc_auc_macro']:.4f}\\n\")\n                f.write(f\"  Parameters: {result['total_params']:,}\\n\")\n                f.write(f\"  Training Time: {result['training_time_total_min']:.1f} minutes\\n\")\n                f.write(f\"  Inference Time: {result['avg_inference_time_ms']:.2f} ms/image\\n\")\n            \n            best_result = max(results_collection, key=lambda x: x['overall_accuracy'])\n            f.write(f\"\\n{'='*110}\\n\")\n            f.write(f\"BEST MODEL: {best_result['model_name']}\\n\")\n            f.write(f\"Test Accuracy: {best_result['overall_accuracy']*100:.2f}%\\n\")\n            f.write(f\"F1-Score: {best_result['f1_macro']:.4f}\\n\")\n            f.write(f\"{'='*110}\\n\")\n        \n        f.write(\"\\nFILES GENERATED\\n\")\n        f.write(\"-\" * 110 + \"\\n\")\n        f.write(\"- Trained model files (.h5)\\n\")\n        f.write(\"- Training logs (CSV)\\n\")\n        f.write(\"- Training curves and analysis plots\\n\")\n        f.write(\"- Confusion matrices\\n\")\n        f.write(\"- ROC curves\\n\")\n        f.write(\"- Evaluation metrics (JSON)\\n\")\n        f.write(\"- Summary table (CSV)\\n\")\n    \n    print(f\"Final report generated: {report_path}\")\n    return report_path\n\nreport_file = generate_final_report()\nprint(f\"\\nReport saved and ready for submission\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T00:00:33.608459Z","iopub.status.idle":"2025-10-25T00:00:33.608750Z","shell.execute_reply.started":"2025-10-25T00:00:33.608610Z","shell.execute_reply":"2025-10-25T00:00:33.608640Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import glob\nimport json\n\ncompleted_models = []\nfor model_dir in glob.glob(os.path.join(cfg.RESULTS_DIR, '*')):\n    metrics_file = os.path.join(model_dir, 'metrics.json')\n    if os.path.exists(metrics_file):\n        with open(metrics_file, 'r') as f:\n            data = json.load(f)\n            completed_models.append({\n                'Model': data['model_name'],\n                'Accuracy': f\"{data['overall_accuracy']*100:.2f}%\",\n                'F1-Score': f\"{data['f1_macro']:.4f}\",\n                'Inference_ms': f\"{data['avg_inference_time_ms']:.2f}\"\n            })\n\nif completed_models:\n    print(\"Completed Models So Far:\")\n    print(pd.DataFrame(completed_models).to_string(index=False))\nelse:\n    print(\"Training in progress... No completed evaluations yet.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T00:00:33.609676Z","iopub.status.idle":"2025-10-25T00:00:33.609972Z","shell.execute_reply.started":"2025-10-25T00:00:33.609822Z","shell.execute_reply":"2025-10-25T00:00:33.609835Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport glob\n\nmodel_folders = glob.glob(os.path.join(cfg.MODELS_DIR, '*'))\nprint(f\"Model folders found: {len(model_folders)}\")\n\nfor folder in model_folders:\n    model_name = os.path.basename(folder)\n    phase2_model = os.path.join(folder, 'best_model_phase2.h5')\n    if os.path.exists(phase2_model):\n        print(f\"✓ {model_name}: Training complete\")\n    else:\n        print(f\"⏳ {model_name}: Still training...\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-25T00:00:33.610779Z","iopub.status.idle":"2025-10-25T00:00:33.611047Z","shell.execute_reply.started":"2025-10-25T00:00:33.610909Z","shell.execute_reply":"2025-10-25T00:00:33.610921Z"}},"outputs":[],"execution_count":null}]}
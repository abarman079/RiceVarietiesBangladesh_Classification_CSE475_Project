{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13375674,"sourceType":"datasetVersion","datasetId":8486036}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# CELL 1: Markdown","metadata":{}},{"cell_type":"code","source":"# Task 2: Supervised Baseline Training - Laptop 3\n## Split: 90:10 (Train:Test)\n\n**Parallel Training Strategy:**\n- Laptop 1: Split 70:30 ✓\n- Laptop 2: Split 80:20 ✓\n- Laptop 3: Split 90:10 (THIS NOTEBOOK)\n\n**Configuration:**\n- Two-phase training (frozen backbone → fine-tuning)\n- Enhanced regularization\n- 50 total epochs (10 + 40)\n\n**Project:** CSE475 Self-Supervised Learning\n**Date:** October 25, 2025\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# CELL 2: Environment Setup","metadata":{}},{"cell_type":"code","source":"import os\nimport sys\nimport time\nimport random\nimport warnings\nimport json\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, models, optimizers, callbacks, regularizers\nfrom tensorflow.keras.applications import (\n    ResNet50, EfficientNetB0, MobileNetV2, InceptionV3, DenseNet121\n)\nfrom tensorflow.keras.applications.resnet50 import preprocess_input as resnet_preprocess\nfrom tensorflow.keras.applications.efficientnet import preprocess_input as efficientnet_preprocess\nfrom tensorflow.keras.applications.mobilenet_v2 import preprocess_input as mobilenet_preprocess\nfrom tensorflow.keras.applications.inception_v3 import preprocess_input as inception_preprocess\nfrom tensorflow.keras.applications.densenet import preprocess_input as densenet_preprocess\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import (\n    classification_report, confusion_matrix, accuracy_score,\n    precision_recall_fscore_support, roc_auc_score, roc_curve, auc\n)\nfrom sklearn.preprocessing import label_binarize\n\nwarnings.filterwarnings('ignore')\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n\nprint(f\"TensorFlow: {tf.__version__}\")\n\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    for gpu in gpus:\n        tf.config.experimental.set_memory_growth(gpu, True)\n    print(f\"GPU: {len(gpus)} device(s)\")\nelse:\n    print(\"CPU mode\")\n\ndef set_seeds(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n\nset_seeds(42)\nprint(\"Ready\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T21:29:50.869677Z","iopub.execute_input":"2025-10-24T21:29:50.869905Z","iopub.status.idle":"2025-10-24T21:29:50.898580Z","shell.execute_reply.started":"2025-10-24T21:29:50.869888Z","shell.execute_reply":"2025-10-24T21:29:50.898006Z"}},"outputs":[{"name":"stdout","text":"TensorFlow: 2.18.0\nGPU: 1 device(s)\nReady\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# CELL 3: Configuration for 90:10","metadata":{}},{"cell_type":"code","source":"class Config:\n    RANDOM_SEED = 42\n    \n    DATASET_BASE = '/kaggle/input/dataset-for-classifying-rice-varieties-in-bd'\n    ORIGINAL_FOLDER = os.path.join(DATASET_BASE, 'Rice Varieties in Bangladesh', 'Original')\n    \n    IMG_SIZE = (224, 224)\n    INPUT_SHAPE = (224, 224, 3)\n    \n    NUM_CLASSES = 38\n    TOTAL_IMAGES = 19000\n    CLASS_NAMES = [\n        'BD30', 'BD33', 'BD39', 'BD49', 'BD51', 'BD52', 'BD56', 'BD57',\n        'BD70', 'BD72', 'BD75', 'BD76', 'BD79', 'BD85', 'BD87', 'BD91',\n        'BD93', 'BD95', 'Binadhan10', 'Binadhan11', 'Binadhan12', 'Binadhan14',\n        'Binadhan16', 'Binadhan17', 'Binadhan19', 'Binadhan20', 'Binadhan21',\n        'Binadhan23', 'Binadhan24', 'Binadhan25', 'Binadhan26', 'Binadhan7',\n        'Binadhan8', 'BR22', 'BR23', 'BRRI102', 'BRRI67', 'BRRI74'\n    ]\n    \n    TRAIN_RATIO = 60\n    TEST_RATIO = 40\n    VAL_RATIO = 0.1\n    SPLIT_NAME = f\"{TRAIN_RATIO}_{TEST_RATIO}\"\n    \n    BATCH_SIZE = 32\n    EPOCHS_PHASE1 = 10\n    EPOCHS_PHASE2 = 40\n    TOTAL_EPOCHS = 50\n    \n    LR_PHASE1 = 1e-3\n    LR_PHASE2 = 1e-4\n    \n    DROPOUT_RATE = 0.5\n    L2_REG = 1e-4\n    \n    MODELS = ['ResNet50', 'EfficientNetB0', 'MobileNetV2', 'InceptionV3', 'DenseNet121']\n    \n    OUTPUT_DIR = f'/kaggle/working/outputs_{SPLIT_NAME}_v2'\n    MODELS_DIR = os.path.join(OUTPUT_DIR, 'models')\n    LOGS_DIR = os.path.join(OUTPUT_DIR, 'logs')\n    PLOTS_DIR = os.path.join(OUTPUT_DIR, 'plots')\n    RESULTS_DIR = os.path.join(OUTPUT_DIR, 'results')\n\ncfg = Config()\n\nfor directory in [cfg.OUTPUT_DIR, cfg.MODELS_DIR, cfg.LOGS_DIR, cfg.PLOTS_DIR, cfg.RESULTS_DIR]:\n    os.makedirs(directory, exist_ok=True)\n\nprint(f\"Configuration: Split {cfg.TRAIN_RATIO}:{cfg.TEST_RATIO}\")\nprint(f\"Output: {cfg.OUTPUT_DIR}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T21:29:58.721535Z","iopub.execute_input":"2025-10-24T21:29:58.721820Z","iopub.status.idle":"2025-10-24T21:29:58.730438Z","shell.execute_reply.started":"2025-10-24T21:29:58.721799Z","shell.execute_reply":"2025-10-24T21:29:58.729671Z"}},"outputs":[{"name":"stdout","text":"Configuration: Split 60:40\nOutput: /kaggle/working/outputs_60_40_v2\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"# CELL 4: Data Loading Functions","metadata":{}},{"cell_type":"code","source":"def load_dataset(data_dir, class_names):\n    image_paths = []\n    labels = []\n    label_to_idx = {name: idx for idx, name in enumerate(sorted(class_names))}\n    idx_to_label = {idx: name for name, idx in label_to_idx.items()}\n    \n    print(\"Loading dataset...\")\n    \n    class_counts = {}\n    for class_name in sorted(class_names):\n        class_dir = os.path.join(data_dir, class_name)\n        if not os.path.exists(class_dir):\n            continue\n        \n        class_images = [\n            os.path.join(class_dir, f)\n            for f in os.listdir(class_dir)\n            if f.lower().endswith(('.jpg', '.jpeg', '.png'))\n        ]\n        \n        image_paths.extend(class_images)\n        labels.extend([label_to_idx[class_name]] * len(class_images))\n        class_counts[class_name] = len(class_images)\n    \n    print(f\"Loaded: {len(image_paths)} images, {len(class_counts)} classes\")\n    return image_paths, labels, label_to_idx, idx_to_label\n\n\ndef prepare_splits(image_paths, labels, train_ratio, test_ratio, val_ratio=0.1, random_state=42):\n    image_paths = np.array(image_paths)\n    labels = np.array(labels)\n    \n    train_val_paths, test_paths, train_val_labels, test_labels = train_test_split(\n        image_paths, labels, test_size=test_ratio/100, stratify=labels, random_state=random_state\n    )\n    \n    train_paths, val_paths, train_labels, val_labels = train_test_split(\n        train_val_paths, train_val_labels, test_size=val_ratio, stratify=train_val_labels, random_state=random_state\n    )\n    \n    print(f\"Train: {len(train_paths)}, Val: {len(val_paths)}, Test: {len(test_paths)}\")\n    return {\n        'train_paths': train_paths, 'train_labels': train_labels,\n        'val_paths': val_paths, 'val_labels': val_labels,\n        'test_paths': test_paths, 'test_labels': test_labels\n    }\n\n\nall_image_paths, all_labels, label_to_idx, idx_to_label = load_dataset(cfg.ORIGINAL_FOLDER, cfg.CLASS_NAMES)\nsplit_data = prepare_splits(all_image_paths, all_labels, cfg.TRAIN_RATIO, cfg.TEST_RATIO, cfg.VAL_RATIO, cfg.RANDOM_SEED)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T21:33:33.724017Z","iopub.execute_input":"2025-10-24T21:33:33.724769Z","iopub.status.idle":"2025-10-24T21:33:34.163418Z","shell.execute_reply.started":"2025-10-24T21:33:33.724742Z","shell.execute_reply":"2025-10-24T21:33:34.162743Z"}},"outputs":[{"name":"stdout","text":"Loading dataset...\nLoaded: 19000 images, 38 classes\nTrain: 10260, Val: 1140, Test: 7600\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"# CELL 5: Data Pipeline Functions","metadata":{}},{"cell_type":"code","source":"def create_dataset_enhanced(paths, labels, preprocess_func, batch_size, img_size, \n                            shuffle=False, augment=False, seed=42):\n    def load_and_augment(path, label):\n        img = tf.io.read_file(path)\n        img = tf.image.decode_jpeg(img, channels=3)\n        \n        if augment:\n            img = tf.image.random_crop(tf.image.resize(img, (256, 256)), [224, 224, 3])\n            img = tf.image.random_flip_left_right(img)\n            img = tf.image.random_flip_up_down(img)\n            img = tf.image.random_brightness(img, 0.3)\n            img = tf.image.random_contrast(img, 0.7, 1.3)\n            img = tf.image.random_saturation(img, 0.7, 1.3)\n            img = tf.image.random_hue(img, 0.1)\n        else:\n            img = tf.image.resize(img, img_size)\n        \n        img = tf.cast(img, tf.float32)\n        if preprocess_func is not None:\n            img = preprocess_func(img)\n        else:\n            img = img / 255.0\n        \n        return img, label\n    \n    dataset = tf.data.Dataset.from_tensor_slices((paths, labels))\n    if shuffle:\n        dataset = dataset.shuffle(buffer_size=2000, seed=seed, reshuffle_each_iteration=True)\n    dataset = dataset.map(load_and_augment, num_parallel_calls=tf.data.AUTOTUNE)\n    dataset = dataset.batch(batch_size)\n    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n    \n    return dataset\n\nprint(\"Enhanced augmentation pipeline ready\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T21:34:17.735339Z","iopub.execute_input":"2025-10-24T21:34:17.735626Z","iopub.status.idle":"2025-10-24T21:34:17.743025Z","shell.execute_reply.started":"2025-10-24T21:34:17.735604Z","shell.execute_reply":"2025-10-24T21:34:17.742166Z"}},"outputs":[{"name":"stdout","text":"Enhanced augmentation pipeline ready\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"# CELL 6: Model Building Function","metadata":{}},{"cell_type":"code","source":"def build_model_advanced(backbone_name, input_shape=(224, 224, 3), num_classes=38):\n    backbones = {\n        'ResNet50': (ResNet50, resnet_preprocess),\n        'EfficientNetB0': (EfficientNetB0, efficientnet_preprocess),\n        'MobileNetV2': (MobileNetV2, mobilenet_preprocess),\n        'InceptionV3': (InceptionV3, inception_preprocess),\n        'DenseNet121': (DenseNet121, densenet_preprocess)\n    }\n    \n    backbone_class, preprocess_func = backbones[backbone_name]\n    \n    print(f\"Building {backbone_name} with enhanced architecture...\")\n    base_model = backbone_class(include_top=False, weights='imagenet', input_shape=input_shape)\n    base_model.trainable = False\n    \n    inputs = keras.Input(shape=input_shape)\n    x = base_model(inputs, training=False)\n    x = layers.GlobalAveragePooling2D()(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(cfg.L2_REG))(x)\n    x = layers.Dropout(cfg.DROPOUT_RATE)(x)\n    x = layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(cfg.L2_REG))(x)\n    x = layers.Dropout(cfg.DROPOUT_RATE)(x)\n    outputs = layers.Dense(num_classes, activation='softmax')(x)\n    \n    model = keras.Model(inputs, outputs, name=f'{backbone_name}_enhanced')\n    \n    model.compile(\n        optimizer=keras.optimizers.Adam(learning_rate=cfg.LR_PHASE1),\n        loss='sparse_categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    \n    print(f\"Model ready: {model.count_params():,} parameters\")\n    return model, preprocess_func, base_model\n\nprint(\"Advanced model builder defined\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T21:34:38.555617Z","iopub.execute_input":"2025-10-24T21:34:38.556231Z","iopub.status.idle":"2025-10-24T21:34:38.563927Z","shell.execute_reply.started":"2025-10-24T21:34:38.556206Z","shell.execute_reply":"2025-10-24T21:34:38.563152Z"}},"outputs":[{"name":"stdout","text":"Advanced model builder defined\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"# CELL 7: Two-Phase Training Controlle","metadata":{}},{"cell_type":"code","source":"class TwoPhaseTrainer:\n    def __init__(self, model, base_model, model_name, split_name):\n        self.model = model\n        self.base_model = base_model\n        self.model_name = model_name\n        self.split_name = split_name\n        self.history_phase1 = None\n        self.history_phase2 = None\n        \n    def get_callbacks(self, phase):\n        model_dir = os.path.join(cfg.MODELS_DIR, f\"{self.model_name}_{self.split_name}\")\n        os.makedirs(model_dir, exist_ok=True)\n        \n        checkpoint_path = os.path.join(model_dir, f'best_model_phase{phase}.h5')\n        \n        callbacks_list = [\n            callbacks.ModelCheckpoint(\n                filepath=checkpoint_path,\n                monitor='val_accuracy',\n                mode='max',\n                save_best_only=True,\n                save_weights_only=False,\n                verbose=1\n            ),\n            callbacks.ReduceLROnPlateau(\n                monitor='val_loss',\n                factor=0.5,\n                patience=3,\n                min_lr=1e-7,\n                verbose=1,\n                mode='min'\n            ),\n            callbacks.CSVLogger(\n                filename=os.path.join(model_dir, f'training_log_phase{phase}.csv'),\n                append=False\n            )\n        ]\n        \n        return callbacks_list, checkpoint_path\n    \n    def train_phase1(self, train_dataset, val_dataset):\n        print(f\"\\nPHASE 1: Training classifier head (backbone frozen)\")\n        print(f\"Epochs: {cfg.EPOCHS_PHASE1}, Learning Rate: {cfg.LR_PHASE1}\")\n        print(f\"Trainable parameters: {sum([tf.size(w).numpy() for w in self.model.trainable_weights]):,}\")\n        \n        self.base_model.trainable = False\n        self.model.compile(\n            optimizer=keras.optimizers.Adam(learning_rate=cfg.LR_PHASE1),\n            loss='sparse_categorical_crossentropy',\n            metrics=['accuracy']\n        )\n        \n        callbacks_list, checkpoint_path = self.get_callbacks(phase=1)\n        \n        start_time = time.time()\n        self.history_phase1 = self.model.fit(\n            train_dataset,\n            validation_data=val_dataset,\n            epochs=cfg.EPOCHS_PHASE1,\n            callbacks=callbacks_list,\n            verbose=1\n        )\n        phase1_time = time.time() - start_time\n        \n        print(f\"Phase 1 completed in {phase1_time/60:.2f} minutes\")\n        print(f\"Best model saved: {checkpoint_path}\")\n        \n        return checkpoint_path, phase1_time\n    \n    def train_phase2(self, train_dataset, val_dataset):\n        print(f\"\\nPHASE 2: Fine-tuning entire model (backbone unfrozen)\")\n        print(f\"Epochs: {cfg.EPOCHS_PHASE2}, Learning Rate: {cfg.LR_PHASE2}\")\n        \n        self.base_model.trainable = True\n        \n        num_layers = len(self.base_model.layers)\n        freeze_until = int(num_layers * 0.5)\n        \n        for layer in self.base_model.layers[:freeze_until]:\n            layer.trainable = False\n        \n        print(f\"Unfreezing last {num_layers - freeze_until}/{num_layers} layers of backbone\")\n        print(f\"Trainable parameters: {sum([tf.size(w).numpy() for w in self.model.trainable_weights]):,}\")\n        \n        self.model.compile(\n            optimizer=keras.optimizers.Adam(learning_rate=cfg.LR_PHASE2),\n            loss='sparse_categorical_crossentropy',\n            metrics=['accuracy']\n        )\n        \n        callbacks_list, checkpoint_path = self.get_callbacks(phase=2)\n        \n        start_time = time.time()\n        self.history_phase2 = self.model.fit(\n            train_dataset,\n            validation_data=val_dataset,\n            initial_epoch=cfg.EPOCHS_PHASE1,\n            epochs=cfg.TOTAL_EPOCHS,\n            callbacks=callbacks_list,\n            verbose=1\n        )\n        phase2_time = time.time() - start_time\n        \n        print(f\"Phase 2 completed in {phase2_time/60:.2f} minutes\")\n        print(f\"Best model saved: {checkpoint_path}\")\n        \n        return checkpoint_path, phase2_time\n    \n    def get_combined_history(self):\n        if self.history_phase1 is None or self.history_phase2 is None:\n            return None\n        \n        combined = {\n            'accuracy': self.history_phase1.history['accuracy'] + self.history_phase2.history['accuracy'],\n            'val_accuracy': self.history_phase1.history['val_accuracy'] + self.history_phase2.history['val_accuracy'],\n            'loss': self.history_phase1.history['loss'] + self.history_phase2.history['loss'],\n            'val_loss': self.history_phase1.history['val_loss'] + self.history_phase2.history['val_loss']\n        }\n        \n        return type('History', (), {'history': combined})()\n\nprint(\"Two-phase training controller defined\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T21:35:02.001551Z","iopub.execute_input":"2025-10-24T21:35:02.002547Z","iopub.status.idle":"2025-10-24T21:35:02.016078Z","shell.execute_reply.started":"2025-10-24T21:35:02.002506Z","shell.execute_reply":"2025-10-24T21:35:02.015160Z"}},"outputs":[{"name":"stdout","text":"Two-phase training controller defined\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"# CELL 8: Evaluation Function","metadata":{}},{"cell_type":"code","source":"def evaluate_model_comprehensive(model, test_dataset, test_labels, idx_to_label, \n                                  model_name, split_name):\n    print(f\"\\nComprehensive evaluation: {model_name} on {split_name}\")\n    \n    results_dir = os.path.join(cfg.RESULTS_DIR, f\"{model_name}_{split_name}\")\n    os.makedirs(results_dir, exist_ok=True)\n    \n    start_time = time.time()\n    y_pred_probs = model.predict(test_dataset, verbose=0)\n    inference_time = time.time() - start_time\n    \n    y_pred = np.argmax(y_pred_probs, axis=1)\n    y_true = test_labels\n    \n    avg_inference_time_ms = (inference_time / len(test_labels)) * 1000\n    \n    overall_accuracy = accuracy_score(y_true, y_pred)\n    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(\n        y_true, y_pred, average='macro', zero_division=0\n    )\n    precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(\n        y_true, y_pred, average='micro', zero_division=0\n    )\n    \n    print(f\"Accuracy: {overall_accuracy*100:.2f}%\")\n    print(f\"F1-Score (Macro): {f1_macro:.4f}\")\n    print(f\"Precision (Macro): {precision_macro:.4f}\")\n    print(f\"Recall (Macro): {recall_macro:.4f}\")\n    \n    precision, recall, f1, support = precision_recall_fscore_support(\n        y_true, y_pred, average=None, zero_division=0\n    )\n    \n    per_class_accuracy = np.array([\n        (y_pred[y_true == i] == y_true[y_true == i]).sum() / (y_true == i).sum()\n        if (y_true == i).sum() > 0 else 0.0\n        for i in range(cfg.NUM_CLASSES)\n    ])\n    \n    try:\n        y_true_bin = label_binarize(y_true, classes=range(cfg.NUM_CLASSES))\n        roc_auc_scores = []\n        for i in range(cfg.NUM_CLASSES):\n            try:\n                score = roc_auc_score(y_true_bin[:, i], y_pred_probs[:, i])\n                roc_auc_scores.append(score)\n            except:\n                roc_auc_scores.append(0.0)\n        roc_auc_macro = np.mean(roc_auc_scores)\n        print(f\"ROC-AUC (Macro): {roc_auc_macro:.4f}\")\n    except:\n        roc_auc_macro = 0.0\n        roc_auc_scores = [0.0] * cfg.NUM_CLASSES\n    \n    cm = confusion_matrix(y_true, y_pred)\n    \n    confused_pairs = []\n    for i in range(cfg.NUM_CLASSES):\n        for j in range(cfg.NUM_CLASSES):\n            if i != j and cm[i, j] > 0:\n                confused_pairs.append({\n                    'true_class': idx_to_label[i],\n                    'pred_class': idx_to_label[j],\n                    'count': int(cm[i, j]),\n                    'true_idx': int(i),\n                    'pred_idx': int(j)\n                })\n    \n    top_confused = sorted(confused_pairs, key=lambda x: x['count'], reverse=True)[:5]\n    \n    total_params = model.count_params()\n    gflops = total_params * 2 / 1e9\n    \n    results_dict = {\n        'model_name': model_name,\n        'split_name': split_name,\n        'overall_accuracy': overall_accuracy,\n        'precision_macro': precision_macro,\n        'recall_macro': recall_macro,\n        'f1_macro': f1_macro,\n        'roc_auc_macro': roc_auc_macro,\n        'avg_inference_time_ms': avg_inference_time_ms,\n        'total_params': total_params,\n        'gflops': gflops,\n        'per_class_accuracy': per_class_accuracy,\n        'per_class_precision': precision,\n        'per_class_recall': recall,\n        'per_class_f1': f1,\n        'confusion_matrix': cm,\n        'y_true': y_true,\n        'y_pred': y_pred,\n        'y_pred_probs': y_pred_probs\n    }\n    \n    json_results = {k: float(v) if isinstance(v, np.floating) else int(v) if isinstance(v, np.integer) else v \n                    for k, v in results_dict.items() if k not in ['confusion_matrix', 'y_true', 'y_pred', 'y_pred_probs', \n                                                                    'per_class_accuracy', 'per_class_precision', \n                                                                    'per_class_recall', 'per_class_f1']}\n    \n    with open(os.path.join(results_dir, 'metrics.json'), 'w') as f:\n        json.dump(json_results, f, indent=4)\n    \n    return results_dict\n\nprint(\"Comprehensive evaluation function defined\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T21:35:19.302471Z","iopub.execute_input":"2025-10-24T21:35:19.303187Z","iopub.status.idle":"2025-10-24T21:35:19.315118Z","shell.execute_reply.started":"2025-10-24T21:35:19.303163Z","shell.execute_reply":"2025-10-24T21:35:19.314307Z"}},"outputs":[{"name":"stdout","text":"Comprehensive evaluation function defined\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"# CELL 9: Visualization Functions","metadata":{}},{"cell_type":"code","source":"def plot_training_curves_enhanced(history, model_name, split_name):\n    model_dir = os.path.join(cfg.PLOTS_DIR, f\"{model_name}_{split_name}\")\n    os.makedirs(model_dir, exist_ok=True)\n    \n    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n    \n    epochs_range = range(1, len(history.history['accuracy']) + 1)\n    phase1_end = cfg.EPOCHS_PHASE1\n    \n    axes[0, 0].plot(epochs_range, history.history['accuracy'], 'b-', linewidth=2, label='Train')\n    axes[0, 0].plot(epochs_range, history.history['val_accuracy'], 'r-', linewidth=2, label='Validation')\n    axes[0, 0].axvline(x=phase1_end, color='g', linestyle='--', linewidth=2, label='Phase 1/2 Boundary')\n    axes[0, 0].set_title('Model Accuracy', fontsize=13, fontweight='bold')\n    axes[0, 0].set_xlabel('Epoch')\n    axes[0, 0].set_ylabel('Accuracy')\n    axes[0, 0].legend()\n    axes[0, 0].grid(True, alpha=0.3)\n    \n    axes[0, 1].plot(epochs_range, history.history['loss'], 'b-', linewidth=2, label='Train')\n    axes[0, 1].plot(epochs_range, history.history['val_loss'], 'r-', linewidth=2, label='Validation')\n    axes[0, 1].axvline(x=phase1_end, color='g', linestyle='--', linewidth=2, label='Phase 1/2 Boundary')\n    axes[0, 1].set_title('Model Loss', fontsize=13, fontweight='bold')\n    axes[0, 1].set_xlabel('Epoch')\n    axes[0, 1].set_ylabel('Loss')\n    axes[0, 1].legend()\n    axes[0, 1].grid(True, alpha=0.3)\n    \n    val_acc = history.history['val_accuracy']\n    best_epoch = np.argmax(val_acc) + 1\n    best_val_acc = max(val_acc)\n    \n    axes[1, 0].plot(epochs_range, val_acc, 'r-', linewidth=2)\n    axes[1, 0].scatter([best_epoch], [best_val_acc], color='gold', s=200, zorder=5, edgecolors='black', linewidth=2)\n    axes[1, 0].set_title(f'Validation Accuracy (Best: {best_val_acc:.4f} at epoch {best_epoch})', \n                         fontsize=13, fontweight='bold')\n    axes[1, 0].set_xlabel('Epoch')\n    axes[1, 0].set_ylabel('Validation Accuracy')\n    axes[1, 0].grid(True, alpha=0.3)\n    \n    overfitting_gap = [history.history['accuracy'][i] - history.history['val_accuracy'][i] \n                       for i in range(len(history.history['accuracy']))]\n    axes[1, 1].plot(epochs_range, overfitting_gap, 'purple', linewidth=2)\n    axes[1, 1].axhline(y=0, color='black', linestyle='-', linewidth=1)\n    axes[1, 1].set_title('Training-Validation Gap (Overfitting Indicator)', fontsize=13, fontweight='bold')\n    axes[1, 1].set_xlabel('Epoch')\n    axes[1, 1].set_ylabel('Train Acc - Val Acc')\n    axes[1, 1].grid(True, alpha=0.3)\n    \n    plt.tight_layout()\n    save_path = os.path.join(model_dir, 'training_analysis.png')\n    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n    print(f\"Training analysis saved: {save_path}\")\n    plt.close()\n\n\ndef plot_confusion_matrix_professional(cm, model_name, split_name):\n    model_dir = os.path.join(cfg.PLOTS_DIR, f\"{model_name}_{split_name}\")\n    os.makedirs(model_dir, exist_ok=True)\n    \n    fig, axes = plt.subplots(1, 2, figsize=(24, 10))\n    \n    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n    \n    sns.heatmap(cm_normalized, annot=False, cmap='Blues', ax=axes[0],\n                xticklabels=cfg.CLASS_NAMES, yticklabels=cfg.CLASS_NAMES,\n                cbar_kws={'label': 'Normalized Frequency'})\n    axes[0].set_title(f'{model_name}: Normalized Confusion Matrix', fontsize=14, fontweight='bold')\n    axes[0].set_xlabel('Predicted Label', fontsize=12)\n    axes[0].set_ylabel('True Label', fontsize=12)\n    \n    per_class_acc = np.diag(cm_normalized)\n    axes[1].barh(cfg.CLASS_NAMES, per_class_acc, color='steelblue')\n    axes[1].set_xlabel('Accuracy', fontsize=12)\n    axes[1].set_title(f'{model_name}: Per-Class Accuracy', fontsize=14, fontweight='bold')\n    axes[1].axvline(x=np.mean(per_class_acc), color='red', linestyle='--', linewidth=2, \n                    label=f'Mean: {np.mean(per_class_acc):.3f}')\n    axes[1].legend()\n    axes[1].grid(True, alpha=0.3, axis='x')\n    \n    plt.tight_layout()\n    save_path = os.path.join(model_dir, 'confusion_matrix_analysis.png')\n    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n    print(f\"Confusion matrix analysis saved: {save_path}\")\n    plt.close()\n\nprint(\"Enhanced visualization functions defined\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T21:36:04.695704Z","iopub.execute_input":"2025-10-24T21:36:04.696277Z","iopub.status.idle":"2025-10-24T21:36:04.712870Z","shell.execute_reply.started":"2025-10-24T21:36:04.696252Z","shell.execute_reply":"2025-10-24T21:36:04.711916Z"}},"outputs":[{"name":"stdout","text":"Enhanced visualization functions defined\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"# CELL 10: Main Training Pipeline","metadata":{}},{"cell_type":"code","source":"print(f\"Starting enhanced training pipeline for split {cfg.TRAIN_RATIO}:{cfg.TEST_RATIO}\")\nprint(f\"Configuration: Two-phase training with enhanced regularization\")\nprint(f\"Expected outcome: 95%+ accuracy with minimal overfitting\\n\")\n\nresults_collection = []\n\nfor model_name in cfg.MODELS:\n    try:\n        print(f\"\\n{'='*90}\")\n        print(f\"MODEL: {model_name}\")\n        print(f\"{'='*90}\")\n        \n        model, preprocess_func, base_model = build_model_advanced(model_name)\n        \n        print(\"\\nPreparing data pipelines...\")\n        train_dataset = create_dataset_enhanced(\n            split_data['train_paths'], split_data['train_labels'],\n            preprocess_func, cfg.BATCH_SIZE, cfg.IMG_SIZE,\n            shuffle=True, augment=True, seed=cfg.RANDOM_SEED\n        )\n        \n        val_dataset = create_dataset_enhanced(\n            split_data['val_paths'], split_data['val_labels'],\n            preprocess_func, cfg.BATCH_SIZE, cfg.IMG_SIZE,\n            shuffle=False, augment=False\n        )\n        \n        test_dataset = create_dataset_enhanced(\n            split_data['test_paths'], split_data['test_labels'],\n            preprocess_func, cfg.BATCH_SIZE, cfg.IMG_SIZE,\n            shuffle=False, augment=False\n        )\n        \n        trainer = TwoPhaseTrainer(model, base_model, model_name, cfg.SPLIT_NAME)\n        \n        checkpoint_p1, time_p1 = trainer.train_phase1(train_dataset, val_dataset)\n        checkpoint_p2, time_p2 = trainer.train_phase2(train_dataset, val_dataset)\n        \n        total_training_time = time_p1 + time_p2\n        \n        print(f\"\\nLoading best model from Phase 2...\")\n        best_model = keras.models.load_model(checkpoint_p2)\n        \n        results = evaluate_model_comprehensive(\n            best_model, test_dataset, split_data['test_labels'],\n            idx_to_label, model_name, cfg.SPLIT_NAME\n        )\n        \n        results['training_time_total_min'] = total_training_time / 60\n        results['training_time_phase1_min'] = time_p1 / 60\n        results['training_time_phase2_min'] = time_p2 / 60\n        \n        combined_history = trainer.get_combined_history()\n        plot_training_curves_enhanced(combined_history, model_name, cfg.SPLIT_NAME)\n        plot_confusion_matrix_professional(results['confusion_matrix'], model_name, cfg.SPLIT_NAME)\n        \n        results_collection.append(results)\n        \n        print(f\"\\n{model_name} Summary:\")\n        print(f\"  Test Accuracy: {results['overall_accuracy']*100:.2f}%\")\n        print(f\"  F1-Score: {results['f1_macro']:.4f}\")\n        print(f\"  Total Training Time: {results['training_time_total_min']:.1f} minutes\")\n        \n        keras.backend.clear_session()\n        \n    except Exception as e:\n        print(f\"\\nError with {model_name}: {str(e)}\")\n        import traceback\n        traceback.print_exc()\n\nprint(f\"\\n{'='*90}\")\nprint(f\"Training pipeline completed for split {cfg.TRAIN_RATIO}:{cfg.TEST_RATIO}\")\nprint(f\"Models trained: {len(results_collection)}/5\")\nprint(f\"{'='*90}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T21:36:10.374543Z","iopub.execute_input":"2025-10-24T21:36:10.375064Z","iopub.status.idle":"2025-10-24T23:47:46.365896Z","shell.execute_reply.started":"2025-10-24T21:36:10.375044Z","shell.execute_reply":"2025-10-24T23:47:46.365245Z"}},"outputs":[{"name":"stdout","text":"Starting enhanced training pipeline for split 60:40\nConfiguration: Two-phase training with enhanced regularization\nExpected outcome: 95%+ accuracy with minimal overfitting\n\n\n==========================================================================================\nMODEL: ResNet50\n==========================================================================================\nBuilding ResNet50 with enhanced architecture...\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1761341770.500344      37 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nModel ready: 24,786,086 parameters\n\nPreparing data pipelines...\n\nPHASE 1: Training classifier head (backbone frozen)\nEpochs: 10, Learning Rate: 0.001\nTrainable parameters: 1,194,278\nEpoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1761341786.474739     109 service.cc:148] XLA service 0x78d960002ce0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1761341786.475427     109 service.cc:156]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\nI0000 00:00:1761341788.294383     109 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m  3/321\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 47ms/step - accuracy: 0.0174 - loss: 5.1333       ","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1761341793.304903     109 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.1800 - loss: 3.4637\nEpoch 1: val_accuracy improved from -inf to 0.46316, saving model to /kaggle/working/outputs_60_40_v2/models/ResNet50_60_40/best_model_phase1.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 150ms/step - accuracy: 0.1802 - loss: 3.4618 - val_accuracy: 0.4632 - val_loss: 1.9240 - learning_rate: 0.0010\nEpoch 2/10\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.3868 - loss: 2.1520\nEpoch 2: val_accuracy improved from 0.46316 to 0.48947, saving model to /kaggle/working/outputs_60_40_v2/models/ResNet50_60_40/best_model_phase1.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 92ms/step - accuracy: 0.3869 - loss: 2.1515 - val_accuracy: 0.4895 - val_loss: 1.7000 - learning_rate: 0.0010\nEpoch 3/10\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.4570 - loss: 1.8933\nEpoch 3: val_accuracy did not improve from 0.48947\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 90ms/step - accuracy: 0.4571 - loss: 1.8929 - val_accuracy: 0.4886 - val_loss: 1.6224 - learning_rate: 0.0010\nEpoch 4/10\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.4975 - loss: 1.7446\nEpoch 4: val_accuracy improved from 0.48947 to 0.52018, saving model to /kaggle/working/outputs_60_40_v2/models/ResNet50_60_40/best_model_phase1.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 94ms/step - accuracy: 0.4975 - loss: 1.7445 - val_accuracy: 0.5202 - val_loss: 1.5593 - learning_rate: 0.0010\nEpoch 5/10\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.5195 - loss: 1.6677\nEpoch 5: val_accuracy did not improve from 0.52018\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 92ms/step - accuracy: 0.5195 - loss: 1.6677 - val_accuracy: 0.5158 - val_loss: 1.5466 - learning_rate: 0.0010\nEpoch 6/10\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.5376 - loss: 1.6355\nEpoch 6: val_accuracy improved from 0.52018 to 0.53333, saving model to /kaggle/working/outputs_60_40_v2/models/ResNet50_60_40/best_model_phase1.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 96ms/step - accuracy: 0.5376 - loss: 1.6354 - val_accuracy: 0.5333 - val_loss: 1.5406 - learning_rate: 0.0010\nEpoch 7/10\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.5584 - loss: 1.5340\nEpoch 7: val_accuracy did not improve from 0.53333\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 92ms/step - accuracy: 0.5584 - loss: 1.5342 - val_accuracy: 0.5132 - val_loss: 1.5720 - learning_rate: 0.0010\nEpoch 8/10\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.5711 - loss: 1.5264\nEpoch 8: val_accuracy did not improve from 0.53333\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 91ms/step - accuracy: 0.5711 - loss: 1.5263 - val_accuracy: 0.5289 - val_loss: 1.6440 - learning_rate: 0.0010\nEpoch 9/10\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.5834 - loss: 1.4955\nEpoch 9: val_accuracy improved from 0.53333 to 0.54737, saving model to /kaggle/working/outputs_60_40_v2/models/ResNet50_60_40/best_model_phase1.h5\n\nEpoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 93ms/step - accuracy: 0.5834 - loss: 1.4955 - val_accuracy: 0.5474 - val_loss: 1.6050 - learning_rate: 0.0010\nEpoch 10/10\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.6051 - loss: 1.4202\nEpoch 10: val_accuracy improved from 0.54737 to 0.54912, saving model to /kaggle/working/outputs_60_40_v2/models/ResNet50_60_40/best_model_phase1.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 93ms/step - accuracy: 0.6052 - loss: 1.4200 - val_accuracy: 0.5491 - val_loss: 1.5098 - learning_rate: 5.0000e-04\nPhase 1 completed in 5.58 minutes\nBest model saved: /kaggle/working/outputs_60_40_v2/models/ResNet50_60_40/best_model_phase1.h5\n\nPHASE 2: Fine-tuning entire model (backbone unfrozen)\nEpochs: 40, Learning Rate: 0.0001\nUnfreezing last 88/175 layers of backbone\nTrainable parameters: 22,556,454\nEpoch 11/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.5166 - loss: 1.8024\nEpoch 11: val_accuracy improved from -inf to 0.48860, saving model to /kaggle/working/outputs_60_40_v2/models/ResNet50_60_40/best_model_phase2.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 171ms/step - accuracy: 0.5167 - loss: 1.8018 - val_accuracy: 0.4886 - val_loss: 1.9965 - learning_rate: 1.0000e-04\nEpoch 12/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.6481 - loss: 1.2944\nEpoch 12: val_accuracy improved from 0.48860 to 0.52193, saving model to /kaggle/working/outputs_60_40_v2/models/ResNet50_60_40/best_model_phase2.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 113ms/step - accuracy: 0.6481 - loss: 1.2943 - val_accuracy: 0.5219 - val_loss: 1.8196 - learning_rate: 1.0000e-04\nEpoch 13/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.7006 - loss: 1.1359\nEpoch 13: val_accuracy improved from 0.52193 to 0.59035, saving model to /kaggle/working/outputs_60_40_v2/models/ResNet50_60_40/best_model_phase2.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 113ms/step - accuracy: 0.7006 - loss: 1.1359 - val_accuracy: 0.5904 - val_loss: 1.6467 - learning_rate: 1.0000e-04\nEpoch 14/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.7415 - loss: 1.0200\nEpoch 14: val_accuracy did not improve from 0.59035\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 109ms/step - accuracy: 0.7415 - loss: 1.0200 - val_accuracy: 0.5632 - val_loss: 1.7236 - learning_rate: 1.0000e-04\nEpoch 15/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.7669 - loss: 0.9492\nEpoch 15: val_accuracy did not improve from 0.59035\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 109ms/step - accuracy: 0.7669 - loss: 0.9492 - val_accuracy: 0.5325 - val_loss: 1.9443 - learning_rate: 1.0000e-04\nEpoch 16/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.7896 - loss: 0.8698\nEpoch 16: val_accuracy improved from 0.59035 to 0.59298, saving model to /kaggle/working/outputs_60_40_v2/models/ResNet50_60_40/best_model_phase2.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 113ms/step - accuracy: 0.7896 - loss: 0.8698 - val_accuracy: 0.5930 - val_loss: 1.6334 - learning_rate: 1.0000e-04\nEpoch 17/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.8027 - loss: 0.8279\nEpoch 17: val_accuracy improved from 0.59298 to 0.60175, saving model to /kaggle/working/outputs_60_40_v2/models/ResNet50_60_40/best_model_phase2.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 112ms/step - accuracy: 0.8027 - loss: 0.8280 - val_accuracy: 0.6018 - val_loss: 1.6518 - learning_rate: 1.0000e-04\nEpoch 18/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.8055 - loss: 0.8172\nEpoch 18: val_accuracy improved from 0.60175 to 0.63333, saving model to /kaggle/working/outputs_60_40_v2/models/ResNet50_60_40/best_model_phase2.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 113ms/step - accuracy: 0.8055 - loss: 0.8172 - val_accuracy: 0.6333 - val_loss: 1.4731 - learning_rate: 1.0000e-04\nEpoch 19/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.8198 - loss: 0.7747\nEpoch 19: val_accuracy did not improve from 0.63333\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 109ms/step - accuracy: 0.8198 - loss: 0.7746 - val_accuracy: 0.6009 - val_loss: 1.5936 - learning_rate: 1.0000e-04\nEpoch 20/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.8364 - loss: 0.7318\nEpoch 20: val_accuracy did not improve from 0.63333\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 109ms/step - accuracy: 0.8364 - loss: 0.7318 - val_accuracy: 0.6289 - val_loss: 1.7097 - learning_rate: 1.0000e-04\nEpoch 21/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.8408 - loss: 0.7043\nEpoch 21: val_accuracy improved from 0.63333 to 0.65877, saving model to /kaggle/working/outputs_60_40_v2/models/ResNet50_60_40/best_model_phase2.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 113ms/step - accuracy: 0.8408 - loss: 0.7043 - val_accuracy: 0.6588 - val_loss: 1.3587 - learning_rate: 1.0000e-04\nEpoch 22/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.8598 - loss: 0.6498\nEpoch 22: val_accuracy improved from 0.65877 to 0.66579, saving model to /kaggle/working/outputs_60_40_v2/models/ResNet50_60_40/best_model_phase2.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 112ms/step - accuracy: 0.8598 - loss: 0.6498 - val_accuracy: 0.6658 - val_loss: 1.4466 - learning_rate: 1.0000e-04\nEpoch 23/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.8661 - loss: 0.6459\nEpoch 23: val_accuracy did not improve from 0.66579\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 109ms/step - accuracy: 0.8661 - loss: 0.6460 - val_accuracy: 0.6219 - val_loss: 1.5964 - learning_rate: 1.0000e-04\nEpoch 24/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.8728 - loss: 0.6080\nEpoch 24: val_accuracy improved from 0.66579 to 0.69386, saving model to /kaggle/working/outputs_60_40_v2/models/ResNet50_60_40/best_model_phase2.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 112ms/step - accuracy: 0.8728 - loss: 0.6080 - val_accuracy: 0.6939 - val_loss: 1.2908 - learning_rate: 1.0000e-04\nEpoch 25/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.8775 - loss: 0.5811\nEpoch 25: val_accuracy did not improve from 0.69386\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 108ms/step - accuracy: 0.8775 - loss: 0.5811 - val_accuracy: 0.6851 - val_loss: 1.4066 - learning_rate: 1.0000e-04\nEpoch 26/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.8787 - loss: 0.5845\nEpoch 26: val_accuracy improved from 0.69386 to 0.69561, saving model to /kaggle/working/outputs_60_40_v2/models/ResNet50_60_40/best_model_phase2.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 112ms/step - accuracy: 0.8787 - loss: 0.5845 - val_accuracy: 0.6956 - val_loss: 1.2134 - learning_rate: 1.0000e-04\nEpoch 27/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.8898 - loss: 0.5700\nEpoch 27: val_accuracy improved from 0.69561 to 0.70175, saving model to /kaggle/working/outputs_60_40_v2/models/ResNet50_60_40/best_model_phase2.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 112ms/step - accuracy: 0.8898 - loss: 0.5700 - val_accuracy: 0.7018 - val_loss: 1.2062 - learning_rate: 1.0000e-04\nEpoch 28/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.8951 - loss: 0.5262\nEpoch 28: val_accuracy did not improve from 0.70175\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 109ms/step - accuracy: 0.8951 - loss: 0.5262 - val_accuracy: 0.6693 - val_loss: 1.4207 - learning_rate: 1.0000e-04\nEpoch 29/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.9047 - loss: 0.5086\nEpoch 29: val_accuracy did not improve from 0.70175\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 109ms/step - accuracy: 0.9047 - loss: 0.5086 - val_accuracy: 0.6491 - val_loss: 1.5376 - learning_rate: 1.0000e-04\nEpoch 30/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.8990 - loss: 0.5226\nEpoch 30: val_accuracy improved from 0.70175 to 0.71316, saving model to /kaggle/working/outputs_60_40_v2/models/ResNet50_60_40/best_model_phase2.h5\n\nEpoch 30: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 112ms/step - accuracy: 0.8990 - loss: 0.5226 - val_accuracy: 0.7132 - val_loss: 1.2754 - learning_rate: 1.0000e-04\nEpoch 31/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.9145 - loss: 0.4715\nEpoch 31: val_accuracy improved from 0.71316 to 0.72807, saving model to /kaggle/working/outputs_60_40_v2/models/ResNet50_60_40/best_model_phase2.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 112ms/step - accuracy: 0.9145 - loss: 0.4714 - val_accuracy: 0.7281 - val_loss: 1.1911 - learning_rate: 5.0000e-05\nEpoch 32/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.9328 - loss: 0.4006\nEpoch 32: val_accuracy did not improve from 0.72807\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 109ms/step - accuracy: 0.9328 - loss: 0.4006 - val_accuracy: 0.7140 - val_loss: 1.3834 - learning_rate: 5.0000e-05\nEpoch 33/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.9445 - loss: 0.3655\nEpoch 33: val_accuracy did not improve from 0.72807\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 110ms/step - accuracy: 0.9445 - loss: 0.3655 - val_accuracy: 0.6535 - val_loss: 1.8918 - learning_rate: 5.0000e-05\nEpoch 34/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.9467 - loss: 0.3638\nEpoch 34: val_accuracy did not improve from 0.72807\n\nEpoch 34: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 109ms/step - accuracy: 0.9467 - loss: 0.3638 - val_accuracy: 0.7123 - val_loss: 1.3713 - learning_rate: 5.0000e-05\nEpoch 35/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.9513 - loss: 0.3488\nEpoch 35: val_accuracy did not improve from 0.72807\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 109ms/step - accuracy: 0.9513 - loss: 0.3487 - val_accuracy: 0.7254 - val_loss: 1.2550 - learning_rate: 2.5000e-05\nEpoch 36/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.9578 - loss: 0.3228\nEpoch 36: val_accuracy improved from 0.72807 to 0.73772, saving model to /kaggle/working/outputs_60_40_v2/models/ResNet50_60_40/best_model_phase2.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 112ms/step - accuracy: 0.9578 - loss: 0.3228 - val_accuracy: 0.7377 - val_loss: 1.3290 - learning_rate: 2.5000e-05\nEpoch 37/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.9584 - loss: 0.3259\nEpoch 37: val_accuracy did not improve from 0.73772\n\nEpoch 37: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 109ms/step - accuracy: 0.9584 - loss: 0.3259 - val_accuracy: 0.7061 - val_loss: 1.5022 - learning_rate: 2.5000e-05\nEpoch 38/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.9614 - loss: 0.3024\nEpoch 38: val_accuracy did not improve from 0.73772\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 109ms/step - accuracy: 0.9614 - loss: 0.3024 - val_accuracy: 0.7246 - val_loss: 1.3670 - learning_rate: 1.2500e-05\nEpoch 39/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.9688 - loss: 0.2901\nEpoch 39: val_accuracy did not improve from 0.73772\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 108ms/step - accuracy: 0.9688 - loss: 0.2901 - val_accuracy: 0.7289 - val_loss: 1.4154 - learning_rate: 1.2500e-05\nEpoch 40/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.9667 - loss: 0.2978\nEpoch 40: val_accuracy improved from 0.73772 to 0.74123, saving model to /kaggle/working/outputs_60_40_v2/models/ResNet50_60_40/best_model_phase2.h5\n\nEpoch 40: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 112ms/step - accuracy: 0.9667 - loss: 0.2978 - val_accuracy: 0.7412 - val_loss: 1.2614 - learning_rate: 1.2500e-05\nEpoch 41/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.9699 - loss: 0.2857\nEpoch 41: val_accuracy did not improve from 0.74123\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 109ms/step - accuracy: 0.9699 - loss: 0.2857 - val_accuracy: 0.7281 - val_loss: 1.3471 - learning_rate: 6.2500e-06\nEpoch 42/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.9718 - loss: 0.2782\nEpoch 42: val_accuracy did not improve from 0.74123\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 109ms/step - accuracy: 0.9718 - loss: 0.2782 - val_accuracy: 0.7342 - val_loss: 1.3161 - learning_rate: 6.2500e-06\nEpoch 43/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.9743 - loss: 0.2697\nEpoch 43: val_accuracy did not improve from 0.74123\n\nEpoch 43: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 109ms/step - accuracy: 0.9743 - loss: 0.2697 - val_accuracy: 0.7333 - val_loss: 1.3572 - learning_rate: 6.2500e-06\nEpoch 44/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.9747 - loss: 0.2777\nEpoch 44: val_accuracy improved from 0.74123 to 0.74474, saving model to /kaggle/working/outputs_60_40_v2/models/ResNet50_60_40/best_model_phase2.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 113ms/step - accuracy: 0.9747 - loss: 0.2777 - val_accuracy: 0.7447 - val_loss: 1.3064 - learning_rate: 3.1250e-06\nEpoch 45/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.9733 - loss: 0.2744\nEpoch 45: val_accuracy improved from 0.74474 to 0.75000, saving model to /kaggle/working/outputs_60_40_v2/models/ResNet50_60_40/best_model_phase2.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 112ms/step - accuracy: 0.9733 - loss: 0.2744 - val_accuracy: 0.7500 - val_loss: 1.2796 - learning_rate: 3.1250e-06\nEpoch 46/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.9791 - loss: 0.2579\nEpoch 46: val_accuracy did not improve from 0.75000\n\nEpoch 46: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 109ms/step - accuracy: 0.9791 - loss: 0.2579 - val_accuracy: 0.7439 - val_loss: 1.3201 - learning_rate: 3.1250e-06\nEpoch 47/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.9782 - loss: 0.2621\nEpoch 47: val_accuracy did not improve from 0.75000\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 109ms/step - accuracy: 0.9782 - loss: 0.2620 - val_accuracy: 0.7412 - val_loss: 1.3219 - learning_rate: 1.5625e-06\nEpoch 48/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.9777 - loss: 0.2630\nEpoch 48: val_accuracy did not improve from 0.75000\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 109ms/step - accuracy: 0.9777 - loss: 0.2630 - val_accuracy: 0.7430 - val_loss: 1.3241 - learning_rate: 1.5625e-06\nEpoch 49/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.9758 - loss: 0.2612\nEpoch 49: val_accuracy did not improve from 0.75000\n\nEpoch 49: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 108ms/step - accuracy: 0.9758 - loss: 0.2612 - val_accuracy: 0.7456 - val_loss: 1.2966 - learning_rate: 1.5625e-06\nEpoch 50/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.9764 - loss: 0.2667\nEpoch 50: val_accuracy did not improve from 0.75000\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 109ms/step - accuracy: 0.9764 - loss: 0.2667 - val_accuracy: 0.7430 - val_loss: 1.3201 - learning_rate: 7.8125e-07\nPhase 2 completed in 24.80 minutes\nBest model saved: /kaggle/working/outputs_60_40_v2/models/ResNet50_60_40/best_model_phase2.h5\n\nLoading best model from Phase 2...\n\nComprehensive evaluation: ResNet50 on 60_40\nAccuracy: 75.00%\nF1-Score (Macro): 0.7379\nPrecision (Macro): 0.8178\nRecall (Macro): 0.7500\nROC-AUC (Macro): 0.9926\nTraining analysis saved: /kaggle/working/outputs_60_40_v2/plots/ResNet50_60_40/training_analysis.png\nConfusion matrix analysis saved: /kaggle/working/outputs_60_40_v2/plots/ResNet50_60_40/confusion_matrix_analysis.png\n\nResNet50 Summary:\n  Test Accuracy: 75.00%\n  F1-Score: 0.7379\n  Total Training Time: 30.4 minutes\n\n==========================================================================================\nMODEL: EfficientNetB0\n==========================================================================================\nBuilding EfficientNetB0 with enhanced architecture...\nDownloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nModel ready: 4,851,657 parameters\n\nPreparing data pipelines...\n\nPHASE 1: Training classifier head (backbone frozen)\nEpochs: 10, Learning Rate: 0.001\nTrainable parameters: 799,526\nEpoch 1/10\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.1607 - loss: 3.4379\nEpoch 1: val_accuracy improved from -inf to 0.45702, saving model to /kaggle/working/outputs_60_40_v2/models/EfficientNetB0_60_40/best_model_phase1.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 140ms/step - accuracy: 0.1609 - loss: 3.4361 - val_accuracy: 0.4570 - val_loss: 1.9926 - learning_rate: 0.0010\nEpoch 2/10\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.3811 - loss: 2.1324\nEpoch 2: val_accuracy improved from 0.45702 to 0.51930, saving model to /kaggle/working/outputs_60_40_v2/models/EfficientNetB0_60_40/best_model_phase1.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 71ms/step - accuracy: 0.3812 - loss: 2.1319 - val_accuracy: 0.5193 - val_loss: 1.5578 - learning_rate: 0.0010\nEpoch 3/10\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.4607 - loss: 1.8238\nEpoch 3: val_accuracy improved from 0.51930 to 0.52719, saving model to /kaggle/working/outputs_60_40_v2/models/EfficientNetB0_60_40/best_model_phase1.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 71ms/step - accuracy: 0.4607 - loss: 1.8236 - val_accuracy: 0.5272 - val_loss: 1.5109 - learning_rate: 0.0010\nEpoch 4/10\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.5057 - loss: 1.6832\nEpoch 4: val_accuracy improved from 0.52719 to 0.54123, saving model to /kaggle/working/outputs_60_40_v2/models/EfficientNetB0_60_40/best_model_phase1.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 70ms/step - accuracy: 0.5058 - loss: 1.6831 - val_accuracy: 0.5412 - val_loss: 1.4902 - learning_rate: 0.0010\nEpoch 5/10\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.5418 - loss: 1.5931\nEpoch 5: val_accuracy improved from 0.54123 to 0.57895, saving model to /kaggle/working/outputs_60_40_v2/models/EfficientNetB0_60_40/best_model_phase1.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 71ms/step - accuracy: 0.5417 - loss: 1.5932 - val_accuracy: 0.5789 - val_loss: 1.3700 - learning_rate: 0.0010\nEpoch 6/10\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.5568 - loss: 1.5431\nEpoch 6: val_accuracy improved from 0.57895 to 0.58860, saving model to /kaggle/working/outputs_60_40_v2/models/EfficientNetB0_60_40/best_model_phase1.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 71ms/step - accuracy: 0.5568 - loss: 1.5431 - val_accuracy: 0.5886 - val_loss: 1.3387 - learning_rate: 0.0010\nEpoch 7/10\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.5738 - loss: 1.5073\nEpoch 7: val_accuracy did not improve from 0.58860\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 69ms/step - accuracy: 0.5738 - loss: 1.5072 - val_accuracy: 0.5886 - val_loss: 1.3870 - learning_rate: 0.0010\nEpoch 8/10\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.5881 - loss: 1.4571\nEpoch 8: val_accuracy did not improve from 0.58860\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 69ms/step - accuracy: 0.5880 - loss: 1.4572 - val_accuracy: 0.5789 - val_loss: 1.3952 - learning_rate: 0.0010\nEpoch 9/10\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.5957 - loss: 1.4506\nEpoch 9: val_accuracy did not improve from 0.58860\n\nEpoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 70ms/step - accuracy: 0.5957 - loss: 1.4506 - val_accuracy: 0.5868 - val_loss: 1.3661 - learning_rate: 0.0010\nEpoch 10/10\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.6266 - loss: 1.3670\nEpoch 10: val_accuracy did not improve from 0.58860\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 69ms/step - accuracy: 0.6266 - loss: 1.3669 - val_accuracy: 0.5605 - val_loss: 1.5051 - learning_rate: 5.0000e-04\nPhase 1 completed in 4.62 minutes\nBest model saved: /kaggle/working/outputs_60_40_v2/models/EfficientNetB0_60_40/best_model_phase1.h5\n\nPHASE 2: Fine-tuning entire model (backbone unfrozen)\nEpochs: 40, Learning Rate: 0.0001\nUnfreezing last 119/238 layers of backbone\nTrainable parameters: 4,498,414\nEpoch 11/50\n","output_type":"stream"},{"name":"stderr","text":"E0000 00:00:1761343959.148233     109 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1761343959.335432     109 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1761343959.809021     109 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1761343960.014889     109 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1761343960.378175     109 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1761343960.584339     109 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.3948 - loss: 2.2773","output_type":"stream"},{"name":"stderr","text":"E0000 00:00:1761344002.462920     112 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1761344002.648232     112 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1761344003.095386     112 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1761344003.303386     112 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1761344003.660432     112 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1761344003.868912     112 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.3951 - loss: 2.2762\nEpoch 11: val_accuracy improved from -inf to 0.51930, saving model to /kaggle/working/outputs_60_40_v2/models/EfficientNetB0_60_40/best_model_phase2.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 171ms/step - accuracy: 0.3954 - loss: 2.2750 - val_accuracy: 0.5193 - val_loss: 1.6397 - learning_rate: 1.0000e-04\nEpoch 12/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.6161 - loss: 1.3917\nEpoch 12: val_accuracy improved from 0.51930 to 0.55088, saving model to /kaggle/working/outputs_60_40_v2/models/EfficientNetB0_60_40/best_model_phase2.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 75ms/step - accuracy: 0.6162 - loss: 1.3914 - val_accuracy: 0.5509 - val_loss: 1.6130 - learning_rate: 1.0000e-04\nEpoch 13/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.6766 - loss: 1.1652\nEpoch 13: val_accuracy improved from 0.55088 to 0.57368, saving model to /kaggle/working/outputs_60_40_v2/models/EfficientNetB0_60_40/best_model_phase2.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 74ms/step - accuracy: 0.6766 - loss: 1.1652 - val_accuracy: 0.5737 - val_loss: 1.5215 - learning_rate: 1.0000e-04\nEpoch 14/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.7194 - loss: 1.0726\nEpoch 14: val_accuracy improved from 0.57368 to 0.60088, saving model to /kaggle/working/outputs_60_40_v2/models/EfficientNetB0_60_40/best_model_phase2.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 77ms/step - accuracy: 0.7194 - loss: 1.0724 - val_accuracy: 0.6009 - val_loss: 1.4230 - learning_rate: 1.0000e-04\nEpoch 15/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.7572 - loss: 0.9322\nEpoch 15: val_accuracy improved from 0.60088 to 0.60702, saving model to /kaggle/working/outputs_60_40_v2/models/EfficientNetB0_60_40/best_model_phase2.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 74ms/step - accuracy: 0.7572 - loss: 0.9322 - val_accuracy: 0.6070 - val_loss: 1.3717 - learning_rate: 1.0000e-04\nEpoch 16/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.7772 - loss: 0.8776\nEpoch 16: val_accuracy did not improve from 0.60702\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 72ms/step - accuracy: 0.7772 - loss: 0.8777 - val_accuracy: 0.6061 - val_loss: 1.5418 - learning_rate: 1.0000e-04\nEpoch 17/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.7829 - loss: 0.8621\nEpoch 17: val_accuracy improved from 0.60702 to 0.64474, saving model to /kaggle/working/outputs_60_40_v2/models/EfficientNetB0_60_40/best_model_phase2.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 74ms/step - accuracy: 0.7829 - loss: 0.8620 - val_accuracy: 0.6447 - val_loss: 1.3711 - learning_rate: 1.0000e-04\nEpoch 18/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.7942 - loss: 0.8034\nEpoch 18: val_accuracy did not improve from 0.64474\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 72ms/step - accuracy: 0.7942 - loss: 0.8033 - val_accuracy: 0.5939 - val_loss: 1.6816 - learning_rate: 1.0000e-04\nEpoch 19/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.8169 - loss: 0.7450\nEpoch 19: val_accuracy improved from 0.64474 to 0.65614, saving model to /kaggle/working/outputs_60_40_v2/models/EfficientNetB0_60_40/best_model_phase2.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 73ms/step - accuracy: 0.8168 - loss: 0.7451 - val_accuracy: 0.6561 - val_loss: 1.3377 - learning_rate: 1.0000e-04\nEpoch 20/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.8273 - loss: 0.7179\nEpoch 20: val_accuracy improved from 0.65614 to 0.67368, saving model to /kaggle/working/outputs_60_40_v2/models/EfficientNetB0_60_40/best_model_phase2.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 74ms/step - accuracy: 0.8273 - loss: 0.7178 - val_accuracy: 0.6737 - val_loss: 1.3205 - learning_rate: 1.0000e-04\nEpoch 21/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.8389 - loss: 0.6664\nEpoch 21: val_accuracy did not improve from 0.67368\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 72ms/step - accuracy: 0.8389 - loss: 0.6664 - val_accuracy: 0.6596 - val_loss: 1.4026 - learning_rate: 1.0000e-04\nEpoch 22/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.8510 - loss: 0.6274\nEpoch 22: val_accuracy did not improve from 0.67368\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 71ms/step - accuracy: 0.8510 - loss: 0.6274 - val_accuracy: 0.6649 - val_loss: 1.3617 - learning_rate: 1.0000e-04\nEpoch 23/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.8618 - loss: 0.6140\nEpoch 23: val_accuracy improved from 0.67368 to 0.67632, saving model to /kaggle/working/outputs_60_40_v2/models/EfficientNetB0_60_40/best_model_phase2.h5\n\nEpoch 23: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 76ms/step - accuracy: 0.8617 - loss: 0.6140 - val_accuracy: 0.6763 - val_loss: 1.3906 - learning_rate: 1.0000e-04\nEpoch 24/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.8763 - loss: 0.5723\nEpoch 24: val_accuracy did not improve from 0.67632\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 75ms/step - accuracy: 0.8763 - loss: 0.5723 - val_accuracy: 0.6693 - val_loss: 1.4737 - learning_rate: 5.0000e-05\nEpoch 25/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.8853 - loss: 0.5360\nEpoch 25: val_accuracy improved from 0.67632 to 0.70789, saving model to /kaggle/working/outputs_60_40_v2/models/EfficientNetB0_60_40/best_model_phase2.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 77ms/step - accuracy: 0.8853 - loss: 0.5360 - val_accuracy: 0.7079 - val_loss: 1.2445 - learning_rate: 5.0000e-05\nEpoch 26/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.8849 - loss: 0.5238\nEpoch 26: val_accuracy did not improve from 0.70789\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 74ms/step - accuracy: 0.8849 - loss: 0.5239 - val_accuracy: 0.6772 - val_loss: 1.3426 - learning_rate: 5.0000e-05\nEpoch 27/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.8878 - loss: 0.5173\nEpoch 27: val_accuracy did not improve from 0.70789\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 74ms/step - accuracy: 0.8878 - loss: 0.5173 - val_accuracy: 0.6816 - val_loss: 1.3750 - learning_rate: 5.0000e-05\nEpoch 28/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.9010 - loss: 0.4962\nEpoch 28: val_accuracy improved from 0.70789 to 0.70965, saving model to /kaggle/working/outputs_60_40_v2/models/EfficientNetB0_60_40/best_model_phase2.h5\n\nEpoch 28: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 75ms/step - accuracy: 0.9010 - loss: 0.4962 - val_accuracy: 0.7096 - val_loss: 1.2807 - learning_rate: 5.0000e-05\nEpoch 29/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.9026 - loss: 0.4782\nEpoch 29: val_accuracy improved from 0.70965 to 0.71053, saving model to /kaggle/working/outputs_60_40_v2/models/EfficientNetB0_60_40/best_model_phase2.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 75ms/step - accuracy: 0.9026 - loss: 0.4781 - val_accuracy: 0.7105 - val_loss: 1.2833 - learning_rate: 2.5000e-05\nEpoch 30/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.9074 - loss: 0.4605\nEpoch 30: val_accuracy did not improve from 0.71053\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 73ms/step - accuracy: 0.9074 - loss: 0.4606 - val_accuracy: 0.6930 - val_loss: 1.4043 - learning_rate: 2.5000e-05\nEpoch 31/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.9024 - loss: 0.4755\nEpoch 31: val_accuracy improved from 0.71053 to 0.72544, saving model to /kaggle/working/outputs_60_40_v2/models/EfficientNetB0_60_40/best_model_phase2.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 76ms/step - accuracy: 0.9024 - loss: 0.4754 - val_accuracy: 0.7254 - val_loss: 1.2086 - learning_rate: 2.5000e-05\nEpoch 32/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.9098 - loss: 0.4583\nEpoch 32: val_accuracy did not improve from 0.72544\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 73ms/step - accuracy: 0.9098 - loss: 0.4583 - val_accuracy: 0.7140 - val_loss: 1.3212 - learning_rate: 2.5000e-05\nEpoch 33/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9209 - loss: 0.4395\nEpoch 33: val_accuracy did not improve from 0.72544\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 72ms/step - accuracy: 0.9209 - loss: 0.4395 - val_accuracy: 0.7132 - val_loss: 1.3481 - learning_rate: 2.5000e-05\nEpoch 34/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9162 - loss: 0.4369\nEpoch 34: val_accuracy did not improve from 0.72544\n\nEpoch 34: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 71ms/step - accuracy: 0.9162 - loss: 0.4369 - val_accuracy: 0.7184 - val_loss: 1.2922 - learning_rate: 2.5000e-05\nEpoch 35/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9250 - loss: 0.4238\nEpoch 35: val_accuracy did not improve from 0.72544\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 71ms/step - accuracy: 0.9250 - loss: 0.4238 - val_accuracy: 0.7149 - val_loss: 1.3476 - learning_rate: 1.2500e-05\nEpoch 36/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9242 - loss: 0.4202\nEpoch 36: val_accuracy did not improve from 0.72544\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 71ms/step - accuracy: 0.9242 - loss: 0.4202 - val_accuracy: 0.7167 - val_loss: 1.3179 - learning_rate: 1.2500e-05\nEpoch 37/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.9254 - loss: 0.4116\nEpoch 37: val_accuracy did not improve from 0.72544\n\nEpoch 37: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 73ms/step - accuracy: 0.9254 - loss: 0.4116 - val_accuracy: 0.7132 - val_loss: 1.3451 - learning_rate: 1.2500e-05\nEpoch 38/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.9255 - loss: 0.4136\nEpoch 38: val_accuracy did not improve from 0.72544\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 75ms/step - accuracy: 0.9255 - loss: 0.4136 - val_accuracy: 0.7123 - val_loss: 1.3524 - learning_rate: 6.2500e-06\nEpoch 39/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.9255 - loss: 0.4042\nEpoch 39: val_accuracy did not improve from 0.72544\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 74ms/step - accuracy: 0.9254 - loss: 0.4042 - val_accuracy: 0.7114 - val_loss: 1.3447 - learning_rate: 6.2500e-06\nEpoch 40/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.9296 - loss: 0.3895\nEpoch 40: val_accuracy did not improve from 0.72544\n\nEpoch 40: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 75ms/step - accuracy: 0.9296 - loss: 0.3896 - val_accuracy: 0.7158 - val_loss: 1.3546 - learning_rate: 6.2500e-06\nEpoch 41/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.9273 - loss: 0.4074\nEpoch 41: val_accuracy did not improve from 0.72544\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 75ms/step - accuracy: 0.9274 - loss: 0.4073 - val_accuracy: 0.7096 - val_loss: 1.3524 - learning_rate: 3.1250e-06\nEpoch 42/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.9263 - loss: 0.4109\nEpoch 42: val_accuracy did not improve from 0.72544\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 74ms/step - accuracy: 0.9263 - loss: 0.4108 - val_accuracy: 0.7167 - val_loss: 1.3274 - learning_rate: 3.1250e-06\nEpoch 43/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.9302 - loss: 0.3935\nEpoch 43: val_accuracy did not improve from 0.72544\n\nEpoch 43: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 74ms/step - accuracy: 0.9302 - loss: 0.3935 - val_accuracy: 0.7149 - val_loss: 1.3345 - learning_rate: 3.1250e-06\nEpoch 44/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.9334 - loss: 0.3787\nEpoch 44: val_accuracy did not improve from 0.72544\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 74ms/step - accuracy: 0.9334 - loss: 0.3788 - val_accuracy: 0.7149 - val_loss: 1.3504 - learning_rate: 1.5625e-06\nEpoch 45/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.9235 - loss: 0.4135\nEpoch 45: val_accuracy did not improve from 0.72544\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 73ms/step - accuracy: 0.9235 - loss: 0.4135 - val_accuracy: 0.7158 - val_loss: 1.3449 - learning_rate: 1.5625e-06\nEpoch 46/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.9241 - loss: 0.3945\nEpoch 46: val_accuracy did not improve from 0.72544\n\nEpoch 46: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 74ms/step - accuracy: 0.9241 - loss: 0.3946 - val_accuracy: 0.7158 - val_loss: 1.3494 - learning_rate: 1.5625e-06\nEpoch 47/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.9302 - loss: 0.3873\nEpoch 47: val_accuracy did not improve from 0.72544\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 73ms/step - accuracy: 0.9302 - loss: 0.3873 - val_accuracy: 0.7132 - val_loss: 1.3481 - learning_rate: 7.8125e-07\nEpoch 48/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.9282 - loss: 0.3938\nEpoch 48: val_accuracy did not improve from 0.72544\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 73ms/step - accuracy: 0.9282 - loss: 0.3938 - val_accuracy: 0.7158 - val_loss: 1.3472 - learning_rate: 7.8125e-07\nEpoch 49/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.9336 - loss: 0.3883\nEpoch 49: val_accuracy did not improve from 0.72544\n\nEpoch 49: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 73ms/step - accuracy: 0.9336 - loss: 0.3883 - val_accuracy: 0.7140 - val_loss: 1.3383 - learning_rate: 7.8125e-07\nEpoch 50/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.9291 - loss: 0.3889\nEpoch 50: val_accuracy did not improve from 0.72544\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 73ms/step - accuracy: 0.9291 - loss: 0.3890 - val_accuracy: 0.7140 - val_loss: 1.3450 - learning_rate: 3.9062e-07\nPhase 2 completed in 17.65 minutes\nBest model saved: /kaggle/working/outputs_60_40_v2/models/EfficientNetB0_60_40/best_model_phase2.h5\n\nLoading best model from Phase 2...\n\nComprehensive evaluation: EfficientNetB0 on 60_40\nAccuracy: 43.04%\nF1-Score (Macro): 0.4158\nPrecision (Macro): 0.5791\nRecall (Macro): 0.4304\nROC-AUC (Macro): 0.9331\nTraining analysis saved: /kaggle/working/outputs_60_40_v2/plots/EfficientNetB0_60_40/training_analysis.png\nConfusion matrix analysis saved: /kaggle/working/outputs_60_40_v2/plots/EfficientNetB0_60_40/confusion_matrix_analysis.png\n\nEfficientNetB0 Summary:\n  Test Accuracy: 43.04%\n  F1-Score: 0.4158\n  Total Training Time: 22.3 minutes\n\n==========================================================================================\nMODEL: MobileNetV2\n==========================================================================================\nBuilding MobileNetV2 with enhanced architecture...\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nModel ready: 3,060,070 parameters\n\nPreparing data pipelines...\n\nPHASE 1: Training classifier head (backbone frozen)\nEpochs: 10, Learning Rate: 0.001\nTrainable parameters: 799,526\nEpoch 1/10\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.1702 - loss: 3.3865\nEpoch 1: val_accuracy improved from -inf to 0.44474, saving model to /kaggle/working/outputs_60_40_v2/models/MobileNetV2_60_40/best_model_phase1.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 111ms/step - accuracy: 0.1705 - loss: 3.3848 - val_accuracy: 0.4447 - val_loss: 1.9399 - learning_rate: 0.0010\nEpoch 2/10\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.3747 - loss: 2.1567\nEpoch 2: val_accuracy improved from 0.44474 to 0.47807, saving model to /kaggle/working/outputs_60_40_v2/models/MobileNetV2_60_40/best_model_phase1.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 74ms/step - accuracy: 0.3748 - loss: 2.1561 - val_accuracy: 0.4781 - val_loss: 1.7099 - learning_rate: 0.0010\nEpoch 3/10\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.4487 - loss: 1.8865\nEpoch 3: val_accuracy improved from 0.47807 to 0.49561, saving model to /kaggle/working/outputs_60_40_v2/models/MobileNetV2_60_40/best_model_phase1.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 74ms/step - accuracy: 0.4487 - loss: 1.8863 - val_accuracy: 0.4956 - val_loss: 1.7400 - learning_rate: 0.0010\nEpoch 4/10\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.4840 - loss: 1.7706\nEpoch 4: val_accuracy did not improve from 0.49561\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 73ms/step - accuracy: 0.4840 - loss: 1.7705 - val_accuracy: 0.4728 - val_loss: 1.7293 - learning_rate: 0.0010\nEpoch 5/10\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.5150 - loss: 1.6689\nEpoch 5: val_accuracy improved from 0.49561 to 0.51491, saving model to /kaggle/working/outputs_60_40_v2/models/MobileNetV2_60_40/best_model_phase1.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 73ms/step - accuracy: 0.5150 - loss: 1.6688 - val_accuracy: 0.5149 - val_loss: 1.6229 - learning_rate: 0.0010\nEpoch 6/10\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.5301 - loss: 1.6199\nEpoch 6: val_accuracy improved from 0.51491 to 0.55175, saving model to /kaggle/working/outputs_60_40_v2/models/MobileNetV2_60_40/best_model_phase1.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 73ms/step - accuracy: 0.5300 - loss: 1.6199 - val_accuracy: 0.5518 - val_loss: 1.5517 - learning_rate: 0.0010\nEpoch 7/10\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.5404 - loss: 1.5745\nEpoch 7: val_accuracy did not improve from 0.55175\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 72ms/step - accuracy: 0.5405 - loss: 1.5744 - val_accuracy: 0.5228 - val_loss: 1.6837 - learning_rate: 0.0010\nEpoch 8/10\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.5564 - loss: 1.5671\nEpoch 8: val_accuracy did not improve from 0.55175\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 74ms/step - accuracy: 0.5563 - loss: 1.5671 - val_accuracy: 0.5219 - val_loss: 1.6660 - learning_rate: 0.0010\nEpoch 9/10\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.5570 - loss: 1.5369\nEpoch 9: val_accuracy improved from 0.55175 to 0.55965, saving model to /kaggle/working/outputs_60_40_v2/models/MobileNetV2_60_40/best_model_phase1.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 73ms/step - accuracy: 0.5570 - loss: 1.5369 - val_accuracy: 0.5596 - val_loss: 1.5315 - learning_rate: 0.0010\nEpoch 10/10\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.5659 - loss: 1.5284\nEpoch 10: val_accuracy did not improve from 0.55965\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 72ms/step - accuracy: 0.5659 - loss: 1.5284 - val_accuracy: 0.5123 - val_loss: 1.7486 - learning_rate: 0.0010\nPhase 1 completed in 4.33 minutes\nBest model saved: /kaggle/working/outputs_60_40_v2/models/MobileNetV2_60_40/best_model_phase1.h5\n\nPHASE 2: Fine-tuning entire model (backbone unfrozen)\nEpochs: 40, Learning Rate: 0.0001\nUnfreezing last 77/154 layers of backbone\nTrainable parameters: 2,863,014\nEpoch 11/50\n","output_type":"stream"},{"name":"stderr","text":"E0000 00:00:1761345296.722908     109 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1761345296.919582     109 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.4249 - loss: 2.1240","output_type":"stream"},{"name":"stderr","text":"E0000 00:00:1761345329.500922     110 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1761345329.699939     110 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.4252 - loss: 2.1232\nEpoch 11: val_accuracy improved from -inf to 0.18158, saving model to /kaggle/working/outputs_60_40_v2/models/MobileNetV2_60_40/best_model_phase2.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 125ms/step - accuracy: 0.4254 - loss: 2.1223 - val_accuracy: 0.1816 - val_loss: 6.9848 - learning_rate: 1.0000e-04\nEpoch 12/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.5902 - loss: 1.4685\nEpoch 12: val_accuracy did not improve from 0.18158\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 75ms/step - accuracy: 0.5903 - loss: 1.4681 - val_accuracy: 0.1482 - val_loss: 10.6218 - learning_rate: 1.0000e-04\nEpoch 13/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.6483 - loss: 1.2768\nEpoch 13: val_accuracy improved from 0.18158 to 0.23860, saving model to /kaggle/working/outputs_60_40_v2/models/MobileNetV2_60_40/best_model_phase2.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 80ms/step - accuracy: 0.6484 - loss: 1.2766 - val_accuracy: 0.2386 - val_loss: 5.4001 - learning_rate: 1.0000e-04\nEpoch 14/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.7042 - loss: 1.1169\nEpoch 14: val_accuracy improved from 0.23860 to 0.29123, saving model to /kaggle/working/outputs_60_40_v2/models/MobileNetV2_60_40/best_model_phase2.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 77ms/step - accuracy: 0.7042 - loss: 1.1169 - val_accuracy: 0.2912 - val_loss: 4.1847 - learning_rate: 1.0000e-04\nEpoch 15/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.7259 - loss: 1.0491\nEpoch 15: val_accuracy improved from 0.29123 to 0.34035, saving model to /kaggle/working/outputs_60_40_v2/models/MobileNetV2_60_40/best_model_phase2.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 74ms/step - accuracy: 0.7259 - loss: 1.0492 - val_accuracy: 0.3404 - val_loss: 3.3820 - learning_rate: 1.0000e-04\nEpoch 16/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.7409 - loss: 0.9851\nEpoch 16: val_accuracy improved from 0.34035 to 0.43860, saving model to /kaggle/working/outputs_60_40_v2/models/MobileNetV2_60_40/best_model_phase2.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 74ms/step - accuracy: 0.7409 - loss: 0.9850 - val_accuracy: 0.4386 - val_loss: 2.7259 - learning_rate: 1.0000e-04\nEpoch 17/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.7558 - loss: 0.9208\nEpoch 17: val_accuracy improved from 0.43860 to 0.52544, saving model to /kaggle/working/outputs_60_40_v2/models/MobileNetV2_60_40/best_model_phase2.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 74ms/step - accuracy: 0.7559 - loss: 0.9207 - val_accuracy: 0.5254 - val_loss: 2.0311 - learning_rate: 1.0000e-04\nEpoch 18/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.7629 - loss: 0.9049\nEpoch 18: val_accuracy did not improve from 0.52544\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 73ms/step - accuracy: 0.7630 - loss: 0.9047 - val_accuracy: 0.5114 - val_loss: 2.2240 - learning_rate: 1.0000e-04\nEpoch 19/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.7912 - loss: 0.8275\nEpoch 19: val_accuracy did not improve from 0.52544\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 72ms/step - accuracy: 0.7912 - loss: 0.8275 - val_accuracy: 0.4842 - val_loss: 2.6339 - learning_rate: 1.0000e-04\nEpoch 20/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.8048 - loss: 0.8054\nEpoch 20: val_accuracy improved from 0.52544 to 0.56316, saving model to /kaggle/working/outputs_60_40_v2/models/MobileNetV2_60_40/best_model_phase2.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 72ms/step - accuracy: 0.8048 - loss: 0.8053 - val_accuracy: 0.5632 - val_loss: 1.8859 - learning_rate: 1.0000e-04\nEpoch 21/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.8169 - loss: 0.7514\nEpoch 21: val_accuracy did not improve from 0.56316\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 71ms/step - accuracy: 0.8169 - loss: 0.7513 - val_accuracy: 0.4956 - val_loss: 2.3706 - learning_rate: 1.0000e-04\nEpoch 22/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.8385 - loss: 0.6922\nEpoch 22: val_accuracy did not improve from 0.56316\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 71ms/step - accuracy: 0.8384 - loss: 0.6923 - val_accuracy: 0.5482 - val_loss: 1.9799 - learning_rate: 1.0000e-04\nEpoch 23/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.8405 - loss: 0.6883\nEpoch 23: val_accuracy did not improve from 0.56316\n\nEpoch 23: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 71ms/step - accuracy: 0.8405 - loss: 0.6883 - val_accuracy: 0.4570 - val_loss: 3.4529 - learning_rate: 1.0000e-04\nEpoch 24/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.8612 - loss: 0.6198\nEpoch 24: val_accuracy improved from 0.56316 to 0.57895, saving model to /kaggle/working/outputs_60_40_v2/models/MobileNetV2_60_40/best_model_phase2.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 72ms/step - accuracy: 0.8612 - loss: 0.6197 - val_accuracy: 0.5789 - val_loss: 2.0623 - learning_rate: 5.0000e-05\nEpoch 25/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.8698 - loss: 0.5859\nEpoch 25: val_accuracy improved from 0.57895 to 0.58596, saving model to /kaggle/working/outputs_60_40_v2/models/MobileNetV2_60_40/best_model_phase2.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 72ms/step - accuracy: 0.8698 - loss: 0.5859 - val_accuracy: 0.5860 - val_loss: 1.8939 - learning_rate: 5.0000e-05\nEpoch 26/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.8749 - loss: 0.5708\nEpoch 26: val_accuracy improved from 0.58596 to 0.64211, saving model to /kaggle/working/outputs_60_40_v2/models/MobileNetV2_60_40/best_model_phase2.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 73ms/step - accuracy: 0.8749 - loss: 0.5707 - val_accuracy: 0.6421 - val_loss: 1.4760 - learning_rate: 5.0000e-05\nEpoch 27/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.8822 - loss: 0.5467\nEpoch 27: val_accuracy did not improve from 0.64211\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 72ms/step - accuracy: 0.8822 - loss: 0.5468 - val_accuracy: 0.6281 - val_loss: 1.6393 - learning_rate: 5.0000e-05\nEpoch 28/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.8916 - loss: 0.5180\nEpoch 28: val_accuracy did not improve from 0.64211\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 73ms/step - accuracy: 0.8916 - loss: 0.5181 - val_accuracy: 0.6263 - val_loss: 1.6742 - learning_rate: 5.0000e-05\nEpoch 29/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.8966 - loss: 0.5037\nEpoch 29: val_accuracy did not improve from 0.64211\n\nEpoch 29: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 72ms/step - accuracy: 0.8966 - loss: 0.5038 - val_accuracy: 0.6307 - val_loss: 1.6813 - learning_rate: 5.0000e-05\nEpoch 30/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9003 - loss: 0.5010\nEpoch 30: val_accuracy improved from 0.64211 to 0.66316, saving model to /kaggle/working/outputs_60_40_v2/models/MobileNetV2_60_40/best_model_phase2.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 73ms/step - accuracy: 0.9004 - loss: 0.5010 - val_accuracy: 0.6632 - val_loss: 1.4114 - learning_rate: 2.5000e-05\nEpoch 31/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9062 - loss: 0.4814\nEpoch 31: val_accuracy improved from 0.66316 to 0.67456, saving model to /kaggle/working/outputs_60_40_v2/models/MobileNetV2_60_40/best_model_phase2.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 73ms/step - accuracy: 0.9062 - loss: 0.4814 - val_accuracy: 0.6746 - val_loss: 1.3425 - learning_rate: 2.5000e-05\nEpoch 32/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.9105 - loss: 0.4597\nEpoch 32: val_accuracy improved from 0.67456 to 0.68070, saving model to /kaggle/working/outputs_60_40_v2/models/MobileNetV2_60_40/best_model_phase2.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 73ms/step - accuracy: 0.9104 - loss: 0.4597 - val_accuracy: 0.6807 - val_loss: 1.3809 - learning_rate: 2.5000e-05\nEpoch 33/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.9165 - loss: 0.4475\nEpoch 33: val_accuracy did not improve from 0.68070\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 73ms/step - accuracy: 0.9165 - loss: 0.4475 - val_accuracy: 0.6781 - val_loss: 1.4470 - learning_rate: 2.5000e-05\nEpoch 34/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.9164 - loss: 0.4439\nEpoch 34: val_accuracy did not improve from 0.68070\n\nEpoch 34: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 73ms/step - accuracy: 0.9164 - loss: 0.4439 - val_accuracy: 0.6579 - val_loss: 1.5901 - learning_rate: 2.5000e-05\nEpoch 35/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.9180 - loss: 0.4316\nEpoch 35: val_accuracy did not improve from 0.68070\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 76ms/step - accuracy: 0.9181 - loss: 0.4316 - val_accuracy: 0.6667 - val_loss: 1.5180 - learning_rate: 1.2500e-05\nEpoch 36/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.9207 - loss: 0.4261\nEpoch 36: val_accuracy did not improve from 0.68070\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 74ms/step - accuracy: 0.9207 - loss: 0.4261 - val_accuracy: 0.6535 - val_loss: 1.6451 - learning_rate: 1.2500e-05\nEpoch 37/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.9158 - loss: 0.4231\nEpoch 37: val_accuracy did not improve from 0.68070\n\nEpoch 37: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 72ms/step - accuracy: 0.9159 - loss: 0.4231 - val_accuracy: 0.6456 - val_loss: 1.6807 - learning_rate: 1.2500e-05\nEpoch 38/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9294 - loss: 0.4030\nEpoch 38: val_accuracy did not improve from 0.68070\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 71ms/step - accuracy: 0.9294 - loss: 0.4030 - val_accuracy: 0.6579 - val_loss: 1.6338 - learning_rate: 6.2500e-06\nEpoch 39/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9317 - loss: 0.3847\nEpoch 39: val_accuracy did not improve from 0.68070\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 71ms/step - accuracy: 0.9317 - loss: 0.3848 - val_accuracy: 0.6702 - val_loss: 1.5543 - learning_rate: 6.2500e-06\nEpoch 40/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9274 - loss: 0.3932\nEpoch 40: val_accuracy did not improve from 0.68070\n\nEpoch 40: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 70ms/step - accuracy: 0.9273 - loss: 0.3932 - val_accuracy: 0.6623 - val_loss: 1.6002 - learning_rate: 6.2500e-06\nEpoch 41/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9295 - loss: 0.3953\nEpoch 41: val_accuracy did not improve from 0.68070\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 71ms/step - accuracy: 0.9295 - loss: 0.3953 - val_accuracy: 0.6702 - val_loss: 1.5967 - learning_rate: 3.1250e-06\nEpoch 42/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9326 - loss: 0.3906\nEpoch 42: val_accuracy did not improve from 0.68070\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 71ms/step - accuracy: 0.9326 - loss: 0.3906 - val_accuracy: 0.6684 - val_loss: 1.5508 - learning_rate: 3.1250e-06\nEpoch 43/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9323 - loss: 0.3845\nEpoch 43: val_accuracy did not improve from 0.68070\n\nEpoch 43: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 72ms/step - accuracy: 0.9323 - loss: 0.3846 - val_accuracy: 0.6649 - val_loss: 1.6158 - learning_rate: 3.1250e-06\nEpoch 44/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9274 - loss: 0.3962\nEpoch 44: val_accuracy did not improve from 0.68070\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 71ms/step - accuracy: 0.9274 - loss: 0.3962 - val_accuracy: 0.6614 - val_loss: 1.6355 - learning_rate: 1.5625e-06\nEpoch 45/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.9341 - loss: 0.3856\nEpoch 45: val_accuracy did not improve from 0.68070\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 73ms/step - accuracy: 0.9341 - loss: 0.3857 - val_accuracy: 0.6632 - val_loss: 1.6101 - learning_rate: 1.5625e-06\nEpoch 46/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.9339 - loss: 0.3803\nEpoch 46: val_accuracy did not improve from 0.68070\n\nEpoch 46: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 76ms/step - accuracy: 0.9340 - loss: 0.3803 - val_accuracy: 0.6596 - val_loss: 1.6318 - learning_rate: 1.5625e-06\nEpoch 47/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.9280 - loss: 0.3983\nEpoch 47: val_accuracy did not improve from 0.68070\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 75ms/step - accuracy: 0.9280 - loss: 0.3983 - val_accuracy: 0.6588 - val_loss: 1.6460 - learning_rate: 7.8125e-07\nEpoch 48/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.9320 - loss: 0.3876\nEpoch 48: val_accuracy did not improve from 0.68070\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 75ms/step - accuracy: 0.9320 - loss: 0.3876 - val_accuracy: 0.6588 - val_loss: 1.6387 - learning_rate: 7.8125e-07\nEpoch 49/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.9377 - loss: 0.3647\nEpoch 49: val_accuracy did not improve from 0.68070\n\nEpoch 49: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 74ms/step - accuracy: 0.9377 - loss: 0.3648 - val_accuracy: 0.6605 - val_loss: 1.6405 - learning_rate: 7.8125e-07\nEpoch 50/50\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.9374 - loss: 0.3844\nEpoch 50: val_accuracy did not improve from 0.68070\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 73ms/step - accuracy: 0.9374 - loss: 0.3844 - val_accuracy: 0.6579 - val_loss: 1.6417 - learning_rate: 3.9062e-07\nPhase 2 completed in 16.56 minutes\nBest model saved: /kaggle/working/outputs_60_40_v2/models/MobileNetV2_60_40/best_model_phase2.h5\n\nLoading best model from Phase 2...\n\nComprehensive evaluation: MobileNetV2 on 60_40\nAccuracy: 68.26%\nF1-Score (Macro): 0.6590\nPrecision (Macro): 0.7713\nRecall (Macro): 0.6826\nROC-AUC (Macro): 0.9910\nTraining analysis saved: /kaggle/working/outputs_60_40_v2/plots/MobileNetV2_60_40/training_analysis.png\nConfusion matrix analysis saved: /kaggle/working/outputs_60_40_v2/plots/MobileNetV2_60_40/confusion_matrix_analysis.png\n\nMobileNetV2 Summary:\n  Test Accuracy: 68.26%\n  F1-Score: 0.6590\n  Total Training Time: 20.9 minutes\n\n==========================================================================================\nMODEL: InceptionV3\n==========================================================================================\nBuilding InceptionV3 with enhanced architecture...\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m87910968/87910968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nModel ready: 23,001,158 parameters\n\nPreparing data pipelines...\n\nPHASE 1: Training classifier head (backbone frozen)\nEpochs: 10, Learning Rate: 0.001\nTrainable parameters: 1,194,278\nEpoch 1/10\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.1401 - loss: 3.7186\nEpoch 1: val_accuracy improved from -inf to 0.36667, saving model to /kaggle/working/outputs_60_40_v2/models/InceptionV3_60_40/best_model_phase1.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 129ms/step - accuracy: 0.1403 - loss: 3.7171 - val_accuracy: 0.3667 - val_loss: 2.3536 - learning_rate: 0.0010\nEpoch 2/10\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.2798 - loss: 2.5671\nEpoch 2: val_accuracy improved from 0.36667 to 0.41228, saving model to /kaggle/working/outputs_60_40_v2/models/InceptionV3_60_40/best_model_phase1.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 75ms/step - accuracy: 0.2799 - loss: 2.5667 - val_accuracy: 0.4123 - val_loss: 1.9937 - learning_rate: 0.0010\nEpoch 3/10\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.3425 - loss: 2.2941\nEpoch 3: val_accuracy improved from 0.41228 to 0.44035, saving model to /kaggle/working/outputs_60_40_v2/models/InceptionV3_60_40/best_model_phase1.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 75ms/step - accuracy: 0.3425 - loss: 2.2939 - val_accuracy: 0.4404 - val_loss: 1.9602 - learning_rate: 0.0010\nEpoch 4/10\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.3726 - loss: 2.1546\nEpoch 4: val_accuracy improved from 0.44035 to 0.44825, saving model to /kaggle/working/outputs_60_40_v2/models/InceptionV3_60_40/best_model_phase1.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 74ms/step - accuracy: 0.3726 - loss: 2.1545 - val_accuracy: 0.4482 - val_loss: 1.8797 - learning_rate: 0.0010\nEpoch 5/10\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.4002 - loss: 2.0835\nEpoch 5: val_accuracy improved from 0.44825 to 0.47895, saving model to /kaggle/working/outputs_60_40_v2/models/InceptionV3_60_40/best_model_phase1.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 73ms/step - accuracy: 0.4001 - loss: 2.0835 - val_accuracy: 0.4789 - val_loss: 1.7846 - learning_rate: 0.0010\nEpoch 6/10\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.4051 - loss: 2.0323\nEpoch 6: val_accuracy improved from 0.47895 to 0.48772, saving model to /kaggle/working/outputs_60_40_v2/models/InceptionV3_60_40/best_model_phase1.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 73ms/step - accuracy: 0.4051 - loss: 2.0322 - val_accuracy: 0.4877 - val_loss: 1.7523 - learning_rate: 0.0010\nEpoch 7/10\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.4249 - loss: 2.0053\nEpoch 7: val_accuracy did not improve from 0.48772\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 71ms/step - accuracy: 0.4250 - loss: 2.0053 - val_accuracy: 0.4789 - val_loss: 1.7936 - learning_rate: 0.0010\nEpoch 8/10\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.4448 - loss: 1.9744\nEpoch 8: val_accuracy improved from 0.48772 to 0.50439, saving model to /kaggle/working/outputs_60_40_v2/models/InceptionV3_60_40/best_model_phase1.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 73ms/step - accuracy: 0.4448 - loss: 1.9742 - val_accuracy: 0.5044 - val_loss: 1.7197 - learning_rate: 0.0010\nEpoch 9/10\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.4648 - loss: 1.9133\nEpoch 9: val_accuracy improved from 0.50439 to 0.50877, saving model to /kaggle/working/outputs_60_40_v2/models/InceptionV3_60_40/best_model_phase1.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 73ms/step - accuracy: 0.4647 - loss: 1.9132 - val_accuracy: 0.5088 - val_loss: 1.7467 - learning_rate: 0.0010\nEpoch 10/10\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.4658 - loss: 1.8742\nEpoch 10: val_accuracy did not improve from 0.50877\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 71ms/step - accuracy: 0.4658 - loss: 1.8743 - val_accuracy: 0.5009 - val_loss: 1.8064 - learning_rate: 0.0010\nPhase 1 completed in 4.56 minutes\nBest model saved: /kaggle/working/outputs_60_40_v2/models/InceptionV3_60_40/best_model_phase1.h5\n\nPHASE 2: Fine-tuning entire model (backbone unfrozen)\nEpochs: 40, Learning Rate: 0.0001\nUnfreezing last 156/311 layers of backbone\nTrainable parameters: 17,983,718\nEpoch 11/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.3902 - loss: 2.1933\nEpoch 11: val_accuracy improved from -inf to 0.42281, saving model to /kaggle/working/outputs_60_40_v2/models/InceptionV3_60_40/best_model_phase2.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 179ms/step - accuracy: 0.3904 - loss: 2.1926 - val_accuracy: 0.4228 - val_loss: 2.3175 - learning_rate: 1.0000e-04\nEpoch 12/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.5519 - loss: 1.5867\nEpoch 12: val_accuracy improved from 0.42281 to 0.48158, saving model to /kaggle/working/outputs_60_40_v2/models/InceptionV3_60_40/best_model_phase2.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 94ms/step - accuracy: 0.5520 - loss: 1.5865 - val_accuracy: 0.4816 - val_loss: 2.0286 - learning_rate: 1.0000e-04\nEpoch 13/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.6232 - loss: 1.3774\nEpoch 13: val_accuracy improved from 0.48158 to 0.56316, saving model to /kaggle/working/outputs_60_40_v2/models/InceptionV3_60_40/best_model_phase2.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 94ms/step - accuracy: 0.6233 - loss: 1.3773 - val_accuracy: 0.5632 - val_loss: 1.5637 - learning_rate: 1.0000e-04\nEpoch 14/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.6824 - loss: 1.2080\nEpoch 14: val_accuracy did not improve from 0.56316\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 91ms/step - accuracy: 0.6824 - loss: 1.2080 - val_accuracy: 0.5395 - val_loss: 1.7665 - learning_rate: 1.0000e-04\nEpoch 15/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.7129 - loss: 1.1043\nEpoch 15: val_accuracy did not improve from 0.56316\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 91ms/step - accuracy: 0.7129 - loss: 1.1043 - val_accuracy: 0.5351 - val_loss: 1.8122 - learning_rate: 1.0000e-04\nEpoch 16/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.7524 - loss: 0.9869\nEpoch 16: val_accuracy improved from 0.56316 to 0.57456, saving model to /kaggle/working/outputs_60_40_v2/models/InceptionV3_60_40/best_model_phase2.h5\n\nEpoch 16: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 95ms/step - accuracy: 0.7523 - loss: 0.9869 - val_accuracy: 0.5746 - val_loss: 1.6733 - learning_rate: 1.0000e-04\nEpoch 17/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.7704 - loss: 0.9085\nEpoch 17: val_accuracy did not improve from 0.57456\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 91ms/step - accuracy: 0.7704 - loss: 0.9085 - val_accuracy: 0.5474 - val_loss: 1.8428 - learning_rate: 5.0000e-05\nEpoch 18/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.7957 - loss: 0.8527\nEpoch 18: val_accuracy did not improve from 0.57456\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 90ms/step - accuracy: 0.7957 - loss: 0.8526 - val_accuracy: 0.5711 - val_loss: 1.7610 - learning_rate: 5.0000e-05\nEpoch 19/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.8168 - loss: 0.7751\nEpoch 19: val_accuracy improved from 0.57456 to 0.58860, saving model to /kaggle/working/outputs_60_40_v2/models/InceptionV3_60_40/best_model_phase2.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 93ms/step - accuracy: 0.8168 - loss: 0.7751 - val_accuracy: 0.5886 - val_loss: 1.5594 - learning_rate: 5.0000e-05\nEpoch 20/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.8334 - loss: 0.7338\nEpoch 20: val_accuracy improved from 0.58860 to 0.59474, saving model to /kaggle/working/outputs_60_40_v2/models/InceptionV3_60_40/best_model_phase2.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 93ms/step - accuracy: 0.8334 - loss: 0.7338 - val_accuracy: 0.5947 - val_loss: 1.7627 - learning_rate: 5.0000e-05\nEpoch 21/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.8426 - loss: 0.6936\nEpoch 21: val_accuracy did not improve from 0.59474\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 90ms/step - accuracy: 0.8426 - loss: 0.6936 - val_accuracy: 0.5675 - val_loss: 1.9707 - learning_rate: 5.0000e-05\nEpoch 22/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.8536 - loss: 0.6722\nEpoch 22: val_accuracy improved from 0.59474 to 0.59825, saving model to /kaggle/working/outputs_60_40_v2/models/InceptionV3_60_40/best_model_phase2.h5\n\nEpoch 22: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 94ms/step - accuracy: 0.8536 - loss: 0.6722 - val_accuracy: 0.5982 - val_loss: 1.7380 - learning_rate: 5.0000e-05\nEpoch 23/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.8734 - loss: 0.6305\nEpoch 23: val_accuracy improved from 0.59825 to 0.62719, saving model to /kaggle/working/outputs_60_40_v2/models/InceptionV3_60_40/best_model_phase2.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 93ms/step - accuracy: 0.8734 - loss: 0.6305 - val_accuracy: 0.6272 - val_loss: 1.6524 - learning_rate: 2.5000e-05\nEpoch 24/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.8836 - loss: 0.5795\nEpoch 24: val_accuracy improved from 0.62719 to 0.63860, saving model to /kaggle/working/outputs_60_40_v2/models/InceptionV3_60_40/best_model_phase2.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 93ms/step - accuracy: 0.8836 - loss: 0.5795 - val_accuracy: 0.6386 - val_loss: 1.6914 - learning_rate: 2.5000e-05\nEpoch 25/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.8948 - loss: 0.5395\nEpoch 25: val_accuracy did not improve from 0.63860\n\nEpoch 25: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 89ms/step - accuracy: 0.8948 - loss: 0.5395 - val_accuracy: 0.6114 - val_loss: 1.7288 - learning_rate: 2.5000e-05\nEpoch 26/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9007 - loss: 0.5239\nEpoch 26: val_accuracy did not improve from 0.63860\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 90ms/step - accuracy: 0.9007 - loss: 0.5239 - val_accuracy: 0.6342 - val_loss: 1.6659 - learning_rate: 1.2500e-05\nEpoch 27/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9046 - loss: 0.5001\nEpoch 27: val_accuracy did not improve from 0.63860\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 89ms/step - accuracy: 0.9046 - loss: 0.5001 - val_accuracy: 0.6237 - val_loss: 1.7662 - learning_rate: 1.2500e-05\nEpoch 28/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9114 - loss: 0.4761\nEpoch 28: val_accuracy did not improve from 0.63860\n\nEpoch 28: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 89ms/step - accuracy: 0.9114 - loss: 0.4761 - val_accuracy: 0.6386 - val_loss: 1.6813 - learning_rate: 1.2500e-05\nEpoch 29/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9099 - loss: 0.4771\nEpoch 29: val_accuracy did not improve from 0.63860\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 89ms/step - accuracy: 0.9099 - loss: 0.4771 - val_accuracy: 0.6386 - val_loss: 1.7178 - learning_rate: 6.2500e-06\nEpoch 30/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9119 - loss: 0.4804\nEpoch 30: val_accuracy improved from 0.63860 to 0.64035, saving model to /kaggle/working/outputs_60_40_v2/models/InceptionV3_60_40/best_model_phase2.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 92ms/step - accuracy: 0.9119 - loss: 0.4804 - val_accuracy: 0.6404 - val_loss: 1.6725 - learning_rate: 6.2500e-06\nEpoch 31/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9162 - loss: 0.4676\nEpoch 31: val_accuracy improved from 0.64035 to 0.64386, saving model to /kaggle/working/outputs_60_40_v2/models/InceptionV3_60_40/best_model_phase2.h5\n\nEpoch 31: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 93ms/step - accuracy: 0.9162 - loss: 0.4677 - val_accuracy: 0.6439 - val_loss: 1.7154 - learning_rate: 6.2500e-06\nEpoch 32/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9215 - loss: 0.4585\nEpoch 32: val_accuracy did not improve from 0.64386\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 89ms/step - accuracy: 0.9215 - loss: 0.4585 - val_accuracy: 0.6386 - val_loss: 1.7325 - learning_rate: 3.1250e-06\nEpoch 33/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9269 - loss: 0.4408\nEpoch 33: val_accuracy improved from 0.64386 to 0.64561, saving model to /kaggle/working/outputs_60_40_v2/models/InceptionV3_60_40/best_model_phase2.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 92ms/step - accuracy: 0.9269 - loss: 0.4408 - val_accuracy: 0.6456 - val_loss: 1.6683 - learning_rate: 3.1250e-06\nEpoch 34/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9256 - loss: 0.4513\nEpoch 34: val_accuracy did not improve from 0.64561\n\nEpoch 34: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 90ms/step - accuracy: 0.9256 - loss: 0.4513 - val_accuracy: 0.6421 - val_loss: 1.7299 - learning_rate: 3.1250e-06\nEpoch 35/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.9284 - loss: 0.4406\nEpoch 35: val_accuracy did not improve from 0.64561\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 89ms/step - accuracy: 0.9284 - loss: 0.4406 - val_accuracy: 0.6333 - val_loss: 1.7699 - learning_rate: 1.5625e-06\nEpoch 36/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9294 - loss: 0.4343\nEpoch 36: val_accuracy did not improve from 0.64561\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 90ms/step - accuracy: 0.9294 - loss: 0.4343 - val_accuracy: 0.6351 - val_loss: 1.7470 - learning_rate: 1.5625e-06\nEpoch 37/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9261 - loss: 0.4430\nEpoch 37: val_accuracy did not improve from 0.64561\n\nEpoch 37: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 90ms/step - accuracy: 0.9261 - loss: 0.4430 - val_accuracy: 0.6377 - val_loss: 1.7351 - learning_rate: 1.5625e-06\nEpoch 38/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9265 - loss: 0.4470\nEpoch 38: val_accuracy did not improve from 0.64561\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 90ms/step - accuracy: 0.9266 - loss: 0.4469 - val_accuracy: 0.6412 - val_loss: 1.7441 - learning_rate: 7.8125e-07\nEpoch 39/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.9286 - loss: 0.4262\nEpoch 39: val_accuracy did not improve from 0.64561\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 90ms/step - accuracy: 0.9286 - loss: 0.4262 - val_accuracy: 0.6430 - val_loss: 1.7335 - learning_rate: 7.8125e-07\nEpoch 40/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9348 - loss: 0.4210\nEpoch 40: val_accuracy did not improve from 0.64561\n\nEpoch 40: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 90ms/step - accuracy: 0.9348 - loss: 0.4210 - val_accuracy: 0.6377 - val_loss: 1.7378 - learning_rate: 7.8125e-07\nEpoch 41/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9195 - loss: 0.4422\nEpoch 41: val_accuracy did not improve from 0.64561\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 90ms/step - accuracy: 0.9195 - loss: 0.4422 - val_accuracy: 0.6404 - val_loss: 1.7456 - learning_rate: 3.9062e-07\nEpoch 42/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9307 - loss: 0.4284\nEpoch 42: val_accuracy did not improve from 0.64561\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 90ms/step - accuracy: 0.9306 - loss: 0.4284 - val_accuracy: 0.6395 - val_loss: 1.7307 - learning_rate: 3.9062e-07\nEpoch 43/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.9248 - loss: 0.4342\nEpoch 43: val_accuracy did not improve from 0.64561\n\nEpoch 43: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 90ms/step - accuracy: 0.9248 - loss: 0.4342 - val_accuracy: 0.6421 - val_loss: 1.7262 - learning_rate: 3.9062e-07\nEpoch 44/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.9288 - loss: 0.4296\nEpoch 44: val_accuracy did not improve from 0.64561\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 90ms/step - accuracy: 0.9288 - loss: 0.4296 - val_accuracy: 0.6412 - val_loss: 1.7348 - learning_rate: 1.9531e-07\nEpoch 45/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.9247 - loss: 0.4305\nEpoch 45: val_accuracy did not improve from 0.64561\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 93ms/step - accuracy: 0.9247 - loss: 0.4305 - val_accuracy: 0.6404 - val_loss: 1.7310 - learning_rate: 1.9531e-07\nEpoch 46/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9286 - loss: 0.4275\nEpoch 46: val_accuracy did not improve from 0.64561\n\nEpoch 46: ReduceLROnPlateau reducing learning rate to 1e-07.\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 89ms/step - accuracy: 0.9286 - loss: 0.4275 - val_accuracy: 0.6395 - val_loss: 1.7370 - learning_rate: 1.9531e-07\nEpoch 47/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9333 - loss: 0.4198\nEpoch 47: val_accuracy did not improve from 0.64561\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 90ms/step - accuracy: 0.9333 - loss: 0.4198 - val_accuracy: 0.6377 - val_loss: 1.7426 - learning_rate: 1.0000e-07\nEpoch 48/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.9260 - loss: 0.4303\nEpoch 48: val_accuracy did not improve from 0.64561\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 91ms/step - accuracy: 0.9260 - loss: 0.4304 - val_accuracy: 0.6412 - val_loss: 1.7462 - learning_rate: 1.0000e-07\nEpoch 49/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.9309 - loss: 0.4239\nEpoch 49: val_accuracy did not improve from 0.64561\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 90ms/step - accuracy: 0.9309 - loss: 0.4239 - val_accuracy: 0.6395 - val_loss: 1.7300 - learning_rate: 1.0000e-07\nEpoch 50/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.9274 - loss: 0.4237\nEpoch 50: val_accuracy did not improve from 0.64561\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 90ms/step - accuracy: 0.9274 - loss: 0.4237 - val_accuracy: 0.6386 - val_loss: 1.7379 - learning_rate: 1.0000e-07\nPhase 2 completed in 20.91 minutes\nBest model saved: /kaggle/working/outputs_60_40_v2/models/InceptionV3_60_40/best_model_phase2.h5\n\nLoading best model from Phase 2...\n\nComprehensive evaluation: InceptionV3 on 60_40\nAccuracy: 65.01%\nF1-Score (Macro): 0.6266\nPrecision (Macro): 0.7544\nRecall (Macro): 0.6501\nROC-AUC (Macro): 0.9865\nTraining analysis saved: /kaggle/working/outputs_60_40_v2/plots/InceptionV3_60_40/training_analysis.png\nConfusion matrix analysis saved: /kaggle/working/outputs_60_40_v2/plots/InceptionV3_60_40/confusion_matrix_analysis.png\n\nInceptionV3 Summary:\n  Test Accuracy: 65.01%\n  F1-Score: 0.6266\n  Total Training Time: 25.5 minutes\n\n==========================================================================================\nMODEL: DenseNet121\n==========================================================================================\nBuilding DenseNet121 with enhanced architecture...\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m29084464/29084464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nModel ready: 7,707,494 parameters\n\nPreparing data pipelines...\n\nPHASE 1: Training classifier head (backbone frozen)\nEpochs: 10, Learning Rate: 0.001\nTrainable parameters: 667,942\nEpoch 1/10\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.1974 - loss: 3.0587\nEpoch 1: val_accuracy improved from -inf to 0.44035, saving model to /kaggle/working/outputs_60_40_v2/models/DenseNet121_60_40/best_model_phase1.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 194ms/step - accuracy: 0.1977 - loss: 3.0570 - val_accuracy: 0.4404 - val_loss: 1.8593 - learning_rate: 0.0010\nEpoch 2/10\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.4634 - loss: 1.8022\nEpoch 2: val_accuracy improved from 0.44035 to 0.50175, saving model to /kaggle/working/outputs_60_40_v2/models/DenseNet121_60_40/best_model_phase1.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 92ms/step - accuracy: 0.4635 - loss: 1.8019 - val_accuracy: 0.5018 - val_loss: 1.5553 - learning_rate: 0.0010\nEpoch 3/10\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5444 - loss: 1.5221\nEpoch 3: val_accuracy did not improve from 0.50175\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 90ms/step - accuracy: 0.5444 - loss: 1.5218 - val_accuracy: 0.5000 - val_loss: 1.6082 - learning_rate: 0.0010\nEpoch 4/10\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.5810 - loss: 1.3850\nEpoch 4: val_accuracy improved from 0.50175 to 0.53070, saving model to /kaggle/working/outputs_60_40_v2/models/DenseNet121_60_40/best_model_phase1.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 93ms/step - accuracy: 0.5811 - loss: 1.3849 - val_accuracy: 0.5307 - val_loss: 1.4355 - learning_rate: 0.0010\nEpoch 5/10\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.6115 - loss: 1.3195\nEpoch 5: val_accuracy improved from 0.53070 to 0.57193, saving model to /kaggle/working/outputs_60_40_v2/models/DenseNet121_60_40/best_model_phase1.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 92ms/step - accuracy: 0.6115 - loss: 1.3194 - val_accuracy: 0.5719 - val_loss: 1.3428 - learning_rate: 0.0010\nEpoch 6/10\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.6379 - loss: 1.2453\nEpoch 6: val_accuracy did not improve from 0.57193\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 90ms/step - accuracy: 0.6379 - loss: 1.2453 - val_accuracy: 0.5596 - val_loss: 1.3945 - learning_rate: 0.0010\nEpoch 7/10\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.6422 - loss: 1.2338\nEpoch 7: val_accuracy did not improve from 0.57193\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 90ms/step - accuracy: 0.6422 - loss: 1.2337 - val_accuracy: 0.5254 - val_loss: 1.5540 - learning_rate: 0.0010\nEpoch 8/10\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.6650 - loss: 1.1744\nEpoch 8: val_accuracy did not improve from 0.57193\n\nEpoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 89ms/step - accuracy: 0.6650 - loss: 1.1745 - val_accuracy: 0.5719 - val_loss: 1.3776 - learning_rate: 0.0010\nEpoch 9/10\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.6841 - loss: 1.1191\nEpoch 9: val_accuracy improved from 0.57193 to 0.58684, saving model to /kaggle/working/outputs_60_40_v2/models/DenseNet121_60_40/best_model_phase1.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 92ms/step - accuracy: 0.6842 - loss: 1.1190 - val_accuracy: 0.5868 - val_loss: 1.3034 - learning_rate: 5.0000e-04\nEpoch 10/10\n\u001b[1m320/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7015 - loss: 1.0621\nEpoch 10: val_accuracy did not improve from 0.58684\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 90ms/step - accuracy: 0.7015 - loss: 1.0620 - val_accuracy: 0.5614 - val_loss: 1.5009 - learning_rate: 5.0000e-04\nPhase 1 completed in 5.98 minutes\nBest model saved: /kaggle/working/outputs_60_40_v2/models/DenseNet121_60_40/best_model_phase1.h5\n\nPHASE 2: Fine-tuning entire model (backbone unfrozen)\nEpochs: 40, Learning Rate: 0.0001\nUnfreezing last 214/427 layers of backbone\nTrainable parameters: 5,299,814\nEpoch 11/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - accuracy: 0.6313 - loss: 1.3062\nEpoch 11: val_accuracy improved from -inf to 0.47807, saving model to /kaggle/working/outputs_60_40_v2/models/DenseNet121_60_40/best_model_phase2.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 288ms/step - accuracy: 0.6314 - loss: 1.3058 - val_accuracy: 0.4781 - val_loss: 2.1065 - learning_rate: 1.0000e-04\nEpoch 12/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.7318 - loss: 0.9625\nEpoch 12: val_accuracy improved from 0.47807 to 0.53596, saving model to /kaggle/working/outputs_60_40_v2/models/DenseNet121_60_40/best_model_phase2.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 101ms/step - accuracy: 0.7319 - loss: 0.9624 - val_accuracy: 0.5360 - val_loss: 1.7498 - learning_rate: 1.0000e-04\nEpoch 13/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.7706 - loss: 0.8443\nEpoch 13: val_accuracy improved from 0.53596 to 0.60000, saving model to /kaggle/working/outputs_60_40_v2/models/DenseNet121_60_40/best_model_phase2.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 101ms/step - accuracy: 0.7706 - loss: 0.8443 - val_accuracy: 0.6000 - val_loss: 1.4568 - learning_rate: 1.0000e-04\nEpoch 14/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.7979 - loss: 0.7625\nEpoch 14: val_accuracy improved from 0.60000 to 0.61053, saving model to /kaggle/working/outputs_60_40_v2/models/DenseNet121_60_40/best_model_phase2.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 100ms/step - accuracy: 0.7979 - loss: 0.7624 - val_accuracy: 0.6105 - val_loss: 1.4819 - learning_rate: 1.0000e-04\nEpoch 15/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.8245 - loss: 0.6834\nEpoch 15: val_accuracy did not improve from 0.61053\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 97ms/step - accuracy: 0.8245 - loss: 0.6835 - val_accuracy: 0.5825 - val_loss: 1.5952 - learning_rate: 1.0000e-04\nEpoch 16/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.8385 - loss: 0.6368\nEpoch 16: val_accuracy improved from 0.61053 to 0.62105, saving model to /kaggle/working/outputs_60_40_v2/models/DenseNet121_60_40/best_model_phase2.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 100ms/step - accuracy: 0.8385 - loss: 0.6368 - val_accuracy: 0.6211 - val_loss: 1.3842 - learning_rate: 1.0000e-04\nEpoch 17/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.8370 - loss: 0.6348\nEpoch 17: val_accuracy did not improve from 0.62105\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 97ms/step - accuracy: 0.8370 - loss: 0.6348 - val_accuracy: 0.5904 - val_loss: 1.6119 - learning_rate: 1.0000e-04\nEpoch 18/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.8498 - loss: 0.6179\nEpoch 18: val_accuracy did not improve from 0.62105\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 95ms/step - accuracy: 0.8498 - loss: 0.6179 - val_accuracy: 0.5912 - val_loss: 1.5399 - learning_rate: 1.0000e-04\nEpoch 19/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.8512 - loss: 0.5898\nEpoch 19: val_accuracy improved from 0.62105 to 0.62632, saving model to /kaggle/working/outputs_60_40_v2/models/DenseNet121_60_40/best_model_phase2.h5\n\nEpoch 19: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 99ms/step - accuracy: 0.8512 - loss: 0.5898 - val_accuracy: 0.6263 - val_loss: 1.4714 - learning_rate: 1.0000e-04\nEpoch 20/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.8795 - loss: 0.5115\nEpoch 20: val_accuracy improved from 0.62632 to 0.66140, saving model to /kaggle/working/outputs_60_40_v2/models/DenseNet121_60_40/best_model_phase2.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 100ms/step - accuracy: 0.8795 - loss: 0.5114 - val_accuracy: 0.6614 - val_loss: 1.2647 - learning_rate: 5.0000e-05\nEpoch 21/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.8896 - loss: 0.4724\nEpoch 21: val_accuracy did not improve from 0.66140\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 95ms/step - accuracy: 0.8896 - loss: 0.4724 - val_accuracy: 0.6596 - val_loss: 1.3332 - learning_rate: 5.0000e-05\nEpoch 22/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.8997 - loss: 0.4456\nEpoch 22: val_accuracy did not improve from 0.66140\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 96ms/step - accuracy: 0.8997 - loss: 0.4456 - val_accuracy: 0.6482 - val_loss: 1.4188 - learning_rate: 5.0000e-05\nEpoch 23/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9054 - loss: 0.4295\nEpoch 23: val_accuracy did not improve from 0.66140\n\nEpoch 23: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 96ms/step - accuracy: 0.9053 - loss: 0.4295 - val_accuracy: 0.6316 - val_loss: 1.5928 - learning_rate: 5.0000e-05\nEpoch 24/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9176 - loss: 0.4102\nEpoch 24: val_accuracy improved from 0.66140 to 0.67368, saving model to /kaggle/working/outputs_60_40_v2/models/DenseNet121_60_40/best_model_phase2.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 99ms/step - accuracy: 0.9176 - loss: 0.4102 - val_accuracy: 0.6737 - val_loss: 1.4021 - learning_rate: 2.5000e-05\nEpoch 25/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9235 - loss: 0.3852\nEpoch 25: val_accuracy improved from 0.67368 to 0.68158, saving model to /kaggle/working/outputs_60_40_v2/models/DenseNet121_60_40/best_model_phase2.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 99ms/step - accuracy: 0.9235 - loss: 0.3853 - val_accuracy: 0.6816 - val_loss: 1.3815 - learning_rate: 2.5000e-05\nEpoch 26/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9277 - loss: 0.3631\nEpoch 26: val_accuracy improved from 0.68158 to 0.69386, saving model to /kaggle/working/outputs_60_40_v2/models/DenseNet121_60_40/best_model_phase2.h5\n\nEpoch 26: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 99ms/step - accuracy: 0.9277 - loss: 0.3631 - val_accuracy: 0.6939 - val_loss: 1.2819 - learning_rate: 2.5000e-05\nEpoch 27/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.9309 - loss: 0.3508\nEpoch 27: val_accuracy did not improve from 0.69386\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 95ms/step - accuracy: 0.9309 - loss: 0.3508 - val_accuracy: 0.6895 - val_loss: 1.3016 - learning_rate: 1.2500e-05\nEpoch 28/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9379 - loss: 0.3300\nEpoch 28: val_accuracy did not improve from 0.69386\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 95ms/step - accuracy: 0.9379 - loss: 0.3300 - val_accuracy: 0.6912 - val_loss: 1.2811 - learning_rate: 1.2500e-05\nEpoch 29/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9308 - loss: 0.3464\nEpoch 29: val_accuracy improved from 0.69386 to 0.69825, saving model to /kaggle/working/outputs_60_40_v2/models/DenseNet121_60_40/best_model_phase2.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 99ms/step - accuracy: 0.9308 - loss: 0.3464 - val_accuracy: 0.6982 - val_loss: 1.2578 - learning_rate: 1.2500e-05\nEpoch 30/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.9378 - loss: 0.3358\nEpoch 30: val_accuracy did not improve from 0.69825\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 96ms/step - accuracy: 0.9378 - loss: 0.3358 - val_accuracy: 0.6860 - val_loss: 1.3689 - learning_rate: 1.2500e-05\nEpoch 31/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.9350 - loss: 0.3362\nEpoch 31: val_accuracy did not improve from 0.69825\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 94ms/step - accuracy: 0.9350 - loss: 0.3362 - val_accuracy: 0.6886 - val_loss: 1.3151 - learning_rate: 1.2500e-05\nEpoch 32/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9345 - loss: 0.3391\nEpoch 32: val_accuracy did not improve from 0.69825\n\nEpoch 32: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 95ms/step - accuracy: 0.9345 - loss: 0.3390 - val_accuracy: 0.6868 - val_loss: 1.3660 - learning_rate: 1.2500e-05\nEpoch 33/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.9402 - loss: 0.3210\nEpoch 33: val_accuracy did not improve from 0.69825\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 95ms/step - accuracy: 0.9402 - loss: 0.3210 - val_accuracy: 0.6965 - val_loss: 1.2867 - learning_rate: 6.2500e-06\nEpoch 34/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.9392 - loss: 0.3234\nEpoch 34: val_accuracy did not improve from 0.69825\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 95ms/step - accuracy: 0.9392 - loss: 0.3234 - val_accuracy: 0.6895 - val_loss: 1.3550 - learning_rate: 6.2500e-06\nEpoch 35/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9365 - loss: 0.3252\nEpoch 35: val_accuracy did not improve from 0.69825\n\nEpoch 35: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 95ms/step - accuracy: 0.9366 - loss: 0.3251 - val_accuracy: 0.6939 - val_loss: 1.2829 - learning_rate: 6.2500e-06\nEpoch 36/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.9395 - loss: 0.3248\nEpoch 36: val_accuracy did not improve from 0.69825\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 95ms/step - accuracy: 0.9395 - loss: 0.3247 - val_accuracy: 0.6939 - val_loss: 1.3005 - learning_rate: 3.1250e-06\nEpoch 37/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9418 - loss: 0.3286\nEpoch 37: val_accuracy did not improve from 0.69825\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 95ms/step - accuracy: 0.9418 - loss: 0.3286 - val_accuracy: 0.6956 - val_loss: 1.2956 - learning_rate: 3.1250e-06\nEpoch 38/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9442 - loss: 0.3022\nEpoch 38: val_accuracy did not improve from 0.69825\n\nEpoch 38: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 95ms/step - accuracy: 0.9442 - loss: 0.3022 - val_accuracy: 0.6982 - val_loss: 1.2950 - learning_rate: 3.1250e-06\nEpoch 39/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.9465 - loss: 0.3042\nEpoch 39: val_accuracy did not improve from 0.69825\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 95ms/step - accuracy: 0.9465 - loss: 0.3043 - val_accuracy: 0.6965 - val_loss: 1.2847 - learning_rate: 1.5625e-06\nEpoch 40/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9472 - loss: 0.3095\nEpoch 40: val_accuracy did not improve from 0.69825\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 95ms/step - accuracy: 0.9471 - loss: 0.3095 - val_accuracy: 0.6965 - val_loss: 1.2985 - learning_rate: 1.5625e-06\nEpoch 41/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.9445 - loss: 0.3095\nEpoch 41: val_accuracy did not improve from 0.69825\n\nEpoch 41: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 95ms/step - accuracy: 0.9445 - loss: 0.3095 - val_accuracy: 0.6930 - val_loss: 1.2960 - learning_rate: 1.5625e-06\nEpoch 42/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9454 - loss: 0.3054\nEpoch 42: val_accuracy improved from 0.69825 to 0.70175, saving model to /kaggle/working/outputs_60_40_v2/models/DenseNet121_60_40/best_model_phase2.h5\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 98ms/step - accuracy: 0.9454 - loss: 0.3054 - val_accuracy: 0.7018 - val_loss: 1.2819 - learning_rate: 7.8125e-07\nEpoch 43/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9495 - loss: 0.2995\nEpoch 43: val_accuracy did not improve from 0.70175\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 95ms/step - accuracy: 0.9495 - loss: 0.2996 - val_accuracy: 0.7000 - val_loss: 1.2841 - learning_rate: 7.8125e-07\nEpoch 44/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.9421 - loss: 0.3084\nEpoch 44: val_accuracy did not improve from 0.70175\n\nEpoch 44: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 95ms/step - accuracy: 0.9421 - loss: 0.3083 - val_accuracy: 0.6965 - val_loss: 1.2959 - learning_rate: 7.8125e-07\nEpoch 45/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9529 - loss: 0.3001\nEpoch 45: val_accuracy did not improve from 0.70175\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 95ms/step - accuracy: 0.9529 - loss: 0.3001 - val_accuracy: 0.6947 - val_loss: 1.2932 - learning_rate: 3.9062e-07\nEpoch 46/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9488 - loss: 0.3007\nEpoch 46: val_accuracy did not improve from 0.70175\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 95ms/step - accuracy: 0.9488 - loss: 0.3007 - val_accuracy: 0.6947 - val_loss: 1.3010 - learning_rate: 3.9062e-07\nEpoch 47/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9447 - loss: 0.3054\nEpoch 47: val_accuracy did not improve from 0.70175\n\nEpoch 47: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 95ms/step - accuracy: 0.9447 - loss: 0.3054 - val_accuracy: 0.6947 - val_loss: 1.3054 - learning_rate: 3.9062e-07\nEpoch 48/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.9490 - loss: 0.2941\nEpoch 48: val_accuracy did not improve from 0.70175\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 95ms/step - accuracy: 0.9490 - loss: 0.2941 - val_accuracy: 0.6965 - val_loss: 1.2979 - learning_rate: 1.9531e-07\nEpoch 49/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.9533 - loss: 0.2849\nEpoch 49: val_accuracy did not improve from 0.70175\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 94ms/step - accuracy: 0.9533 - loss: 0.2849 - val_accuracy: 0.6965 - val_loss: 1.2943 - learning_rate: 1.9531e-07\nEpoch 50/50\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.9490 - loss: 0.2960\nEpoch 50: val_accuracy did not improve from 0.70175\n\nEpoch 50: ReduceLROnPlateau reducing learning rate to 1e-07.\n\u001b[1m321/321\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 95ms/step - accuracy: 0.9490 - loss: 0.2960 - val_accuracy: 0.6956 - val_loss: 1.2974 - learning_rate: 1.9531e-07\nPhase 2 completed in 23.41 minutes\nBest model saved: /kaggle/working/outputs_60_40_v2/models/DenseNet121_60_40/best_model_phase2.h5\n\nLoading best model from Phase 2...\n\nComprehensive evaluation: DenseNet121 on 60_40\nAccuracy: 70.17%\nF1-Score (Macro): 0.6802\nPrecision (Macro): 0.7953\nRecall (Macro): 0.7017\nROC-AUC (Macro): 0.9930\nTraining analysis saved: /kaggle/working/outputs_60_40_v2/plots/DenseNet121_60_40/training_analysis.png\nConfusion matrix analysis saved: /kaggle/working/outputs_60_40_v2/plots/DenseNet121_60_40/confusion_matrix_analysis.png\n\nDenseNet121 Summary:\n  Test Accuracy: 70.17%\n  F1-Score: 0.6802\n  Total Training Time: 29.4 minutes\n\n==========================================================================================\nTraining pipeline completed for split 60:40\nModels trained: 5/5\n==========================================================================================\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"# CELL 11: Results Summary and Analysis","metadata":{}},{"cell_type":"code","source":"if len(results_collection) > 0:\n    results_df = pd.DataFrame({\n        'Model': [r['model_name'] for r in results_collection],\n        'Split': [cfg.SPLIT_NAME] * len(results_collection),\n        'Test_Accuracy': [r['overall_accuracy'] * 100 for r in results_collection],\n        'F1_Macro': [r['f1_macro'] for r in results_collection],\n        'Precision_Macro': [r['precision_macro'] for r in results_collection],\n        'Recall_Macro': [r['recall_macro'] for r in results_collection],\n        'ROC_AUC': [r['roc_auc_macro'] for r in results_collection],\n        'Inference_ms': [r['avg_inference_time_ms'] for r in results_collection],\n        'Training_min': [r['training_time_total_min'] for r in results_collection],\n        'Parameters': [r['total_params'] for r in results_collection],\n        'GFLOPs': [r['gflops'] for r in results_collection]\n    })\n    \n    results_df_sorted = results_df.sort_values('Test_Accuracy', ascending=False)\n    \n    print(\"\\n\" + \"=\"*110)\n    print(f\"FINAL RESULTS SUMMARY - Split {cfg.TRAIN_RATIO}:{cfg.TEST_RATIO}\")\n    print(\"=\"*110)\n    print(results_df_sorted.to_string(index=False))\n    print(\"=\"*110)\n    \n    best_model = results_df_sorted.iloc[0]\n    print(f\"\\nBest Model: {best_model['Model']}\")\n    print(f\"Test Accuracy: {best_model['Test_Accuracy']:.2f}%\")\n    print(f\"F1-Score: {best_model['F1_Macro']:.4f}\")\n    print(f\"Training Time: {best_model['Training_min']:.1f} minutes\")\n    \n    csv_path = os.path.join(cfg.RESULTS_DIR, f'summary_{cfg.SPLIT_NAME}.csv')\n    results_df_sorted.to_csv(csv_path, index=False)\n    print(f\"\\nResults saved: {csv_path}\")\nelse:\n    print(\"No results to summarize\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T23:48:38.474081Z","iopub.execute_input":"2025-10-24T23:48:38.474344Z","iopub.status.idle":"2025-10-24T23:48:38.512153Z","shell.execute_reply.started":"2025-10-24T23:48:38.474325Z","shell.execute_reply":"2025-10-24T23:48:38.511513Z"}},"outputs":[{"name":"stdout","text":"\n==============================================================================================================\nFINAL RESULTS SUMMARY - Split 60:40\n==============================================================================================================\n         Model Split  Test_Accuracy  F1_Macro  Precision_Macro  Recall_Macro  ROC_AUC  Inference_ms  Training_min  Parameters   GFLOPs\n      ResNet50 60_40      75.000000  0.737932         0.817827      0.750000 0.992626      4.091649     30.379960    24786086 0.049572\n   DenseNet121 60_40      70.171053  0.680161         0.795319      0.701711 0.992981      5.134895     29.386155     7707494 0.015415\n   MobileNetV2 60_40      68.263158  0.659006         0.771263      0.682632 0.990956      2.561114     20.885296     3060070 0.006120\n   InceptionV3 60_40      65.013158  0.626576         0.754440      0.650132 0.986507      3.357189     25.471130    23001158 0.046002\nEfficientNetB0 60_40      43.039474  0.415754         0.579054      0.430395 0.933090      3.341677     22.269147     4851657 0.009703\n==============================================================================================================\n\nBest Model: ResNet50\nTest Accuracy: 75.00%\nF1-Score: 0.7379\nTraining Time: 30.4 minutes\n\nResults saved: /kaggle/working/outputs_60_40_v2/results/summary_60_40.csv\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"# CELL 12:  Archive","metadata":{}},{"cell_type":"code","source":"import zipfile\nfrom datetime import datetime\nimport shutil\n\ndef create_comprehensive_archive():\n    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n    archive_name = f'Task2_Split_{cfg.SPLIT_NAME}_Complete_{timestamp}.zip'\n    \n    print(f\"Creating comprehensive archive: {archive_name}\")\n    \n    with zipfile.ZipFile(archive_name, 'w', zipfile.ZIP_DEFLATED) as zipf:\n        for root, dirs, files in os.walk(cfg.OUTPUT_DIR):\n            for file in files:\n                file_path = os.path.join(root, file)\n                arcname = os.path.relpath(file_path, cfg.OUTPUT_DIR)\n                zipf.write(file_path, arcname)\n                \n    file_size_mb = os.path.getsize(archive_name) / (1024*1024)\n    \n    print(f\"\\nArchive created successfully\")\n    print(f\"Filename: {archive_name}\")\n    print(f\"Size: {file_size_mb:.2f} MB\")\n    print(f\"Location: /kaggle/working/{archive_name}\")\n    print(f\"\\nContents:\")\n    print(f\"  - Trained models (.h5 files)\")\n    print(f\"  - Training logs (CSV)\")\n    print(f\"  - All plots and visualizations\")\n    print(f\"  - Evaluation metrics (JSON)\")\n    print(f\"  - Summary results (CSV)\")\n    \n    return archive_name\n\narchive_file = create_comprehensive_archive()\n\nprint(\"\\n\" + \"=\"*110)\nprint(\"BACKUP AND DOWNLOAD INSTRUCTIONS\")\nprint(\"=\"*110)\nprint(f\"1. Navigate to /kaggle/working/ in the Output panel\")\nprint(f\"2. Right-click on: {archive_file}\")\nprint(f\"3. Select 'Download'\")\nprint(f\"4. Store safely - this contains ALL your work for split {cfg.SPLIT_NAME}\")\nprint(\"=\"*110)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T23:48:44.858152Z","iopub.execute_input":"2025-10-24T23:48:44.858424Z","iopub.status.idle":"2025-10-24T23:49:31.843086Z","shell.execute_reply.started":"2025-10-24T23:48:44.858405Z","shell.execute_reply":"2025-10-24T23:49:31.842365Z"}},"outputs":[{"name":"stdout","text":"Creating comprehensive archive: Task2_Split_60_40_Complete_20251024_234844.zip\n\nArchive created successfully\nFilename: Task2_Split_60_40_Complete_20251024_234844.zip\nSize: 858.51 MB\nLocation: /kaggle/working/Task2_Split_60_40_Complete_20251024_234844.zip\n\nContents:\n  - Trained models (.h5 files)\n  - Training logs (CSV)\n  - All plots and visualizations\n  - Evaluation metrics (JSON)\n  - Summary results (CSV)\n\n==============================================================================================================\nBACKUP AND DOWNLOAD INSTRUCTIONS\n==============================================================================================================\n1. Navigate to /kaggle/working/ in the Output panel\n2. Right-click on: Task2_Split_60_40_Complete_20251024_234844.zip\n3. Select 'Download'\n4. Store safely - this contains ALL your work for split 60_40\n==============================================================================================================\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"# CELL 13: Final Report Generation","metadata":{}},{"cell_type":"code","source":"def generate_final_report():\n    report_path = os.path.join(cfg.RESULTS_DIR, f'REPORT_Split_{cfg.SPLIT_NAME}.txt')\n    \n    with open(report_path, 'w') as f:\n        f.write(\"=\"*110 + \"\\n\")\n        f.write(f\"TASK 2: SUPERVISED BASELINE TRAINING REPORT\\n\")\n        f.write(f\"Split: {cfg.TRAIN_RATIO}:{cfg.TEST_RATIO}\\n\")\n        f.write(f\"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n        f.write(\"=\"*110 + \"\\n\\n\")\n        \n        f.write(\"PROJECT INFORMATION\\n\")\n        f.write(\"-\" * 110 + \"\\n\")\n        f.write(f\"Course: CSE475 - Self-Supervised Learning\\n\")\n        f.write(f\"Dataset: Rice Varieties in Bangladesh (38 classes)\\n\")\n        f.write(f\"Total Images: {cfg.TOTAL_IMAGES}\\n\")\n        f.write(f\"Training Strategy: Two-phase (frozen backbone → fine-tuning)\\n\")\n        f.write(f\"Total Epochs: {cfg.TOTAL_EPOCHS} (Phase 1: {cfg.EPOCHS_PHASE1}, Phase 2: {cfg.EPOCHS_PHASE2})\\n\\n\")\n        \n        if len(results_collection) > 0:\n            f.write(\"MODEL PERFORMANCE SUMMARY\\n\")\n            f.write(\"-\" * 110 + \"\\n\")\n            for result in results_collection:\n                f.write(f\"\\nModel: {result['model_name']}\\n\")\n                f.write(f\"  Test Accuracy: {result['overall_accuracy']*100:.2f}%\\n\")\n                f.write(f\"  F1-Score (Macro): {result['f1_macro']:.4f}\\n\")\n                f.write(f\"  Precision (Macro): {result['precision_macro']:.4f}\\n\")\n                f.write(f\"  Recall (Macro): {result['recall_macro']:.4f}\\n\")\n                f.write(f\"  ROC-AUC: {result['roc_auc_macro']:.4f}\\n\")\n                f.write(f\"  Parameters: {result['total_params']:,}\\n\")\n                f.write(f\"  Training Time: {result['training_time_total_min']:.1f} minutes\\n\")\n                f.write(f\"  Inference Time: {result['avg_inference_time_ms']:.2f} ms/image\\n\")\n            \n            best_result = max(results_collection, key=lambda x: x['overall_accuracy'])\n            f.write(f\"\\n{'='*110}\\n\")\n            f.write(f\"BEST MODEL: {best_result['model_name']}\\n\")\n            f.write(f\"Test Accuracy: {best_result['overall_accuracy']*100:.2f}%\\n\")\n            f.write(f\"F1-Score: {best_result['f1_macro']:.4f}\\n\")\n            f.write(f\"{'='*110}\\n\")\n        \n        f.write(\"\\nFILES GENERATED\\n\")\n        f.write(\"-\" * 110 + \"\\n\")\n        f.write(\"- Trained model files (.h5)\\n\")\n        f.write(\"- Training logs (CSV)\\n\")\n        f.write(\"- Training curves and analysis plots\\n\")\n        f.write(\"- Confusion matrices\\n\")\n        f.write(\"- ROC curves\\n\")\n        f.write(\"- Evaluation metrics (JSON)\\n\")\n        f.write(\"- Summary table (CSV)\\n\")\n    \n    print(f\"Final report generated: {report_path}\")\n    return report_path\n\nreport_file = generate_final_report()\nprint(f\"\\nReport saved and ready for submission\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-24T23:49:46.269426Z","iopub.execute_input":"2025-10-24T23:49:46.269979Z","iopub.status.idle":"2025-10-24T23:49:46.279830Z","shell.execute_reply.started":"2025-10-24T23:49:46.269944Z","shell.execute_reply":"2025-10-24T23:49:46.279137Z"}},"outputs":[{"name":"stdout","text":"Final report generated: /kaggle/working/outputs_60_40_v2/results/REPORT_Split_60_40.txt\n\nReport saved and ready for submission\n","output_type":"stream"}],"execution_count":14}]}
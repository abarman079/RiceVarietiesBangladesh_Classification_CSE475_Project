{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CELL 1: Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Task 2: Supervised Baseline - Split 10:90"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CELL 2: Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T14:44:00.438167Z",
     "iopub.status.busy": "2025-10-27T14:44:00.437885Z",
     "iopub.status.idle": "2025-10-27T14:44:00.446434Z",
     "shell.execute_reply": "2025-10-27T14:44:00.445672Z",
     "shell.execute_reply.started": "2025-10-27T14:44:00.438146Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow: 2.18.0\n",
      "Keras: 3.8.0\n",
      "GPU Available: 1 device(s)\n",
      "Environment ready\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import warnings\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks, regularizers\n",
    "from tensorflow.keras.applications import (\n",
    "    ResNet50, EfficientNetB0, MobileNetV2, InceptionV3, DenseNet121\n",
    ")\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input as resnet_preprocess\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input as efficientnet_preprocess\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as mobilenet_preprocess\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input as inception_preprocess\n",
    "from tensorflow.keras.applications.densenet import preprocess_input as densenet_preprocess\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, accuracy_score,\n",
    "    precision_recall_fscore_support, roc_auc_score, roc_curve, auc\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "print(f\"TensorFlow: {tf.__version__}\")\n",
    "print(f\"Keras: {keras.__version__}\")\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"GPU Available: {len(gpus)} device(s)\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU error: {e}\")\n",
    "else:\n",
    "    print(\"CPU mode\")\n",
    "\n",
    "def set_seeds(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "set_seeds(42)\n",
    "print(\"Environment ready\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CELL 3: Configuration for 40:60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T14:44:15.981630Z",
     "iopub.status.busy": "2025-10-27T14:44:15.980923Z",
     "iopub.status.idle": "2025-10-27T14:44:15.989517Z",
     "shell.execute_reply": "2025-10-27T14:44:15.988889Z",
     "shell.execute_reply.started": "2025-10-27T14:44:15.981604Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration: Split 10:90\n",
      "Output: /kaggle/working/outputs_10_90_v2\n"
     ]
    }
   ],
   "source": [
    "class Config:\n",
    "    RANDOM_SEED = 42\n",
    "    \n",
    "    DATASET_BASE = '/kaggle/input/dataset-for-classifying-rice-varieties-in-bd'\n",
    "    ORIGINAL_FOLDER = os.path.join(DATASET_BASE, 'Rice Varieties in Bangladesh', 'Original')\n",
    "    \n",
    "    IMG_SIZE = (224, 224)\n",
    "    INPUT_SHAPE = (224, 224, 3)\n",
    "    \n",
    "    NUM_CLASSES = 38\n",
    "    TOTAL_IMAGES = 19000\n",
    "    CLASS_NAMES = [\n",
    "        'BD30', 'BD33', 'BD39', 'BD49', 'BD51', 'BD52', 'BD56', 'BD57',\n",
    "        'BD70', 'BD72', 'BD75', 'BD76', 'BD79', 'BD85', 'BD87', 'BD91',\n",
    "        'BD93', 'BD95', 'Binadhan10', 'Binadhan11', 'Binadhan12', 'Binadhan14',\n",
    "        'Binadhan16', 'Binadhan17', 'Binadhan19', 'Binadhan20', 'Binadhan21',\n",
    "        'Binadhan23', 'Binadhan24', 'Binadhan25', 'Binadhan26', 'Binadhan7',\n",
    "        'Binadhan8', 'BR22', 'BR23', 'BRRI102', 'BRRI67', 'BRRI74'\n",
    "    ]\n",
    "    \n",
    "    TRAIN_RATIO = 10\n",
    "    TEST_RATIO = 90\n",
    "    VAL_RATIO = 0.1\n",
    "    SPLIT_NAME = f\"{TRAIN_RATIO}_{TEST_RATIO}\"\n",
    "    \n",
    "    BATCH_SIZE = 32\n",
    "    EPOCHS_PHASE1 = 10\n",
    "    EPOCHS_PHASE2 = 40\n",
    "    TOTAL_EPOCHS = 50\n",
    "    \n",
    "    LR_PHASE1 = 1e-3\n",
    "    LR_PHASE2 = 1e-4\n",
    "    \n",
    "    DROPOUT_RATE = 0.5\n",
    "    L2_REG = 1e-4\n",
    "    \n",
    "    MODELS = ['ResNet50', 'EfficientNetB0', 'MobileNetV2', 'InceptionV3', 'DenseNet121']\n",
    "    \n",
    "    OUTPUT_DIR = f'/kaggle/working/outputs_{SPLIT_NAME}_v2'\n",
    "    MODELS_DIR = os.path.join(OUTPUT_DIR, 'models')\n",
    "    LOGS_DIR = os.path.join(OUTPUT_DIR, 'logs')\n",
    "    PLOTS_DIR = os.path.join(OUTPUT_DIR, 'plots')\n",
    "    RESULTS_DIR = os.path.join(OUTPUT_DIR, 'results')\n",
    "\n",
    "cfg = Config()\n",
    "\n",
    "for directory in [cfg.OUTPUT_DIR, cfg.MODELS_DIR, cfg.LOGS_DIR, cfg.PLOTS_DIR, cfg.RESULTS_DIR]:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "print(f\"Configuration: Split {cfg.TRAIN_RATIO}:{cfg.TEST_RATIO}\")\n",
    "print(f\"Output: {cfg.OUTPUT_DIR}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CELL 4: Data Loading Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T14:44:58.100344Z",
     "iopub.status.busy": "2025-10-27T14:44:58.100017Z",
     "iopub.status.idle": "2025-10-27T14:44:58.208254Z",
     "shell.execute_reply": "2025-10-27T14:44:58.207595Z",
     "shell.execute_reply.started": "2025-10-27T14:44:58.100320Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Loaded: 19000 images, 38 classes\n",
      "Train: 1710, Val: 190, Test: 17100\n"
     ]
    }
   ],
   "source": [
    "def load_dataset(data_dir, class_names):\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    label_to_idx = {name: idx for idx, name in enumerate(sorted(class_names))}\n",
    "    idx_to_label = {idx: name for name, idx in label_to_idx.items()}\n",
    "    \n",
    "    print(\"Loading dataset...\")\n",
    "    \n",
    "    class_counts = {}\n",
    "    for class_name in sorted(class_names):\n",
    "        class_dir = os.path.join(data_dir, class_name)\n",
    "        if not os.path.exists(class_dir):\n",
    "            continue\n",
    "        \n",
    "        class_images = [\n",
    "            os.path.join(class_dir, f)\n",
    "            for f in os.listdir(class_dir)\n",
    "            if f.lower().endswith(('.jpg', '.jpeg', '.png'))\n",
    "        ]\n",
    "        \n",
    "        image_paths.extend(class_images)\n",
    "        labels.extend([label_to_idx[class_name]] * len(class_images))\n",
    "        class_counts[class_name] = len(class_images)\n",
    "    \n",
    "    print(f\"Loaded: {len(image_paths)} images, {len(class_counts)} classes\")\n",
    "    return image_paths, labels, label_to_idx, idx_to_label\n",
    "\n",
    "\n",
    "def prepare_splits(image_paths, labels, train_ratio, test_ratio, val_ratio=0.1, random_state=42):\n",
    "    image_paths = np.array(image_paths)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    train_val_paths, test_paths, train_val_labels, test_labels = train_test_split(\n",
    "        image_paths, labels, test_size=test_ratio/100, stratify=labels, random_state=random_state\n",
    "    )\n",
    "    \n",
    "    train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
    "        train_val_paths, train_val_labels, test_size=val_ratio, stratify=train_val_labels, random_state=random_state\n",
    "    )\n",
    "    \n",
    "    print(f\"Train: {len(train_paths)}, Val: {len(val_paths)}, Test: {len(test_paths)}\")\n",
    "    return {\n",
    "        'train_paths': train_paths, 'train_labels': train_labels,\n",
    "        'val_paths': val_paths, 'val_labels': val_labels,\n",
    "        'test_paths': test_paths, 'test_labels': test_labels\n",
    "    }\n",
    "\n",
    "\n",
    "all_image_paths, all_labels, label_to_idx, idx_to_label = load_dataset(cfg.ORIGINAL_FOLDER, cfg.CLASS_NAMES)\n",
    "split_data = prepare_splits(all_image_paths, all_labels, cfg.TRAIN_RATIO, cfg.TEST_RATIO, cfg.VAL_RATIO, cfg.RANDOM_SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CELL 5: Data Pipeline Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T14:45:03.656866Z",
     "iopub.status.busy": "2025-10-27T14:45:03.656593Z",
     "iopub.status.idle": "2025-10-27T14:45:03.664013Z",
     "shell.execute_reply": "2025-10-27T14:45:03.663260Z",
     "shell.execute_reply.started": "2025-10-27T14:45:03.656838Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhanced augmentation pipeline ready\n"
     ]
    }
   ],
   "source": [
    "def create_dataset_enhanced(paths, labels, preprocess_func, batch_size, img_size, \n",
    "                            shuffle=False, augment=False, seed=42):\n",
    "    def load_and_augment(path, label):\n",
    "        img = tf.io.read_file(path)\n",
    "        img = tf.image.decode_jpeg(img, channels=3)\n",
    "        \n",
    "        if augment:\n",
    "            img = tf.image.random_crop(tf.image.resize(img, (256, 256)), [224, 224, 3])\n",
    "            img = tf.image.random_flip_left_right(img)\n",
    "            img = tf.image.random_flip_up_down(img)\n",
    "            img = tf.image.random_brightness(img, 0.3)\n",
    "            img = tf.image.random_contrast(img, 0.7, 1.3)\n",
    "            img = tf.image.random_saturation(img, 0.7, 1.3)\n",
    "            img = tf.image.random_hue(img, 0.1)\n",
    "        else:\n",
    "            img = tf.image.resize(img, img_size)\n",
    "        \n",
    "        img = tf.cast(img, tf.float32)\n",
    "        if preprocess_func is not None:\n",
    "            img = preprocess_func(img)\n",
    "        else:\n",
    "            img = img / 255.0\n",
    "        \n",
    "        return img, label\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=2000, seed=seed, reshuffle_each_iteration=True)\n",
    "    dataset = dataset.map(load_and_augment, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "print(\"Enhanced augmentation pipeline ready\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CELL 6: Model Building Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T14:45:08.280536Z",
     "iopub.status.busy": "2025-10-27T14:45:08.279941Z",
     "iopub.status.idle": "2025-10-27T14:45:08.287780Z",
     "shell.execute_reply": "2025-10-27T14:45:08.286991Z",
     "shell.execute_reply.started": "2025-10-27T14:45:08.280509Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Advanced model builder defined\n"
     ]
    }
   ],
   "source": [
    "def build_model_advanced(backbone_name, input_shape=(224, 224, 3), num_classes=38):\n",
    "    backbones = {\n",
    "        'ResNet50': (ResNet50, resnet_preprocess),\n",
    "        'EfficientNetB0': (EfficientNetB0, efficientnet_preprocess),\n",
    "        'MobileNetV2': (MobileNetV2, mobilenet_preprocess),\n",
    "        'InceptionV3': (InceptionV3, inception_preprocess),\n",
    "        'DenseNet121': (DenseNet121, densenet_preprocess)\n",
    "    }\n",
    "    \n",
    "    backbone_class, preprocess_func = backbones[backbone_name]\n",
    "    \n",
    "    print(f\"Building {backbone_name} with enhanced architecture...\")\n",
    "    base_model = backbone_class(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = base_model(inputs, training=False)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(cfg.L2_REG))(x)\n",
    "    x = layers.Dropout(cfg.DROPOUT_RATE)(x)\n",
    "    x = layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(cfg.L2_REG))(x)\n",
    "    x = layers.Dropout(cfg.DROPOUT_RATE)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = keras.Model(inputs, outputs, name=f'{backbone_name}_enhanced')\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=cfg.LR_PHASE1),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    print(f\"Model ready: {model.count_params():,} parameters\")\n",
    "    return model, preprocess_func, base_model\n",
    "\n",
    "print(\"Advanced model builder defined\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CELL 7: Two-Phase Training Controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T14:45:16.954143Z",
     "iopub.status.busy": "2025-10-27T14:45:16.953881Z",
     "iopub.status.idle": "2025-10-27T14:45:16.966474Z",
     "shell.execute_reply": "2025-10-27T14:45:16.965741Z",
     "shell.execute_reply.started": "2025-10-27T14:45:16.954125Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-phase training controller defined\n"
     ]
    }
   ],
   "source": [
    "class TwoPhaseTrainer:\n",
    "    def __init__(self, model, base_model, model_name, split_name):\n",
    "        self.model = model\n",
    "        self.base_model = base_model\n",
    "        self.model_name = model_name\n",
    "        self.split_name = split_name\n",
    "        self.history_phase1 = None\n",
    "        self.history_phase2 = None\n",
    "        \n",
    "    def get_callbacks(self, phase):\n",
    "        model_dir = os.path.join(cfg.MODELS_DIR, f\"{self.model_name}_{self.split_name}\")\n",
    "        os.makedirs(model_dir, exist_ok=True)\n",
    "        \n",
    "        checkpoint_path = os.path.join(model_dir, f'best_model_phase{phase}.h5')\n",
    "        \n",
    "        callbacks_list = [\n",
    "            callbacks.ModelCheckpoint(\n",
    "                filepath=checkpoint_path,\n",
    "                monitor='val_accuracy',\n",
    "                mode='max',\n",
    "                save_best_only=True,\n",
    "                save_weights_only=False,\n",
    "                verbose=1\n",
    "            ),\n",
    "            callbacks.ReduceLROnPlateau(\n",
    "                monitor='val_loss',\n",
    "                factor=0.5,\n",
    "                patience=3,\n",
    "                min_lr=1e-7,\n",
    "                verbose=1,\n",
    "                mode='min'\n",
    "            ),\n",
    "            callbacks.CSVLogger(\n",
    "                filename=os.path.join(model_dir, f'training_log_phase{phase}.csv'),\n",
    "                append=False\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        return callbacks_list, checkpoint_path\n",
    "    \n",
    "    def train_phase1(self, train_dataset, val_dataset):\n",
    "        print(f\"\\nPHASE 1: Training classifier head (backbone frozen)\")\n",
    "        print(f\"Epochs: {cfg.EPOCHS_PHASE1}, Learning Rate: {cfg.LR_PHASE1}\")\n",
    "        print(f\"Trainable parameters: {sum([tf.size(w).numpy() for w in self.model.trainable_weights]):,}\")\n",
    "        \n",
    "        self.base_model.trainable = False\n",
    "        self.model.compile(\n",
    "            optimizer=keras.optimizers.Adam(learning_rate=cfg.LR_PHASE1),\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        callbacks_list, checkpoint_path = self.get_callbacks(phase=1)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        self.history_phase1 = self.model.fit(\n",
    "            train_dataset,\n",
    "            validation_data=val_dataset,\n",
    "            epochs=cfg.EPOCHS_PHASE1,\n",
    "            callbacks=callbacks_list,\n",
    "            verbose=1\n",
    "        )\n",
    "        phase1_time = time.time() - start_time\n",
    "        \n",
    "        print(f\"Phase 1 completed in {phase1_time/60:.2f} minutes\")\n",
    "        print(f\"Best model saved: {checkpoint_path}\")\n",
    "        \n",
    "        return checkpoint_path, phase1_time\n",
    "    \n",
    "    def train_phase2(self, train_dataset, val_dataset):\n",
    "        print(f\"\\nPHASE 2: Fine-tuning entire model (backbone unfrozen)\")\n",
    "        print(f\"Epochs: {cfg.EPOCHS_PHASE2}, Learning Rate: {cfg.LR_PHASE2}\")\n",
    "        \n",
    "        self.base_model.trainable = True\n",
    "        \n",
    "        num_layers = len(self.base_model.layers)\n",
    "        freeze_until = int(num_layers * 0.5)\n",
    "        \n",
    "        for layer in self.base_model.layers[:freeze_until]:\n",
    "            layer.trainable = False\n",
    "        \n",
    "        print(f\"Unfreezing last {num_layers - freeze_until}/{num_layers} layers of backbone\")\n",
    "        print(f\"Trainable parameters: {sum([tf.size(w).numpy() for w in self.model.trainable_weights]):,}\")\n",
    "        \n",
    "        self.model.compile(\n",
    "            optimizer=keras.optimizers.Adam(learning_rate=cfg.LR_PHASE2),\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        callbacks_list, checkpoint_path = self.get_callbacks(phase=2)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        self.history_phase2 = self.model.fit(\n",
    "            train_dataset,\n",
    "            validation_data=val_dataset,\n",
    "            initial_epoch=cfg.EPOCHS_PHASE1,\n",
    "            epochs=cfg.TOTAL_EPOCHS,\n",
    "            callbacks=callbacks_list,\n",
    "            verbose=1\n",
    "        )\n",
    "        phase2_time = time.time() - start_time\n",
    "        \n",
    "        print(f\"Phase 2 completed in {phase2_time/60:.2f} minutes\")\n",
    "        print(f\"Best model saved: {checkpoint_path}\")\n",
    "        \n",
    "        return checkpoint_path, phase2_time\n",
    "    \n",
    "    def get_combined_history(self):\n",
    "        if self.history_phase1 is None or self.history_phase2 is None:\n",
    "            return None\n",
    "        \n",
    "        combined = {\n",
    "            'accuracy': self.history_phase1.history['accuracy'] + self.history_phase2.history['accuracy'],\n",
    "            'val_accuracy': self.history_phase1.history['val_accuracy'] + self.history_phase2.history['val_accuracy'],\n",
    "            'loss': self.history_phase1.history['loss'] + self.history_phase2.history['loss'],\n",
    "            'val_loss': self.history_phase1.history['val_loss'] + self.history_phase2.history['val_loss']\n",
    "        }\n",
    "        \n",
    "        return type('History', (), {'history': combined})()\n",
    "\n",
    "print(\"Two-phase training controller defined\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CELL 8: Evaluation Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T14:45:23.018044Z",
     "iopub.status.busy": "2025-10-27T14:45:23.017575Z",
     "iopub.status.idle": "2025-10-27T14:45:23.031852Z",
     "shell.execute_reply": "2025-10-27T14:45:23.031255Z",
     "shell.execute_reply.started": "2025-10-27T14:45:23.018020Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comprehensive evaluation function defined\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model_comprehensive(model, test_dataset, test_labels, idx_to_label, \n",
    "                                  model_name, split_name):\n",
    "    print(f\"\\nComprehensive evaluation: {model_name} on {split_name}\")\n",
    "    \n",
    "    results_dir = os.path.join(cfg.RESULTS_DIR, f\"{model_name}_{split_name}\")\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    y_pred_probs = model.predict(test_dataset, verbose=0)\n",
    "    inference_time = time.time() - start_time\n",
    "    \n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "    y_true = test_labels\n",
    "    \n",
    "    avg_inference_time_ms = (inference_time / len(test_labels)) * 1000\n",
    "    \n",
    "    overall_accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average='macro', zero_division=0\n",
    "    )\n",
    "    precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average='micro', zero_division=0\n",
    "    )\n",
    "    \n",
    "    print(f\"Accuracy: {overall_accuracy*100:.2f}%\")\n",
    "    print(f\"F1-Score (Macro): {f1_macro:.4f}\")\n",
    "    print(f\"Precision (Macro): {precision_macro:.4f}\")\n",
    "    print(f\"Recall (Macro): {recall_macro:.4f}\")\n",
    "    \n",
    "    precision, recall, f1, support = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average=None, zero_division=0\n",
    "    )\n",
    "    \n",
    "    per_class_accuracy = np.array([\n",
    "        (y_pred[y_true == i] == y_true[y_true == i]).sum() / (y_true == i).sum()\n",
    "        if (y_true == i).sum() > 0 else 0.0\n",
    "        for i in range(cfg.NUM_CLASSES)\n",
    "    ])\n",
    "    \n",
    "    try:\n",
    "        y_true_bin = label_binarize(y_true, classes=range(cfg.NUM_CLASSES))\n",
    "        roc_auc_scores = []\n",
    "        for i in range(cfg.NUM_CLASSES):\n",
    "            try:\n",
    "                score = roc_auc_score(y_true_bin[:, i], y_pred_probs[:, i])\n",
    "                roc_auc_scores.append(score)\n",
    "            except:\n",
    "                roc_auc_scores.append(0.0)\n",
    "        roc_auc_macro = np.mean(roc_auc_scores)\n",
    "        print(f\"ROC-AUC (Macro): {roc_auc_macro:.4f}\")\n",
    "    except:\n",
    "        roc_auc_macro = 0.0\n",
    "        roc_auc_scores = [0.0] * cfg.NUM_CLASSES\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    confused_pairs = []\n",
    "    for i in range(cfg.NUM_CLASSES):\n",
    "        for j in range(cfg.NUM_CLASSES):\n",
    "            if i != j and cm[i, j] > 0:\n",
    "                confused_pairs.append({\n",
    "                    'true_class': idx_to_label[i],\n",
    "                    'pred_class': idx_to_label[j],\n",
    "                    'count': int(cm[i, j]),\n",
    "                    'true_idx': int(i),\n",
    "                    'pred_idx': int(j)\n",
    "                })\n",
    "    \n",
    "    top_confused = sorted(confused_pairs, key=lambda x: x['count'], reverse=True)[:5]\n",
    "    \n",
    "    total_params = model.count_params()\n",
    "    gflops = total_params * 2 / 1e9\n",
    "    \n",
    "    results_dict = {\n",
    "        'model_name': model_name,\n",
    "        'split_name': split_name,\n",
    "        'overall_accuracy': overall_accuracy,\n",
    "        'precision_macro': precision_macro,\n",
    "        'recall_macro': recall_macro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'roc_auc_macro': roc_auc_macro,\n",
    "        'avg_inference_time_ms': avg_inference_time_ms,\n",
    "        'total_params': total_params,\n",
    "        'gflops': gflops,\n",
    "        'per_class_accuracy': per_class_accuracy,\n",
    "        'per_class_precision': precision,\n",
    "        'per_class_recall': recall,\n",
    "        'per_class_f1': f1,\n",
    "        'confusion_matrix': cm,\n",
    "        'y_true': y_true,\n",
    "        'y_pred': y_pred,\n",
    "        'y_pred_probs': y_pred_probs\n",
    "    }\n",
    "    \n",
    "    json_results = {k: float(v) if isinstance(v, np.floating) else int(v) if isinstance(v, np.integer) else v \n",
    "                    for k, v in results_dict.items() if k not in ['confusion_matrix', 'y_true', 'y_pred', 'y_pred_probs', \n",
    "                                                                    'per_class_accuracy', 'per_class_precision', \n",
    "                                                                    'per_class_recall', 'per_class_f1']}\n",
    "    \n",
    "    with open(os.path.join(results_dir, 'metrics.json'), 'w') as f:\n",
    "        json.dump(json_results, f, indent=4)\n",
    "    \n",
    "    return results_dict\n",
    "\n",
    "print(\"Comprehensive evaluation function defined\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CELL 9: Visualization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T14:45:28.640924Z",
     "iopub.status.busy": "2025-10-27T14:45:28.640441Z",
     "iopub.status.idle": "2025-10-27T14:45:28.655362Z",
     "shell.execute_reply": "2025-10-27T14:45:28.654567Z",
     "shell.execute_reply.started": "2025-10-27T14:45:28.640904Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhanced visualization functions defined\n"
     ]
    }
   ],
   "source": [
    "def plot_training_curves_enhanced(history, model_name, split_name):\n",
    "    model_dir = os.path.join(cfg.PLOTS_DIR, f\"{model_name}_{split_name}\")\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    epochs_range = range(1, len(history.history['accuracy']) + 1)\n",
    "    phase1_end = cfg.EPOCHS_PHASE1\n",
    "    \n",
    "    axes[0, 0].plot(epochs_range, history.history['accuracy'], 'b-', linewidth=2, label='Train')\n",
    "    axes[0, 0].plot(epochs_range, history.history['val_accuracy'], 'r-', linewidth=2, label='Validation')\n",
    "    axes[0, 0].axvline(x=phase1_end, color='g', linestyle='--', linewidth=2, label='Phase 1/2 Boundary')\n",
    "    axes[0, 0].set_title('Model Accuracy', fontsize=13, fontweight='bold')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Accuracy')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    axes[0, 1].plot(epochs_range, history.history['loss'], 'b-', linewidth=2, label='Train')\n",
    "    axes[0, 1].plot(epochs_range, history.history['val_loss'], 'r-', linewidth=2, label='Validation')\n",
    "    axes[0, 1].axvline(x=phase1_end, color='g', linestyle='--', linewidth=2, label='Phase 1/2 Boundary')\n",
    "    axes[0, 1].set_title('Model Loss', fontsize=13, fontweight='bold')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Loss')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    val_acc = history.history['val_accuracy']\n",
    "    best_epoch = np.argmax(val_acc) + 1\n",
    "    best_val_acc = max(val_acc)\n",
    "    \n",
    "    axes[1, 0].plot(epochs_range, val_acc, 'r-', linewidth=2)\n",
    "    axes[1, 0].scatter([best_epoch], [best_val_acc], color='gold', s=200, zorder=5, edgecolors='black', linewidth=2)\n",
    "    axes[1, 0].set_title(f'Validation Accuracy (Best: {best_val_acc:.4f} at epoch {best_epoch})', \n",
    "                         fontsize=13, fontweight='bold')\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('Validation Accuracy')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    overfitting_gap = [history.history['accuracy'][i] - history.history['val_accuracy'][i] \n",
    "                       for i in range(len(history.history['accuracy']))]\n",
    "    axes[1, 1].plot(epochs_range, overfitting_gap, 'purple', linewidth=2)\n",
    "    axes[1, 1].axhline(y=0, color='black', linestyle='-', linewidth=1)\n",
    "    axes[1, 1].set_title('Training-Validation Gap (Overfitting Indicator)', fontsize=13, fontweight='bold')\n",
    "    axes[1, 1].set_xlabel('Epoch')\n",
    "    axes[1, 1].set_ylabel('Train Acc - Val Acc')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    save_path = os.path.join(model_dir, 'training_analysis.png')\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Training analysis saved: {save_path}\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_confusion_matrix_professional(cm, model_name, split_name):\n",
    "    model_dir = os.path.join(cfg.PLOTS_DIR, f\"{model_name}_{split_name}\")\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(24, 10))\n",
    "    \n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    sns.heatmap(cm_normalized, annot=False, cmap='Blues', ax=axes[0],\n",
    "                xticklabels=cfg.CLASS_NAMES, yticklabels=cfg.CLASS_NAMES,\n",
    "                cbar_kws={'label': 'Normalized Frequency'})\n",
    "    axes[0].set_title(f'{model_name}: Normalized Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_xlabel('Predicted Label', fontsize=12)\n",
    "    axes[0].set_ylabel('True Label', fontsize=12)\n",
    "    \n",
    "    per_class_acc = np.diag(cm_normalized)\n",
    "    axes[1].barh(cfg.CLASS_NAMES, per_class_acc, color='steelblue')\n",
    "    axes[1].set_xlabel('Accuracy', fontsize=12)\n",
    "    axes[1].set_title(f'{model_name}: Per-Class Accuracy', fontsize=14, fontweight='bold')\n",
    "    axes[1].axvline(x=np.mean(per_class_acc), color='red', linestyle='--', linewidth=2, \n",
    "                    label=f'Mean: {np.mean(per_class_acc):.3f}')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    save_path = os.path.join(model_dir, 'confusion_matrix_analysis.png')\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Confusion matrix analysis saved: {save_path}\")\n",
    "    plt.close()\n",
    "\n",
    "print(\"Enhanced visualization functions defined\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CELL 10: Main Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T14:45:33.615027Z",
     "iopub.status.busy": "2025-10-27T14:45:33.614761Z",
     "iopub.status.idle": "2025-10-27T15:21:27.785932Z",
     "shell.execute_reply": "2025-10-27T15:21:27.785261Z",
     "shell.execute_reply.started": "2025-10-27T14:45:33.615008Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting enhanced training pipeline for split 10:90\n",
      "Configuration: Two-phase training with enhanced regularization\n",
      "Expected outcome: 95%+ accuracy with minimal overfitting\n",
      "\n",
      "\n",
      "==========================================================================================\n",
      "MODEL: ResNet50\n",
      "==========================================================================================\n",
      "Building ResNet50 with enhanced architecture...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1761576333.731190      37 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n",
      "Model ready: 24,786,086 parameters\n",
      "\n",
      "Preparing data pipelines...\n",
      "\n",
      "PHASE 1: Training classifier head (backbone frozen)\n",
      "Epochs: 10, Learning Rate: 0.001\n",
      "Trainable parameters: 1,194,278\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1761576351.681527     100 service.cc:148] XLA service 0x7913fc0033e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1761576351.682494     100 service.cc:156]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
      "I0000 00:00:1761576353.348585     100 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 3/54\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.0156 - loss: 5.2457      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1761576358.209551     100 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - accuracy: 0.0655 - loss: 4.5302\n",
      "Epoch 1: val_accuracy improved from -inf to 0.21579, saving model to /kaggle/working/outputs_10_90_v2/models/ResNet50_10_90/best_model_phase1.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 345ms/step - accuracy: 0.0661 - loss: 4.5213 - val_accuracy: 0.2158 - val_loss: 3.1120 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.2073 - loss: 3.0336\n",
      "Epoch 2: val_accuracy improved from 0.21579 to 0.37895, saving model to /kaggle/working/outputs_10_90_v2/models/ResNet50_10_90/best_model_phase1.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 97ms/step - accuracy: 0.2081 - loss: 3.0322 - val_accuracy: 0.3789 - val_loss: 2.7114 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.2589 - loss: 2.7959\n",
      "Epoch 3: val_accuracy improved from 0.37895 to 0.40526, saving model to /kaggle/working/outputs_10_90_v2/models/ResNet50_10_90/best_model_phase1.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 101ms/step - accuracy: 0.2592 - loss: 2.7946 - val_accuracy: 0.4053 - val_loss: 2.3372 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.3242 - loss: 2.4996\n",
      "Epoch 4: val_accuracy improved from 0.40526 to 0.45263, saving model to /kaggle/working/outputs_10_90_v2/models/ResNet50_10_90/best_model_phase1.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 101ms/step - accuracy: 0.3245 - loss: 2.4982 - val_accuracy: 0.4526 - val_loss: 2.1226 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.3779 - loss: 2.2441\n",
      "Epoch 5: val_accuracy improved from 0.45263 to 0.48421, saving model to /kaggle/working/outputs_10_90_v2/models/ResNet50_10_90/best_model_phase1.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 100ms/step - accuracy: 0.3777 - loss: 2.2445 - val_accuracy: 0.4842 - val_loss: 1.9785 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.4107 - loss: 2.1708\n",
      "Epoch 6: val_accuracy did not improve from 0.48421\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 91ms/step - accuracy: 0.4102 - loss: 2.1713 - val_accuracy: 0.4842 - val_loss: 1.8560 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.4408 - loss: 2.0156\n",
      "Epoch 7: val_accuracy did not improve from 0.48421\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 91ms/step - accuracy: 0.4402 - loss: 2.0177 - val_accuracy: 0.4842 - val_loss: 1.8023 - learning_rate: 0.0010\n",
      "Epoch 8/10\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.4585 - loss: 1.9367\n",
      "Epoch 8: val_accuracy improved from 0.48421 to 0.50000, saving model to /kaggle/working/outputs_10_90_v2/models/ResNet50_10_90/best_model_phase1.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 99ms/step - accuracy: 0.4580 - loss: 1.9374 - val_accuracy: 0.5000 - val_loss: 1.7323 - learning_rate: 0.0010\n",
      "Epoch 9/10\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.4416 - loss: 1.8974\n",
      "Epoch 9: val_accuracy did not improve from 0.50000\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 90ms/step - accuracy: 0.4422 - loss: 1.8976 - val_accuracy: 0.4789 - val_loss: 1.7312 - learning_rate: 0.0010\n",
      "Epoch 10/10\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.4586 - loss: 1.8386\n",
      "Epoch 10: val_accuracy improved from 0.50000 to 0.51579, saving model to /kaggle/working/outputs_10_90_v2/models/ResNet50_10_90/best_model_phase1.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 99ms/step - accuracy: 0.4588 - loss: 1.8385 - val_accuracy: 0.5158 - val_loss: 1.6883 - learning_rate: 0.0010\n",
      "Phase 1 completed in 1.39 minutes\n",
      "Best model saved: /kaggle/working/outputs_10_90_v2/models/ResNet50_10_90/best_model_phase1.h5\n",
      "\n",
      "PHASE 2: Fine-tuning entire model (backbone unfrozen)\n",
      "Epochs: 40, Learning Rate: 0.0001\n",
      "Unfreezing last 88/175 layers of backbone\n",
      "Trainable parameters: 22,556,454\n",
      "Epoch 11/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 315ms/step - accuracy: 0.3758 - loss: 2.2646\n",
      "Epoch 11: val_accuracy improved from -inf to 0.26842, saving model to /kaggle/working/outputs_10_90_v2/models/ResNet50_10_90/best_model_phase2.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 454ms/step - accuracy: 0.3760 - loss: 2.2634 - val_accuracy: 0.2684 - val_loss: 3.1509 - learning_rate: 1.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.4793 - loss: 1.8621\n",
      "Epoch 12: val_accuracy improved from 0.26842 to 0.35789, saving model to /kaggle/working/outputs_10_90_v2/models/ResNet50_10_90/best_model_phase2.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 128ms/step - accuracy: 0.4793 - loss: 1.8616 - val_accuracy: 0.3579 - val_loss: 2.2581 - learning_rate: 1.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.5170 - loss: 1.6967 \n",
      "Epoch 13: val_accuracy did not improve from 0.35789\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 109ms/step - accuracy: 0.5170 - loss: 1.6961 - val_accuracy: 0.3053 - val_loss: 2.4051 - learning_rate: 1.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.5613 - loss: 1.5245\n",
      "Epoch 14: val_accuracy did not improve from 0.35789\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 109ms/step - accuracy: 0.5614 - loss: 1.5241 - val_accuracy: 0.3474 - val_loss: 2.2582 - learning_rate: 1.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.5871 - loss: 1.4255 \n",
      "Epoch 15: val_accuracy improved from 0.35789 to 0.45263, saving model to /kaggle/working/outputs_10_90_v2/models/ResNet50_10_90/best_model_phase2.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 128ms/step - accuracy: 0.5868 - loss: 1.4262 - val_accuracy: 0.4526 - val_loss: 1.8100 - learning_rate: 1.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.6245 - loss: 1.3181\n",
      "Epoch 16: val_accuracy did not improve from 0.45263\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 109ms/step - accuracy: 0.6243 - loss: 1.3187 - val_accuracy: 0.4474 - val_loss: 1.8361 - learning_rate: 1.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.6377 - loss: 1.2979 \n",
      "Epoch 17: val_accuracy did not improve from 0.45263\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 109ms/step - accuracy: 0.6375 - loss: 1.2985 - val_accuracy: 0.3947 - val_loss: 2.0312 - learning_rate: 1.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.6302 - loss: 1.2288\n",
      "Epoch 18: val_accuracy improved from 0.45263 to 0.49474, saving model to /kaggle/working/outputs_10_90_v2/models/ResNet50_10_90/best_model_phase2.h5\n",
      "\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 129ms/step - accuracy: 0.6303 - loss: 1.2287 - val_accuracy: 0.4947 - val_loss: 1.9268 - learning_rate: 1.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.6542 - loss: 1.2132 \n",
      "Epoch 19: val_accuracy improved from 0.49474 to 0.52632, saving model to /kaggle/working/outputs_10_90_v2/models/ResNet50_10_90/best_model_phase2.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 129ms/step - accuracy: 0.6545 - loss: 1.2124 - val_accuracy: 0.5263 - val_loss: 1.5938 - learning_rate: 5.0000e-05\n",
      "Epoch 20/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.7002 - loss: 1.0274\n",
      "Epoch 20: val_accuracy improved from 0.52632 to 0.56842, saving model to /kaggle/working/outputs_10_90_v2/models/ResNet50_10_90/best_model_phase2.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 133ms/step - accuracy: 0.7004 - loss: 1.0267 - val_accuracy: 0.5684 - val_loss: 1.5805 - learning_rate: 5.0000e-05\n",
      "Epoch 21/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.7286 - loss: 0.9609\n",
      "Epoch 21: val_accuracy did not improve from 0.56842\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 109ms/step - accuracy: 0.7285 - loss: 0.9611 - val_accuracy: 0.5368 - val_loss: 1.6174 - learning_rate: 5.0000e-05\n",
      "Epoch 22/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.7382 - loss: 0.9047\n",
      "Epoch 22: val_accuracy improved from 0.56842 to 0.58947, saving model to /kaggle/working/outputs_10_90_v2/models/ResNet50_10_90/best_model_phase2.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 129ms/step - accuracy: 0.7383 - loss: 0.9047 - val_accuracy: 0.5895 - val_loss: 1.4236 - learning_rate: 5.0000e-05\n",
      "Epoch 23/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.7629 - loss: 0.8330 \n",
      "Epoch 23: val_accuracy did not improve from 0.58947\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 108ms/step - accuracy: 0.7628 - loss: 0.8339 - val_accuracy: 0.5842 - val_loss: 1.5404 - learning_rate: 5.0000e-05\n",
      "Epoch 24/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.7616 - loss: 0.8580\n",
      "Epoch 24: val_accuracy did not improve from 0.58947\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 109ms/step - accuracy: 0.7615 - loss: 0.8585 - val_accuracy: 0.5684 - val_loss: 1.5169 - learning_rate: 5.0000e-05\n",
      "Epoch 25/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.7787 - loss: 0.8145\n",
      "Epoch 25: val_accuracy did not improve from 0.58947\n",
      "\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 109ms/step - accuracy: 0.7784 - loss: 0.8150 - val_accuracy: 0.5263 - val_loss: 1.6330 - learning_rate: 5.0000e-05\n",
      "Epoch 26/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.7729 - loss: 0.8217\n",
      "Epoch 26: val_accuracy did not improve from 0.58947\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 110ms/step - accuracy: 0.7731 - loss: 0.8213 - val_accuracy: 0.5789 - val_loss: 1.4574 - learning_rate: 2.5000e-05\n",
      "Epoch 27/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.7938 - loss: 0.7568\n",
      "Epoch 27: val_accuracy improved from 0.58947 to 0.61053, saving model to /kaggle/working/outputs_10_90_v2/models/ResNet50_10_90/best_model_phase2.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 129ms/step - accuracy: 0.7939 - loss: 0.7566 - val_accuracy: 0.6105 - val_loss: 1.4348 - learning_rate: 2.5000e-05\n",
      "Epoch 28/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.8219 - loss: 0.7077\n",
      "Epoch 28: val_accuracy did not improve from 0.61053\n",
      "\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 110ms/step - accuracy: 0.8217 - loss: 0.7081 - val_accuracy: 0.6000 - val_loss: 1.4333 - learning_rate: 2.5000e-05\n",
      "Epoch 29/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.8215 - loss: 0.6783\n",
      "Epoch 29: val_accuracy did not improve from 0.61053\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 110ms/step - accuracy: 0.8213 - loss: 0.6785 - val_accuracy: 0.6053 - val_loss: 1.4197 - learning_rate: 1.2500e-05\n",
      "Epoch 30/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.8165 - loss: 0.6979\n",
      "Epoch 30: val_accuracy did not improve from 0.61053\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 110ms/step - accuracy: 0.8167 - loss: 0.6975 - val_accuracy: 0.6000 - val_loss: 1.4181 - learning_rate: 1.2500e-05\n",
      "Epoch 31/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.8333 - loss: 0.6318\n",
      "Epoch 31: val_accuracy did not improve from 0.61053\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 110ms/step - accuracy: 0.8332 - loss: 0.6322 - val_accuracy: 0.6053 - val_loss: 1.4220 - learning_rate: 1.2500e-05\n",
      "Epoch 32/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.8332 - loss: 0.6457\n",
      "Epoch 32: val_accuracy did not improve from 0.61053\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 109ms/step - accuracy: 0.8332 - loss: 0.6459 - val_accuracy: 0.6053 - val_loss: 1.4254 - learning_rate: 1.2500e-05\n",
      "Epoch 33/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.8270 - loss: 0.6421 \n",
      "Epoch 33: val_accuracy improved from 0.61053 to 0.61579, saving model to /kaggle/working/outputs_10_90_v2/models/ResNet50_10_90/best_model_phase2.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 128ms/step - accuracy: 0.8270 - loss: 0.6420 - val_accuracy: 0.6158 - val_loss: 1.3592 - learning_rate: 1.2500e-05\n",
      "Epoch 34/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.8180 - loss: 0.6616\n",
      "Epoch 34: val_accuracy improved from 0.61579 to 0.63158, saving model to /kaggle/working/outputs_10_90_v2/models/ResNet50_10_90/best_model_phase2.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 129ms/step - accuracy: 0.8184 - loss: 0.6611 - val_accuracy: 0.6316 - val_loss: 1.2822 - learning_rate: 1.2500e-05\n",
      "Epoch 35/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.8331 - loss: 0.6154 \n",
      "Epoch 35: val_accuracy did not improve from 0.63158\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 109ms/step - accuracy: 0.8333 - loss: 0.6151 - val_accuracy: 0.6211 - val_loss: 1.3899 - learning_rate: 1.2500e-05\n",
      "Epoch 36/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.8596 - loss: 0.5999\n",
      "Epoch 36: val_accuracy did not improve from 0.63158\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 109ms/step - accuracy: 0.8593 - loss: 0.6003 - val_accuracy: 0.6158 - val_loss: 1.4650 - learning_rate: 1.2500e-05\n",
      "Epoch 37/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.8478 - loss: 0.5789\n",
      "Epoch 37: val_accuracy improved from 0.63158 to 0.63684, saving model to /kaggle/working/outputs_10_90_v2/models/ResNet50_10_90/best_model_phase2.h5\n",
      "\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 130ms/step - accuracy: 0.8480 - loss: 0.5786 - val_accuracy: 0.6368 - val_loss: 1.4465 - learning_rate: 1.2500e-05\n",
      "Epoch 38/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.8367 - loss: 0.5944 \n",
      "Epoch 38: val_accuracy did not improve from 0.63684\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 108ms/step - accuracy: 0.8366 - loss: 0.5943 - val_accuracy: 0.6105 - val_loss: 1.4668 - learning_rate: 6.2500e-06\n",
      "Epoch 39/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.8371 - loss: 0.6521\n",
      "Epoch 39: val_accuracy did not improve from 0.63684\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 109ms/step - accuracy: 0.8374 - loss: 0.6509 - val_accuracy: 0.6158 - val_loss: 1.4227 - learning_rate: 6.2500e-06\n",
      "Epoch 40/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.8770 - loss: 0.5647\n",
      "Epoch 40: val_accuracy did not improve from 0.63684\n",
      "\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 109ms/step - accuracy: 0.8768 - loss: 0.5649 - val_accuracy: 0.6158 - val_loss: 1.4489 - learning_rate: 6.2500e-06\n",
      "Epoch 41/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.8576 - loss: 0.5417\n",
      "Epoch 41: val_accuracy did not improve from 0.63684\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 110ms/step - accuracy: 0.8577 - loss: 0.5418 - val_accuracy: 0.6105 - val_loss: 1.4489 - learning_rate: 3.1250e-06\n",
      "Epoch 42/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.8781 - loss: 0.5516 \n",
      "Epoch 42: val_accuracy did not improve from 0.63684\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 109ms/step - accuracy: 0.8779 - loss: 0.5521 - val_accuracy: 0.6053 - val_loss: 1.4393 - learning_rate: 3.1250e-06\n",
      "Epoch 43/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.8600 - loss: 0.5476 \n",
      "Epoch 43: val_accuracy did not improve from 0.63684\n",
      "\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 109ms/step - accuracy: 0.8597 - loss: 0.5484 - val_accuracy: 0.6211 - val_loss: 1.4389 - learning_rate: 3.1250e-06\n",
      "Epoch 44/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.8671 - loss: 0.5287\n",
      "Epoch 44: val_accuracy did not improve from 0.63684\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 109ms/step - accuracy: 0.8671 - loss: 0.5289 - val_accuracy: 0.6158 - val_loss: 1.4285 - learning_rate: 1.5625e-06\n",
      "Epoch 45/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.8632 - loss: 0.5416 \n",
      "Epoch 45: val_accuracy did not improve from 0.63684\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 108ms/step - accuracy: 0.8632 - loss: 0.5418 - val_accuracy: 0.6105 - val_loss: 1.4316 - learning_rate: 1.5625e-06\n",
      "Epoch 46/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.8642 - loss: 0.5284 \n",
      "Epoch 46: val_accuracy did not improve from 0.63684\n",
      "\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 108ms/step - accuracy: 0.8641 - loss: 0.5287 - val_accuracy: 0.6105 - val_loss: 1.4375 - learning_rate: 1.5625e-06\n",
      "Epoch 47/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.8620 - loss: 0.5102\n",
      "Epoch 47: val_accuracy did not improve from 0.63684\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 110ms/step - accuracy: 0.8621 - loss: 0.5103 - val_accuracy: 0.6105 - val_loss: 1.4312 - learning_rate: 7.8125e-07\n",
      "Epoch 48/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.8753 - loss: 0.5094\n",
      "Epoch 48: val_accuracy did not improve from 0.63684\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 109ms/step - accuracy: 0.8752 - loss: 0.5100 - val_accuracy: 0.6105 - val_loss: 1.4144 - learning_rate: 7.8125e-07\n",
      "Epoch 49/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.8621 - loss: 0.5480\n",
      "Epoch 49: val_accuracy did not improve from 0.63684\n",
      "\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 109ms/step - accuracy: 0.8623 - loss: 0.5477 - val_accuracy: 0.6105 - val_loss: 1.4136 - learning_rate: 7.8125e-07\n",
      "Epoch 50/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.8664 - loss: 0.5474\n",
      "Epoch 50: val_accuracy did not improve from 0.63684\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 109ms/step - accuracy: 0.8664 - loss: 0.5474 - val_accuracy: 0.6105 - val_loss: 1.4228 - learning_rate: 3.9062e-07\n",
      "Phase 2 completed in 5.22 minutes\n",
      "Best model saved: /kaggle/working/outputs_10_90_v2/models/ResNet50_10_90/best_model_phase2.h5\n",
      "\n",
      "Loading best model from Phase 2...\n",
      "\n",
      "Comprehensive evaluation: ResNet50 on 10_90\n",
      "Accuracy: 58.36%\n",
      "F1-Score (Macro): 0.5620\n",
      "Precision (Macro): 0.6794\n",
      "Recall (Macro): 0.5836\n",
      "ROC-AUC (Macro): 0.9792\n",
      "Training analysis saved: /kaggle/working/outputs_10_90_v2/plots/ResNet50_10_90/training_analysis.png\n",
      "Confusion matrix analysis saved: /kaggle/working/outputs_10_90_v2/plots/ResNet50_10_90/confusion_matrix_analysis.png\n",
      "\n",
      "ResNet50 Summary:\n",
      "  Test Accuracy: 58.36%\n",
      "  F1-Score: 0.5620\n",
      "  Total Training Time: 6.6 minutes\n",
      "\n",
      "==========================================================================================\n",
      "MODEL: EfficientNetB0\n",
      "==========================================================================================\n",
      "Building EfficientNetB0 with enhanced architecture...\n",
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
      "\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
      "Model ready: 4,851,657 parameters\n",
      "\n",
      "Preparing data pipelines...\n",
      "\n",
      "PHASE 1: Training classifier head (backbone frozen)\n",
      "Epochs: 10, Learning Rate: 0.001\n",
      "Trainable parameters: 799,526\n",
      "Epoch 1/10\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - accuracy: 0.0594 - loss: 4.3654\n",
      "Epoch 1: val_accuracy improved from -inf to 0.21579, saving model to /kaggle/working/outputs_10_90_v2/models/EfficientNetB0_10_90/best_model_phase1.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 475ms/step - accuracy: 0.0600 - loss: 4.3569 - val_accuracy: 0.2158 - val_loss: 3.4055 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.1910 - loss: 3.1824\n",
      "Epoch 2: val_accuracy improved from 0.21579 to 0.34211, saving model to /kaggle/working/outputs_10_90_v2/models/EfficientNetB0_10_90/best_model_phase1.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step - accuracy: 0.1914 - loss: 3.1787 - val_accuracy: 0.3421 - val_loss: 3.0582 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.2405 - loss: 2.8200\n",
      "Epoch 3: val_accuracy did not improve from 0.34211\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step - accuracy: 0.2414 - loss: 2.8162 - val_accuracy: 0.3316 - val_loss: 2.6407 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.3256 - loss: 2.4030\n",
      "Epoch 4: val_accuracy improved from 0.34211 to 0.44737, saving model to /kaggle/working/outputs_10_90_v2/models/EfficientNetB0_10_90/best_model_phase1.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 81ms/step - accuracy: 0.3252 - loss: 2.4032 - val_accuracy: 0.4474 - val_loss: 2.3623 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.3540 - loss: 2.2732\n",
      "Epoch 5: val_accuracy did not improve from 0.44737\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - accuracy: 0.3539 - loss: 2.2733 - val_accuracy: 0.4474 - val_loss: 2.0936 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.3953 - loss: 2.1095\n",
      "Epoch 6: val_accuracy improved from 0.44737 to 0.50526, saving model to /kaggle/working/outputs_10_90_v2/models/EfficientNetB0_10_90/best_model_phase1.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step - accuracy: 0.3947 - loss: 2.1115 - val_accuracy: 0.5053 - val_loss: 1.8965 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.4108 - loss: 2.0775\n",
      "Epoch 7: val_accuracy improved from 0.50526 to 0.54737, saving model to /kaggle/working/outputs_10_90_v2/models/EfficientNetB0_10_90/best_model_phase1.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step - accuracy: 0.4107 - loss: 2.0774 - val_accuracy: 0.5474 - val_loss: 1.7051 - learning_rate: 0.0010\n",
      "Epoch 8/10\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.4151 - loss: 2.0078\n",
      "Epoch 8: val_accuracy did not improve from 0.54737\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - accuracy: 0.4153 - loss: 2.0062 - val_accuracy: 0.5263 - val_loss: 1.5753 - learning_rate: 0.0010\n",
      "Epoch 9/10\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.4762 - loss: 1.7988\n",
      "Epoch 9: val_accuracy did not improve from 0.54737\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - accuracy: 0.4755 - loss: 1.8009 - val_accuracy: 0.5158 - val_loss: 1.5786 - learning_rate: 0.0010\n",
      "Epoch 10/10\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.4895 - loss: 1.7340\n",
      "Epoch 10: val_accuracy did not improve from 0.54737\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - accuracy: 0.4895 - loss: 1.7342 - val_accuracy: 0.5316 - val_loss: 1.5739 - learning_rate: 0.0010\n",
      "Phase 1 completed in 1.45 minutes\n",
      "Best model saved: /kaggle/working/outputs_10_90_v2/models/EfficientNetB0_10_90/best_model_phase1.h5\n",
      "\n",
      "PHASE 2: Fine-tuning entire model (backbone unfrozen)\n",
      "Epochs: 40, Learning Rate: 0.0001\n",
      "Unfreezing last 119/238 layers of backbone\n",
      "Trainable parameters: 4,498,414\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1761576938.239270     101 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1761576938.428521     101 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1761576938.904737     101 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1761576939.111463     101 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1761576939.476223     101 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1761576939.682991     101 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.2395 - loss: 2.7816"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1761576961.313288     101 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1761576961.498509     101 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1761576961.924907     101 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1761576962.130421     101 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1761576962.477948     101 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1761576962.683431     101 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432ms/step - accuracy: 0.2399 - loss: 2.7791\n",
      "Epoch 11: val_accuracy improved from -inf to 0.41053, saving model to /kaggle/working/outputs_10_90_v2/models/EfficientNetB0_10_90/best_model_phase2.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 634ms/step - accuracy: 0.2403 - loss: 2.7767 - val_accuracy: 0.4105 - val_loss: 2.1803 - learning_rate: 1.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.3986 - loss: 2.1502\n",
      "Epoch 12: val_accuracy improved from 0.41053 to 0.46316, saving model to /kaggle/working/outputs_10_90_v2/models/EfficientNetB0_10_90/best_model_phase2.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 0.3983 - loss: 2.1499 - val_accuracy: 0.4632 - val_loss: 2.0685 - learning_rate: 1.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.4153 - loss: 2.0288\n",
      "Epoch 13: val_accuracy did not improve from 0.46316\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 0.4159 - loss: 2.0253 - val_accuracy: 0.4632 - val_loss: 1.8889 - learning_rate: 1.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.4646 - loss: 1.8590\n",
      "Epoch 14: val_accuracy did not improve from 0.46316\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 0.4648 - loss: 1.8569 - val_accuracy: 0.4579 - val_loss: 1.7066 - learning_rate: 1.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.5390 - loss: 1.5896\n",
      "Epoch 15: val_accuracy improved from 0.46316 to 0.50526, saving model to /kaggle/working/outputs_10_90_v2/models/EfficientNetB0_10_90/best_model_phase2.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - accuracy: 0.5385 - loss: 1.5907 - val_accuracy: 0.5053 - val_loss: 1.6847 - learning_rate: 1.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.5441 - loss: 1.5352\n",
      "Epoch 16: val_accuracy did not improve from 0.50526\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 0.5438 - loss: 1.5355 - val_accuracy: 0.4737 - val_loss: 1.7010 - learning_rate: 1.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.5914 - loss: 1.3852\n",
      "Epoch 17: val_accuracy did not improve from 0.50526\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 0.5905 - loss: 1.3883 - val_accuracy: 0.4947 - val_loss: 1.6259 - learning_rate: 1.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.6011 - loss: 1.3437\n",
      "Epoch 18: val_accuracy improved from 0.50526 to 0.53158, saving model to /kaggle/working/outputs_10_90_v2/models/EfficientNetB0_10_90/best_model_phase2.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 82ms/step - accuracy: 0.6009 - loss: 1.3437 - val_accuracy: 0.5316 - val_loss: 1.5605 - learning_rate: 1.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.6166 - loss: 1.2923\n",
      "Epoch 19: val_accuracy did not improve from 0.53158\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 0.6166 - loss: 1.2925 - val_accuracy: 0.5158 - val_loss: 1.5225 - learning_rate: 1.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.6224 - loss: 1.2851\n",
      "Epoch 20: val_accuracy did not improve from 0.53158\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 0.6226 - loss: 1.2834 - val_accuracy: 0.5000 - val_loss: 1.6685 - learning_rate: 1.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.6599 - loss: 1.1651\n",
      "Epoch 21: val_accuracy did not improve from 0.53158\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 0.6597 - loss: 1.1664 - val_accuracy: 0.5000 - val_loss: 1.4963 - learning_rate: 1.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.6787 - loss: 1.0814\n",
      "Epoch 22: val_accuracy did not improve from 0.53158\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 0.6785 - loss: 1.0821 - val_accuracy: 0.4895 - val_loss: 1.6744 - learning_rate: 1.0000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.6918 - loss: 1.0802\n",
      "Epoch 23: val_accuracy did not improve from 0.53158\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step - accuracy: 0.6916 - loss: 1.0810 - val_accuracy: 0.4842 - val_loss: 1.6471 - learning_rate: 1.0000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.7132 - loss: 1.0228\n",
      "Epoch 24: val_accuracy improved from 0.53158 to 0.53684, saving model to /kaggle/working/outputs_10_90_v2/models/EfficientNetB0_10_90/best_model_phase2.h5\n",
      "\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 81ms/step - accuracy: 0.7126 - loss: 1.0242 - val_accuracy: 0.5368 - val_loss: 1.5899 - learning_rate: 1.0000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.7067 - loss: 1.0142\n",
      "Epoch 25: val_accuracy improved from 0.53684 to 0.56316, saving model to /kaggle/working/outputs_10_90_v2/models/EfficientNetB0_10_90/best_model_phase2.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - accuracy: 0.7065 - loss: 1.0145 - val_accuracy: 0.5632 - val_loss: 1.4669 - learning_rate: 5.0000e-05\n",
      "Epoch 26/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.6980 - loss: 1.0332\n",
      "Epoch 26: val_accuracy improved from 0.56316 to 0.60000, saving model to /kaggle/working/outputs_10_90_v2/models/EfficientNetB0_10_90/best_model_phase2.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 81ms/step - accuracy: 0.6980 - loss: 1.0329 - val_accuracy: 0.6000 - val_loss: 1.3907 - learning_rate: 5.0000e-05\n",
      "Epoch 27/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.7176 - loss: 0.9702\n",
      "Epoch 27: val_accuracy did not improve from 0.60000\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 0.7173 - loss: 0.9704 - val_accuracy: 0.5947 - val_loss: 1.4419 - learning_rate: 5.0000e-05\n",
      "Epoch 28/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.7433 - loss: 0.8680\n",
      "Epoch 28: val_accuracy did not improve from 0.60000\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 0.7432 - loss: 0.8691 - val_accuracy: 0.5947 - val_loss: 1.4388 - learning_rate: 5.0000e-05\n",
      "Epoch 29/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.7416 - loss: 0.8872\n",
      "Epoch 29: val_accuracy did not improve from 0.60000\n",
      "\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 0.7418 - loss: 0.8874 - val_accuracy: 0.6000 - val_loss: 1.4282 - learning_rate: 5.0000e-05\n",
      "Epoch 30/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.7425 - loss: 0.8986\n",
      "Epoch 30: val_accuracy did not improve from 0.60000\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 0.7421 - loss: 0.8994 - val_accuracy: 0.5842 - val_loss: 1.3839 - learning_rate: 2.5000e-05\n",
      "Epoch 31/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.7172 - loss: 0.9229\n",
      "Epoch 31: val_accuracy did not improve from 0.60000\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 0.7179 - loss: 0.9219 - val_accuracy: 0.5947 - val_loss: 1.3517 - learning_rate: 2.5000e-05\n",
      "Epoch 32/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.7252 - loss: 0.9216\n",
      "Epoch 32: val_accuracy improved from 0.60000 to 0.61053, saving model to /kaggle/working/outputs_10_90_v2/models/EfficientNetB0_10_90/best_model_phase2.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - accuracy: 0.7255 - loss: 0.9219 - val_accuracy: 0.6105 - val_loss: 1.3619 - learning_rate: 2.5000e-05\n",
      "Epoch 33/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.7378 - loss: 0.8977\n",
      "Epoch 33: val_accuracy did not improve from 0.61053\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 0.7381 - loss: 0.8969 - val_accuracy: 0.5947 - val_loss: 1.3786 - learning_rate: 2.5000e-05\n",
      "Epoch 34/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.7416 - loss: 0.8504\n",
      "Epoch 34: val_accuracy did not improve from 0.61053\n",
      "\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 0.7417 - loss: 0.8502 - val_accuracy: 0.5947 - val_loss: 1.4004 - learning_rate: 2.5000e-05\n",
      "Epoch 35/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.7444 - loss: 0.8689\n",
      "Epoch 35: val_accuracy did not improve from 0.61053\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 0.7447 - loss: 0.8683 - val_accuracy: 0.5895 - val_loss: 1.4009 - learning_rate: 1.2500e-05\n",
      "Epoch 36/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.7512 - loss: 0.8276\n",
      "Epoch 36: val_accuracy did not improve from 0.61053\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 0.7512 - loss: 0.8277 - val_accuracy: 0.5895 - val_loss: 1.4071 - learning_rate: 1.2500e-05\n",
      "Epoch 37/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7747 - loss: 0.7818\n",
      "Epoch 37: val_accuracy did not improve from 0.61053\n",
      "\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 0.7752 - loss: 0.7809 - val_accuracy: 0.5947 - val_loss: 1.4141 - learning_rate: 1.2500e-05\n",
      "Epoch 38/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.7443 - loss: 0.8577\n",
      "Epoch 38: val_accuracy did not improve from 0.61053\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 0.7446 - loss: 0.8575 - val_accuracy: 0.6000 - val_loss: 1.3977 - learning_rate: 6.2500e-06\n",
      "Epoch 39/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7599 - loss: 0.8342\n",
      "Epoch 39: val_accuracy did not improve from 0.61053\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 0.7600 - loss: 0.8341 - val_accuracy: 0.5895 - val_loss: 1.4195 - learning_rate: 6.2500e-06\n",
      "Epoch 40/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.7570 - loss: 0.8732\n",
      "Epoch 40: val_accuracy did not improve from 0.61053\n",
      "\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 0.7570 - loss: 0.8721 - val_accuracy: 0.5842 - val_loss: 1.4018 - learning_rate: 6.2500e-06\n",
      "Epoch 41/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.7555 - loss: 0.8525\n",
      "Epoch 41: val_accuracy did not improve from 0.61053\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 0.7556 - loss: 0.8520 - val_accuracy: 0.5895 - val_loss: 1.3952 - learning_rate: 3.1250e-06\n",
      "Epoch 42/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.7524 - loss: 0.8431\n",
      "Epoch 42: val_accuracy did not improve from 0.61053\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 0.7525 - loss: 0.8431 - val_accuracy: 0.5947 - val_loss: 1.3920 - learning_rate: 3.1250e-06\n",
      "Epoch 43/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.7685 - loss: 0.8013\n",
      "Epoch 43: val_accuracy did not improve from 0.61053\n",
      "\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 0.7683 - loss: 0.8020 - val_accuracy: 0.5895 - val_loss: 1.3995 - learning_rate: 3.1250e-06\n",
      "Epoch 44/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.7606 - loss: 0.8459\n",
      "Epoch 44: val_accuracy did not improve from 0.61053\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 0.7602 - loss: 0.8460 - val_accuracy: 0.5895 - val_loss: 1.4010 - learning_rate: 1.5625e-06\n",
      "Epoch 45/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.7655 - loss: 0.8125\n",
      "Epoch 45: val_accuracy did not improve from 0.61053\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 0.7657 - loss: 0.8122 - val_accuracy: 0.5947 - val_loss: 1.3990 - learning_rate: 1.5625e-06\n",
      "Epoch 46/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.7784 - loss: 0.7838\n",
      "Epoch 46: val_accuracy did not improve from 0.61053\n",
      "\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 0.7784 - loss: 0.7844 - val_accuracy: 0.5895 - val_loss: 1.4033 - learning_rate: 1.5625e-06\n",
      "Epoch 47/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.7643 - loss: 0.8361\n",
      "Epoch 47: val_accuracy did not improve from 0.61053\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 0.7641 - loss: 0.8356 - val_accuracy: 0.5895 - val_loss: 1.4011 - learning_rate: 7.8125e-07\n",
      "Epoch 48/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.7875 - loss: 0.7643\n",
      "Epoch 48: val_accuracy did not improve from 0.61053\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 0.7871 - loss: 0.7652 - val_accuracy: 0.5947 - val_loss: 1.3917 - learning_rate: 7.8125e-07\n",
      "Epoch 49/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.7576 - loss: 0.8522\n",
      "Epoch 49: val_accuracy did not improve from 0.61053\n",
      "\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 0.7576 - loss: 0.8516 - val_accuracy: 0.5947 - val_loss: 1.3960 - learning_rate: 7.8125e-07\n",
      "Epoch 50/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7522 - loss: 0.8645\n",
      "Epoch 50: val_accuracy did not improve from 0.61053\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 0.7521 - loss: 0.8634 - val_accuracy: 0.6000 - val_loss: 1.4046 - learning_rate: 3.9062e-07\n",
      "Phase 2 completed in 4.07 minutes\n",
      "Best model saved: /kaggle/working/outputs_10_90_v2/models/EfficientNetB0_10_90/best_model_phase2.h5\n",
      "\n",
      "Loading best model from Phase 2...\n",
      "\n",
      "Comprehensive evaluation: EfficientNetB0 on 10_90\n",
      "Accuracy: 41.94%\n",
      "F1-Score (Macro): 0.3888\n",
      "Precision (Macro): 0.5338\n",
      "Recall (Macro): 0.4194\n",
      "ROC-AUC (Macro): 0.9502\n",
      "Training analysis saved: /kaggle/working/outputs_10_90_v2/plots/EfficientNetB0_10_90/training_analysis.png\n",
      "Confusion matrix analysis saved: /kaggle/working/outputs_10_90_v2/plots/EfficientNetB0_10_90/confusion_matrix_analysis.png\n",
      "\n",
      "EfficientNetB0 Summary:\n",
      "  Test Accuracy: 41.94%\n",
      "  F1-Score: 0.3888\n",
      "  Total Training Time: 5.5 minutes\n",
      "\n",
      "==========================================================================================\n",
      "MODEL: MobileNetV2\n",
      "==========================================================================================\n",
      "Building MobileNetV2 with enhanced architecture...\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
      "Model ready: 3,060,070 parameters\n",
      "\n",
      "Preparing data pipelines...\n",
      "\n",
      "PHASE 1: Training classifier head (backbone frozen)\n",
      "Epochs: 10, Learning Rate: 0.001\n",
      "Trainable parameters: 799,526\n",
      "Epoch 1/10\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.0668 - loss: 4.2938\n",
      "Epoch 1: val_accuracy improved from -inf to 0.24211, saving model to /kaggle/working/outputs_10_90_v2/models/MobileNetV2_10_90/best_model_phase1.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 271ms/step - accuracy: 0.0673 - loss: 4.2856 - val_accuracy: 0.2421 - val_loss: 3.0925 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.1991 - loss: 3.0269\n",
      "Epoch 2: val_accuracy improved from 0.24211 to 0.34211, saving model to /kaggle/working/outputs_10_90_v2/models/MobileNetV2_10_90/best_model_phase1.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step - accuracy: 0.1995 - loss: 3.0249 - val_accuracy: 0.3421 - val_loss: 2.7041 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.2622 - loss: 2.7271\n",
      "Epoch 3: val_accuracy improved from 0.34211 to 0.44211, saving model to /kaggle/working/outputs_10_90_v2/models/MobileNetV2_10_90/best_model_phase1.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step - accuracy: 0.2626 - loss: 2.7243 - val_accuracy: 0.4421 - val_loss: 2.3237 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.3496 - loss: 2.4047\n",
      "Epoch 4: val_accuracy did not improve from 0.44211\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 0.3489 - loss: 2.4049 - val_accuracy: 0.4211 - val_loss: 2.1143 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.3612 - loss: 2.2506\n",
      "Epoch 5: val_accuracy did not improve from 0.44211\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - accuracy: 0.3611 - loss: 2.2507 - val_accuracy: 0.4316 - val_loss: 2.0263 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.3873 - loss: 2.0946\n",
      "Epoch 6: val_accuracy improved from 0.44211 to 0.45789, saving model to /kaggle/working/outputs_10_90_v2/models/MobileNetV2_10_90/best_model_phase1.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 75ms/step - accuracy: 0.3876 - loss: 2.0951 - val_accuracy: 0.4579 - val_loss: 1.8886 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.4255 - loss: 2.0018\n",
      "Epoch 7: val_accuracy did not improve from 0.45789\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 0.4250 - loss: 2.0029 - val_accuracy: 0.4526 - val_loss: 1.7835 - learning_rate: 0.0010\n",
      "Epoch 8/10\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.4475 - loss: 1.9155\n",
      "Epoch 8: val_accuracy improved from 0.45789 to 0.48947, saving model to /kaggle/working/outputs_10_90_v2/models/MobileNetV2_10_90/best_model_phase1.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step - accuracy: 0.4474 - loss: 1.9156 - val_accuracy: 0.4895 - val_loss: 1.7295 - learning_rate: 0.0010\n",
      "Epoch 9/10\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.4821 - loss: 1.7830\n",
      "Epoch 9: val_accuracy improved from 0.48947 to 0.50526, saving model to /kaggle/working/outputs_10_90_v2/models/MobileNetV2_10_90/best_model_phase1.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step - accuracy: 0.4819 - loss: 1.7839 - val_accuracy: 0.5053 - val_loss: 1.6810 - learning_rate: 0.0010\n",
      "Epoch 10/10\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.4975 - loss: 1.7376\n",
      "Epoch 10: val_accuracy did not improve from 0.50526\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - accuracy: 0.4969 - loss: 1.7386 - val_accuracy: 0.4947 - val_loss: 1.7139 - learning_rate: 0.0010\n",
      "Phase 1 completed in 1.01 minutes\n",
      "Best model saved: /kaggle/working/outputs_10_90_v2/models/MobileNetV2_10_90/best_model_phase1.h5\n",
      "\n",
      "PHASE 2: Fine-tuning entire model (backbone unfrozen)\n",
      "Epochs: 40, Learning Rate: 0.0001\n",
      "Unfreezing last 77/154 layers of backbone\n",
      "Trainable parameters: 2,863,014\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1761577274.630214     102 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1761577274.827318     102 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m52/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.2595 - loss: 2.7248"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1761577288.516362     101 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1761577288.712396     101 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - accuracy: 0.2611 - loss: 2.7164\n",
      "Epoch 11: val_accuracy improved from -inf to 0.19474, saving model to /kaggle/working/outputs_10_90_v2/models/MobileNetV2_10_90/best_model_phase2.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 357ms/step - accuracy: 0.2618 - loss: 2.7124 - val_accuracy: 0.1947 - val_loss: 4.9519 - learning_rate: 1.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.4224 - loss: 1.9687\n",
      "Epoch 12: val_accuracy did not improve from 0.19474\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 0.4225 - loss: 1.9680 - val_accuracy: 0.1895 - val_loss: 4.2517 - learning_rate: 1.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.4729 - loss: 1.8557\n",
      "Epoch 13: val_accuracy did not improve from 0.19474\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - accuracy: 0.4732 - loss: 1.8537 - val_accuracy: 0.1737 - val_loss: 4.9444 - learning_rate: 1.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.5055 - loss: 1.7012\n",
      "Epoch 14: val_accuracy did not improve from 0.19474\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 0.5052 - loss: 1.7011 - val_accuracy: 0.1579 - val_loss: 4.9202 - learning_rate: 1.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.5440 - loss: 1.5200\n",
      "Epoch 15: val_accuracy did not improve from 0.19474\n",
      "\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 0.5443 - loss: 1.5201 - val_accuracy: 0.1684 - val_loss: 5.6207 - learning_rate: 1.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.5607 - loss: 1.4613\n",
      "Epoch 16: val_accuracy did not improve from 0.19474\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - accuracy: 0.5607 - loss: 1.4618 - val_accuracy: 0.1579 - val_loss: 6.0252 - learning_rate: 5.0000e-05\n",
      "Epoch 17/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.6229 - loss: 1.3106\n",
      "Epoch 17: val_accuracy did not improve from 0.19474\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 0.6220 - loss: 1.3126 - val_accuracy: 0.1737 - val_loss: 5.5008 - learning_rate: 5.0000e-05\n",
      "Epoch 18/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.6175 - loss: 1.3248\n",
      "Epoch 18: val_accuracy improved from 0.19474 to 0.21053, saving model to /kaggle/working/outputs_10_90_v2/models/MobileNetV2_10_90/best_model_phase2.h5\n",
      "\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 77ms/step - accuracy: 0.6170 - loss: 1.3268 - val_accuracy: 0.2105 - val_loss: 4.8740 - learning_rate: 5.0000e-05\n",
      "Epoch 19/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.6107 - loss: 1.2770\n",
      "Epoch 19: val_accuracy improved from 0.21053 to 0.22105, saving model to /kaggle/working/outputs_10_90_v2/models/MobileNetV2_10_90/best_model_phase2.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 77ms/step - accuracy: 0.6105 - loss: 1.2776 - val_accuracy: 0.2211 - val_loss: 4.7761 - learning_rate: 2.5000e-05\n",
      "Epoch 20/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.6328 - loss: 1.2060\n",
      "Epoch 20: val_accuracy improved from 0.22105 to 0.23158, saving model to /kaggle/working/outputs_10_90_v2/models/MobileNetV2_10_90/best_model_phase2.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 77ms/step - accuracy: 0.6331 - loss: 1.2055 - val_accuracy: 0.2316 - val_loss: 4.7692 - learning_rate: 2.5000e-05\n",
      "Epoch 21/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.6186 - loss: 1.2494\n",
      "Epoch 21: val_accuracy improved from 0.23158 to 0.26316, saving model to /kaggle/working/outputs_10_90_v2/models/MobileNetV2_10_90/best_model_phase2.h5\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 77ms/step - accuracy: 0.6189 - loss: 1.2498 - val_accuracy: 0.2632 - val_loss: 4.6096 - learning_rate: 2.5000e-05\n",
      "Epoch 22/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.6372 - loss: 1.2154\n",
      "Epoch 22: val_accuracy improved from 0.26316 to 0.26842, saving model to /kaggle/working/outputs_10_90_v2/models/MobileNetV2_10_90/best_model_phase2.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 78ms/step - accuracy: 0.6370 - loss: 1.2158 - val_accuracy: 0.2684 - val_loss: 4.4924 - learning_rate: 1.2500e-05\n",
      "Epoch 23/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.6396 - loss: 1.1870\n",
      "Epoch 23: val_accuracy did not improve from 0.26842\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 0.6392 - loss: 1.1887 - val_accuracy: 0.2632 - val_loss: 4.3068 - learning_rate: 1.2500e-05\n",
      "Epoch 24/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.6264 - loss: 1.2134\n",
      "Epoch 24: val_accuracy improved from 0.26842 to 0.27368, saving model to /kaggle/working/outputs_10_90_v2/models/MobileNetV2_10_90/best_model_phase2.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 78ms/step - accuracy: 0.6269 - loss: 1.2127 - val_accuracy: 0.2737 - val_loss: 4.0559 - learning_rate: 1.2500e-05\n",
      "Epoch 25/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.6366 - loss: 1.2054\n",
      "Epoch 25: val_accuracy improved from 0.27368 to 0.28421, saving model to /kaggle/working/outputs_10_90_v2/models/MobileNetV2_10_90/best_model_phase2.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 0.6367 - loss: 1.2049 - val_accuracy: 0.2842 - val_loss: 3.9342 - learning_rate: 1.2500e-05\n",
      "Epoch 26/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.6292 - loss: 1.2008\n",
      "Epoch 26: val_accuracy improved from 0.28421 to 0.28947, saving model to /kaggle/working/outputs_10_90_v2/models/MobileNetV2_10_90/best_model_phase2.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 78ms/step - accuracy: 0.6293 - loss: 1.2004 - val_accuracy: 0.2895 - val_loss: 3.9994 - learning_rate: 1.2500e-05\n",
      "Epoch 27/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.6420 - loss: 1.1811\n",
      "Epoch 27: val_accuracy improved from 0.28947 to 0.29474, saving model to /kaggle/working/outputs_10_90_v2/models/MobileNetV2_10_90/best_model_phase2.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 78ms/step - accuracy: 0.6418 - loss: 1.1823 - val_accuracy: 0.2947 - val_loss: 4.0020 - learning_rate: 1.2500e-05\n",
      "Epoch 28/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.6476 - loss: 1.1691\n",
      "Epoch 28: val_accuracy improved from 0.29474 to 0.31053, saving model to /kaggle/working/outputs_10_90_v2/models/MobileNetV2_10_90/best_model_phase2.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 76ms/step - accuracy: 0.6479 - loss: 1.1689 - val_accuracy: 0.3105 - val_loss: 3.7784 - learning_rate: 1.2500e-05\n",
      "Epoch 29/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.6707 - loss: 1.1509\n",
      "Epoch 29: val_accuracy improved from 0.31053 to 0.32105, saving model to /kaggle/working/outputs_10_90_v2/models/MobileNetV2_10_90/best_model_phase2.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 77ms/step - accuracy: 0.6707 - loss: 1.1500 - val_accuracy: 0.3211 - val_loss: 3.6403 - learning_rate: 1.2500e-05\n",
      "Epoch 30/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.6696 - loss: 1.1372\n",
      "Epoch 30: val_accuracy improved from 0.32105 to 0.35263, saving model to /kaggle/working/outputs_10_90_v2/models/MobileNetV2_10_90/best_model_phase2.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 76ms/step - accuracy: 0.6694 - loss: 1.1368 - val_accuracy: 0.3526 - val_loss: 3.3515 - learning_rate: 1.2500e-05\n",
      "Epoch 31/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.6599 - loss: 1.1068\n",
      "Epoch 31: val_accuracy did not improve from 0.35263\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 0.6608 - loss: 1.1050 - val_accuracy: 0.3474 - val_loss: 3.2953 - learning_rate: 1.2500e-05\n",
      "Epoch 32/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.6844 - loss: 1.1167\n",
      "Epoch 32: val_accuracy improved from 0.35263 to 0.38421, saving model to /kaggle/working/outputs_10_90_v2/models/MobileNetV2_10_90/best_model_phase2.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 78ms/step - accuracy: 0.6844 - loss: 1.1166 - val_accuracy: 0.3842 - val_loss: 3.0529 - learning_rate: 1.2500e-05\n",
      "Epoch 33/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.6468 - loss: 1.1268\n",
      "Epoch 33: val_accuracy improved from 0.38421 to 0.39474, saving model to /kaggle/working/outputs_10_90_v2/models/MobileNetV2_10_90/best_model_phase2.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 77ms/step - accuracy: 0.6475 - loss: 1.1262 - val_accuracy: 0.3947 - val_loss: 3.0390 - learning_rate: 1.2500e-05\n",
      "Epoch 34/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.6822 - loss: 1.1352\n",
      "Epoch 34: val_accuracy did not improve from 0.39474\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 0.6820 - loss: 1.1337 - val_accuracy: 0.3947 - val_loss: 2.8778 - learning_rate: 1.2500e-05\n",
      "Epoch 35/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.6827 - loss: 1.1028\n",
      "Epoch 35: val_accuracy improved from 0.39474 to 0.40526, saving model to /kaggle/working/outputs_10_90_v2/models/MobileNetV2_10_90/best_model_phase2.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 77ms/step - accuracy: 0.6825 - loss: 1.1015 - val_accuracy: 0.4053 - val_loss: 2.8935 - learning_rate: 1.2500e-05\n",
      "Epoch 36/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7135 - loss: 0.9794\n",
      "Epoch 36: val_accuracy did not improve from 0.40526\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 0.7131 - loss: 0.9814 - val_accuracy: 0.4053 - val_loss: 2.8708 - learning_rate: 1.2500e-05\n",
      "Epoch 37/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.6612 - loss: 1.1013\n",
      "Epoch 37: val_accuracy improved from 0.40526 to 0.41579, saving model to /kaggle/working/outputs_10_90_v2/models/MobileNetV2_10_90/best_model_phase2.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 76ms/step - accuracy: 0.6621 - loss: 1.0995 - val_accuracy: 0.4158 - val_loss: 2.8042 - learning_rate: 1.2500e-05\n",
      "Epoch 38/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.6703 - loss: 1.0865\n",
      "Epoch 38: val_accuracy did not improve from 0.41579\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 0.6711 - loss: 1.0848 - val_accuracy: 0.4053 - val_loss: 2.7474 - learning_rate: 1.2500e-05\n",
      "Epoch 39/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.6832 - loss: 1.0623\n",
      "Epoch 39: val_accuracy improved from 0.41579 to 0.43158, saving model to /kaggle/working/outputs_10_90_v2/models/MobileNetV2_10_90/best_model_phase2.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 78ms/step - accuracy: 0.6835 - loss: 1.0616 - val_accuracy: 0.4316 - val_loss: 2.5186 - learning_rate: 1.2500e-05\n",
      "Epoch 40/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.7258 - loss: 0.9581\n",
      "Epoch 40: val_accuracy did not improve from 0.43158\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 0.7251 - loss: 0.9600 - val_accuracy: 0.4316 - val_loss: 2.4380 - learning_rate: 1.2500e-05\n",
      "Epoch 41/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.7078 - loss: 1.0508\n",
      "Epoch 41: val_accuracy improved from 0.43158 to 0.45263, saving model to /kaggle/working/outputs_10_90_v2/models/MobileNetV2_10_90/best_model_phase2.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 77ms/step - accuracy: 0.7077 - loss: 1.0498 - val_accuracy: 0.4526 - val_loss: 2.3143 - learning_rate: 1.2500e-05\n",
      "Epoch 42/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.7022 - loss: 1.0260\n",
      "Epoch 42: val_accuracy improved from 0.45263 to 0.46316, saving model to /kaggle/working/outputs_10_90_v2/models/MobileNetV2_10_90/best_model_phase2.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 0.7026 - loss: 1.0247 - val_accuracy: 0.4632 - val_loss: 2.3646 - learning_rate: 1.2500e-05\n",
      "Epoch 43/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7095 - loss: 0.9636\n",
      "Epoch 43: val_accuracy did not improve from 0.46316\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 0.7095 - loss: 0.9646 - val_accuracy: 0.4632 - val_loss: 2.2932 - learning_rate: 1.2500e-05\n",
      "Epoch 44/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.7129 - loss: 0.9863\n",
      "Epoch 44: val_accuracy improved from 0.46316 to 0.46842, saving model to /kaggle/working/outputs_10_90_v2/models/MobileNetV2_10_90/best_model_phase2.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 78ms/step - accuracy: 0.7128 - loss: 0.9867 - val_accuracy: 0.4684 - val_loss: 2.2686 - learning_rate: 1.2500e-05\n",
      "Epoch 45/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.7049 - loss: 1.0140\n",
      "Epoch 45: val_accuracy did not improve from 0.46842\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step - accuracy: 0.7049 - loss: 1.0134 - val_accuracy: 0.4684 - val_loss: 2.2340 - learning_rate: 1.2500e-05\n",
      "Epoch 46/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.7227 - loss: 0.9776\n",
      "Epoch 46: val_accuracy improved from 0.46842 to 0.48421, saving model to /kaggle/working/outputs_10_90_v2/models/MobileNetV2_10_90/best_model_phase2.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 78ms/step - accuracy: 0.7226 - loss: 0.9777 - val_accuracy: 0.4842 - val_loss: 2.2155 - learning_rate: 1.2500e-05\n",
      "Epoch 47/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.7158 - loss: 0.9278\n",
      "Epoch 47: val_accuracy improved from 0.48421 to 0.50526, saving model to /kaggle/working/outputs_10_90_v2/models/MobileNetV2_10_90/best_model_phase2.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - accuracy: 0.7159 - loss: 0.9282 - val_accuracy: 0.5053 - val_loss: 2.1341 - learning_rate: 1.2500e-05\n",
      "Epoch 48/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.7201 - loss: 0.9510\n",
      "Epoch 48: val_accuracy did not improve from 0.50526\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 0.7199 - loss: 0.9514 - val_accuracy: 0.4947 - val_loss: 2.1640 - learning_rate: 1.2500e-05\n",
      "Epoch 49/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.7063 - loss: 0.9936\n",
      "Epoch 49: val_accuracy did not improve from 0.50526\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 0.7068 - loss: 0.9921 - val_accuracy: 0.5000 - val_loss: 2.0904 - learning_rate: 1.2500e-05\n",
      "Epoch 50/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.7183 - loss: 0.9223\n",
      "Epoch 50: val_accuracy improved from 0.50526 to 0.51053, saving model to /kaggle/working/outputs_10_90_v2/models/MobileNetV2_10_90/best_model_phase2.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 81ms/step - accuracy: 0.7184 - loss: 0.9230 - val_accuracy: 0.5105 - val_loss: 2.0444 - learning_rate: 1.2500e-05\n",
      "Phase 2 completed in 3.54 minutes\n",
      "Best model saved: /kaggle/working/outputs_10_90_v2/models/MobileNetV2_10_90/best_model_phase2.h5\n",
      "\n",
      "Loading best model from Phase 2...\n",
      "\n",
      "Comprehensive evaluation: MobileNetV2 on 10_90\n",
      "Accuracy: 43.73%\n",
      "F1-Score (Macro): 0.4031\n",
      "Precision (Macro): 0.5793\n",
      "Recall (Macro): 0.4373\n",
      "ROC-AUC (Macro): 0.9656\n",
      "Training analysis saved: /kaggle/working/outputs_10_90_v2/plots/MobileNetV2_10_90/training_analysis.png\n",
      "Confusion matrix analysis saved: /kaggle/working/outputs_10_90_v2/plots/MobileNetV2_10_90/confusion_matrix_analysis.png\n",
      "\n",
      "MobileNetV2 Summary:\n",
      "  Test Accuracy: 43.73%\n",
      "  F1-Score: 0.4031\n",
      "  Total Training Time: 4.5 minutes\n",
      "\n",
      "==========================================================================================\n",
      "MODEL: InceptionV3\n",
      "==========================================================================================\n",
      "Building InceptionV3 with enhanced architecture...\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m87910968/87910968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n",
      "Model ready: 23,001,158 parameters\n",
      "\n",
      "Preparing data pipelines...\n",
      "\n",
      "PHASE 1: Training classifier head (backbone frozen)\n",
      "Epochs: 10, Learning Rate: 0.001\n",
      "Trainable parameters: 1,194,278\n",
      "Epoch 1/10\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - accuracy: 0.0545 - loss: 4.6625\n",
      "Epoch 1: val_accuracy improved from -inf to 0.20000, saving model to /kaggle/working/outputs_10_90_v2/models/InceptionV3_10_90/best_model_phase1.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 430ms/step - accuracy: 0.0550 - loss: 4.6558 - val_accuracy: 0.2000 - val_loss: 3.3280 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.1330 - loss: 3.3621\n",
      "Epoch 2: val_accuracy improved from 0.20000 to 0.28947, saving model to /kaggle/working/outputs_10_90_v2/models/InceptionV3_10_90/best_model_phase1.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 82ms/step - accuracy: 0.1336 - loss: 3.3600 - val_accuracy: 0.2895 - val_loss: 3.0688 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.2283 - loss: 3.0034\n",
      "Epoch 3: val_accuracy improved from 0.28947 to 0.35789, saving model to /kaggle/working/outputs_10_90_v2/models/InceptionV3_10_90/best_model_phase1.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - accuracy: 0.2283 - loss: 3.0033 - val_accuracy: 0.3579 - val_loss: 2.7841 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.2530 - loss: 2.8048\n",
      "Epoch 4: val_accuracy did not improve from 0.35789\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 0.2527 - loss: 2.8061 - val_accuracy: 0.3421 - val_loss: 2.5836 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.2609 - loss: 2.7431\n",
      "Epoch 5: val_accuracy improved from 0.35789 to 0.36842, saving model to /kaggle/working/outputs_10_90_v2/models/InceptionV3_10_90/best_model_phase1.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 81ms/step - accuracy: 0.2610 - loss: 2.7426 - val_accuracy: 0.3684 - val_loss: 2.3809 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.3133 - loss: 2.4860\n",
      "Epoch 6: val_accuracy did not improve from 0.36842\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 71ms/step - accuracy: 0.3131 - loss: 2.4881 - val_accuracy: 0.3421 - val_loss: 2.2735 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.3091 - loss: 2.4442\n",
      "Epoch 7: val_accuracy did not improve from 0.36842\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 0.3091 - loss: 2.4448 - val_accuracy: 0.3684 - val_loss: 2.1808 - learning_rate: 0.0010\n",
      "Epoch 8/10\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.3408 - loss: 2.3844\n",
      "Epoch 8: val_accuracy improved from 0.36842 to 0.42105, saving model to /kaggle/working/outputs_10_90_v2/models/InceptionV3_10_90/best_model_phase1.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 82ms/step - accuracy: 0.3408 - loss: 2.3853 - val_accuracy: 0.4211 - val_loss: 2.1189 - learning_rate: 0.0010\n",
      "Epoch 9/10\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.3766 - loss: 2.2724\n",
      "Epoch 9: val_accuracy improved from 0.42105 to 0.48947, saving model to /kaggle/working/outputs_10_90_v2/models/InceptionV3_10_90/best_model_phase1.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 81ms/step - accuracy: 0.3765 - loss: 2.2726 - val_accuracy: 0.4895 - val_loss: 2.0020 - learning_rate: 0.0010\n",
      "Epoch 10/10\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.3694 - loss: 2.2349\n",
      "Epoch 10: val_accuracy did not improve from 0.48947\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 0.3693 - loss: 2.2357 - val_accuracy: 0.4263 - val_loss: 2.0395 - learning_rate: 0.0010\n",
      "Phase 1 completed in 1.35 minutes\n",
      "Best model saved: /kaggle/working/outputs_10_90_v2/models/InceptionV3_10_90/best_model_phase1.h5\n",
      "\n",
      "PHASE 2: Fine-tuning entire model (backbone unfrozen)\n",
      "Epochs: 40, Learning Rate: 0.0001\n",
      "Unfreezing last 156/311 layers of backbone\n",
      "Trainable parameters: 17,983,718\n",
      "Epoch 11/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step - accuracy: 0.2224 - loss: 2.7832\n",
      "Epoch 11: val_accuracy improved from -inf to 0.31579, saving model to /kaggle/working/outputs_10_90_v2/models/InceptionV3_10_90/best_model_phase2.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 567ms/step - accuracy: 0.2230 - loss: 2.7805 - val_accuracy: 0.3158 - val_loss: 2.6944 - learning_rate: 1.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.3923 - loss: 2.1845\n",
      "Epoch 12: val_accuracy improved from 0.31579 to 0.33684, saving model to /kaggle/working/outputs_10_90_v2/models/InceptionV3_10_90/best_model_phase2.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 109ms/step - accuracy: 0.3920 - loss: 2.1847 - val_accuracy: 0.3368 - val_loss: 2.5165 - learning_rate: 1.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.3791 - loss: 2.1043\n",
      "Epoch 13: val_accuracy did not improve from 0.33684\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 91ms/step - accuracy: 0.3795 - loss: 2.1029 - val_accuracy: 0.3263 - val_loss: 2.6389 - learning_rate: 1.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.4302 - loss: 1.9006\n",
      "Epoch 14: val_accuracy improved from 0.33684 to 0.38421, saving model to /kaggle/working/outputs_10_90_v2/models/InceptionV3_10_90/best_model_phase2.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 110ms/step - accuracy: 0.4306 - loss: 1.9002 - val_accuracy: 0.3842 - val_loss: 2.3676 - learning_rate: 1.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.4956 - loss: 1.6879\n",
      "Epoch 15: val_accuracy improved from 0.38421 to 0.46842, saving model to /kaggle/working/outputs_10_90_v2/models/InceptionV3_10_90/best_model_phase2.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 109ms/step - accuracy: 0.4957 - loss: 1.6876 - val_accuracy: 0.4684 - val_loss: 1.9528 - learning_rate: 1.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5456 - loss: 1.5233\n",
      "Epoch 16: val_accuracy did not improve from 0.46842\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 90ms/step - accuracy: 0.5454 - loss: 1.5238 - val_accuracy: 0.4000 - val_loss: 2.1394 - learning_rate: 1.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.6043 - loss: 1.4228\n",
      "Epoch 17: val_accuracy did not improve from 0.46842\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - accuracy: 0.6036 - loss: 1.4247 - val_accuracy: 0.4053 - val_loss: 1.9634 - learning_rate: 1.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5826 - loss: 1.3811\n",
      "Epoch 18: val_accuracy did not improve from 0.46842\n",
      "\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 90ms/step - accuracy: 0.5826 - loss: 1.3811 - val_accuracy: 0.3737 - val_loss: 2.1965 - learning_rate: 1.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.6127 - loss: 1.2843\n",
      "Epoch 19: val_accuracy improved from 0.46842 to 0.47368, saving model to /kaggle/working/outputs_10_90_v2/models/InceptionV3_10_90/best_model_phase2.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 108ms/step - accuracy: 0.6129 - loss: 1.2841 - val_accuracy: 0.4737 - val_loss: 1.7968 - learning_rate: 5.0000e-05\n",
      "Epoch 20/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.6318 - loss: 1.2328\n",
      "Epoch 20: val_accuracy improved from 0.47368 to 0.54211, saving model to /kaggle/working/outputs_10_90_v2/models/InceptionV3_10_90/best_model_phase2.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 109ms/step - accuracy: 0.6321 - loss: 1.2325 - val_accuracy: 0.5421 - val_loss: 1.5898 - learning_rate: 5.0000e-05\n",
      "Epoch 21/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.6532 - loss: 1.1822\n",
      "Epoch 21: val_accuracy did not improve from 0.54211\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 90ms/step - accuracy: 0.6533 - loss: 1.1822 - val_accuracy: 0.5263 - val_loss: 1.7488 - learning_rate: 5.0000e-05\n",
      "Epoch 22/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.6979 - loss: 1.0560\n",
      "Epoch 22: val_accuracy did not improve from 0.54211\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 90ms/step - accuracy: 0.6976 - loss: 1.0568 - val_accuracy: 0.5211 - val_loss: 1.7302 - learning_rate: 5.0000e-05\n",
      "Epoch 23/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7123 - loss: 0.9951\n",
      "Epoch 23: val_accuracy did not improve from 0.54211\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 90ms/step - accuracy: 0.7122 - loss: 0.9958 - val_accuracy: 0.5000 - val_loss: 1.8944 - learning_rate: 5.0000e-05\n",
      "Epoch 24/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7038 - loss: 1.0364\n",
      "Epoch 24: val_accuracy did not improve from 0.54211\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - accuracy: 0.7039 - loss: 1.0362 - val_accuracy: 0.4947 - val_loss: 1.8159 - learning_rate: 2.5000e-05\n",
      "Epoch 25/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.7160 - loss: 0.9814\n",
      "Epoch 25: val_accuracy did not improve from 0.54211\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - accuracy: 0.7159 - loss: 0.9815 - val_accuracy: 0.4947 - val_loss: 1.7471 - learning_rate: 2.5000e-05\n",
      "Epoch 26/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7602 - loss: 0.9170\n",
      "Epoch 26: val_accuracy did not improve from 0.54211\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 90ms/step - accuracy: 0.7599 - loss: 0.9169 - val_accuracy: 0.5263 - val_loss: 1.7186 - learning_rate: 2.5000e-05\n",
      "Epoch 27/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7207 - loss: 0.9329\n",
      "Epoch 27: val_accuracy did not improve from 0.54211\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 90ms/step - accuracy: 0.7209 - loss: 0.9328 - val_accuracy: 0.5211 - val_loss: 1.7123 - learning_rate: 1.2500e-05\n",
      "Epoch 28/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7664 - loss: 0.8499\n",
      "Epoch 28: val_accuracy improved from 0.54211 to 0.54737, saving model to /kaggle/working/outputs_10_90_v2/models/InceptionV3_10_90/best_model_phase2.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 108ms/step - accuracy: 0.7662 - loss: 0.8506 - val_accuracy: 0.5474 - val_loss: 1.7020 - learning_rate: 1.2500e-05\n",
      "Epoch 29/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.7491 - loss: 0.8994\n",
      "Epoch 29: val_accuracy improved from 0.54737 to 0.55789, saving model to /kaggle/working/outputs_10_90_v2/models/InceptionV3_10_90/best_model_phase2.h5\n",
      "\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 115ms/step - accuracy: 0.7490 - loss: 0.8991 - val_accuracy: 0.5579 - val_loss: 1.6528 - learning_rate: 1.2500e-05\n",
      "Epoch 30/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7339 - loss: 0.9109\n",
      "Epoch 30: val_accuracy did not improve from 0.55789\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 90ms/step - accuracy: 0.7339 - loss: 0.9108 - val_accuracy: 0.5421 - val_loss: 1.6369 - learning_rate: 6.2500e-06\n",
      "Epoch 31/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7794 - loss: 0.8050\n",
      "Epoch 31: val_accuracy did not improve from 0.55789\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 90ms/step - accuracy: 0.7793 - loss: 0.8054 - val_accuracy: 0.5526 - val_loss: 1.6374 - learning_rate: 6.2500e-06\n",
      "Epoch 32/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7992 - loss: 0.7973\n",
      "Epoch 32: val_accuracy did not improve from 0.55789\n",
      "\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 90ms/step - accuracy: 0.7988 - loss: 0.7980 - val_accuracy: 0.5526 - val_loss: 1.6306 - learning_rate: 6.2500e-06\n",
      "Epoch 33/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.7552 - loss: 0.8422\n",
      "Epoch 33: val_accuracy did not improve from 0.55789\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - accuracy: 0.7555 - loss: 0.8418 - val_accuracy: 0.5526 - val_loss: 1.6231 - learning_rate: 3.1250e-06\n",
      "Epoch 34/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7718 - loss: 0.8423\n",
      "Epoch 34: val_accuracy did not improve from 0.55789\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 90ms/step - accuracy: 0.7722 - loss: 0.8414 - val_accuracy: 0.5526 - val_loss: 1.6374 - learning_rate: 3.1250e-06\n",
      "Epoch 35/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7855 - loss: 0.8026\n",
      "Epoch 35: val_accuracy did not improve from 0.55789\n",
      "\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - accuracy: 0.7854 - loss: 0.8026 - val_accuracy: 0.5526 - val_loss: 1.6333 - learning_rate: 3.1250e-06\n",
      "Epoch 36/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7767 - loss: 0.8323\n",
      "Epoch 36: val_accuracy did not improve from 0.55789\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 90ms/step - accuracy: 0.7767 - loss: 0.8324 - val_accuracy: 0.5526 - val_loss: 1.6352 - learning_rate: 1.5625e-06\n",
      "Epoch 37/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7931 - loss: 0.8082\n",
      "Epoch 37: val_accuracy improved from 0.55789 to 0.56316, saving model to /kaggle/working/outputs_10_90_v2/models/InceptionV3_10_90/best_model_phase2.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 109ms/step - accuracy: 0.7931 - loss: 0.8080 - val_accuracy: 0.5632 - val_loss: 1.6328 - learning_rate: 1.5625e-06\n",
      "Epoch 38/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.7663 - loss: 0.8385\n",
      "Epoch 38: val_accuracy did not improve from 0.56316\n",
      "\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - accuracy: 0.7666 - loss: 0.8378 - val_accuracy: 0.5632 - val_loss: 1.6371 - learning_rate: 1.5625e-06\n",
      "Epoch 39/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.7577 - loss: 0.8640\n",
      "Epoch 39: val_accuracy did not improve from 0.56316\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 91ms/step - accuracy: 0.7580 - loss: 0.8633 - val_accuracy: 0.5632 - val_loss: 1.6442 - learning_rate: 7.8125e-07\n",
      "Epoch 40/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.7722 - loss: 0.8130\n",
      "Epoch 40: val_accuracy did not improve from 0.56316\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 90ms/step - accuracy: 0.7720 - loss: 0.8133 - val_accuracy: 0.5632 - val_loss: 1.6419 - learning_rate: 7.8125e-07\n",
      "Epoch 41/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.7890 - loss: 0.8210\n",
      "Epoch 41: val_accuracy did not improve from 0.56316\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - accuracy: 0.7888 - loss: 0.8208 - val_accuracy: 0.5632 - val_loss: 1.6420 - learning_rate: 7.8125e-07\n",
      "Epoch 42/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.7866 - loss: 0.8061\n",
      "Epoch 42: val_accuracy did not improve from 0.56316\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - accuracy: 0.7865 - loss: 0.8061 - val_accuracy: 0.5632 - val_loss: 1.6354 - learning_rate: 3.9062e-07\n",
      "Epoch 43/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.8056 - loss: 0.7290\n",
      "Epoch 43: val_accuracy did not improve from 0.56316\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 90ms/step - accuracy: 0.8051 - loss: 0.7305 - val_accuracy: 0.5579 - val_loss: 1.6468 - learning_rate: 3.9062e-07\n",
      "Epoch 44/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7896 - loss: 0.7535\n",
      "Epoch 44: val_accuracy did not improve from 0.56316\n",
      "\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - accuracy: 0.7895 - loss: 0.7540 - val_accuracy: 0.5579 - val_loss: 1.6468 - learning_rate: 3.9062e-07\n",
      "Epoch 45/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7725 - loss: 0.8240\n",
      "Epoch 45: val_accuracy did not improve from 0.56316\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 90ms/step - accuracy: 0.7725 - loss: 0.8238 - val_accuracy: 0.5579 - val_loss: 1.6443 - learning_rate: 1.9531e-07\n",
      "Epoch 46/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7804 - loss: 0.7903\n",
      "Epoch 46: val_accuracy did not improve from 0.56316\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 90ms/step - accuracy: 0.7803 - loss: 0.7905 - val_accuracy: 0.5474 - val_loss: 1.6530 - learning_rate: 1.9531e-07\n",
      "Epoch 47/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.7890 - loss: 0.7569\n",
      "Epoch 47: val_accuracy did not improve from 0.56316\n",
      "\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - accuracy: 0.7888 - loss: 0.7576 - val_accuracy: 0.5579 - val_loss: 1.6432 - learning_rate: 1.9531e-07\n",
      "Epoch 48/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.7893 - loss: 0.7821\n",
      "Epoch 48: val_accuracy did not improve from 0.56316\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 90ms/step - accuracy: 0.7891 - loss: 0.7823 - val_accuracy: 0.5579 - val_loss: 1.6384 - learning_rate: 1.0000e-07\n",
      "Epoch 49/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.7788 - loss: 0.7759\n",
      "Epoch 49: val_accuracy did not improve from 0.56316\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - accuracy: 0.7788 - loss: 0.7758 - val_accuracy: 0.5632 - val_loss: 1.6382 - learning_rate: 1.0000e-07\n",
      "Epoch 50/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.7708 - loss: 0.8210\n",
      "Epoch 50: val_accuracy did not improve from 0.56316\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - accuracy: 0.7708 - loss: 0.8210 - val_accuracy: 0.5632 - val_loss: 1.6428 - learning_rate: 1.0000e-07\n",
      "Phase 2 completed in 4.70 minutes\n",
      "Best model saved: /kaggle/working/outputs_10_90_v2/models/InceptionV3_10_90/best_model_phase2.h5\n",
      "\n",
      "Loading best model from Phase 2...\n",
      "\n",
      "Comprehensive evaluation: InceptionV3 on 10_90\n",
      "Accuracy: 52.07%\n",
      "F1-Score (Macro): 0.4971\n",
      "Precision (Macro): 0.6143\n",
      "Recall (Macro): 0.5207\n",
      "ROC-AUC (Macro): 0.9694\n",
      "Training analysis saved: /kaggle/working/outputs_10_90_v2/plots/InceptionV3_10_90/training_analysis.png\n",
      "Confusion matrix analysis saved: /kaggle/working/outputs_10_90_v2/plots/InceptionV3_10_90/confusion_matrix_analysis.png\n",
      "\n",
      "InceptionV3 Summary:\n",
      "  Test Accuracy: 52.07%\n",
      "  F1-Score: 0.4971\n",
      "  Total Training Time: 6.1 minutes\n",
      "\n",
      "==========================================================================================\n",
      "MODEL: DenseNet121\n",
      "==========================================================================================\n",
      "Building DenseNet121 with enhanced architecture...\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m29084464/29084464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
      "Model ready: 7,707,494 parameters\n",
      "\n",
      "Preparing data pipelines...\n",
      "\n",
      "PHASE 1: Training classifier head (backbone frozen)\n",
      "Epochs: 10, Learning Rate: 0.001\n",
      "Trainable parameters: 667,942\n",
      "Epoch 1/10\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307ms/step - accuracy: 0.0667 - loss: 3.9343\n",
      "Epoch 1: val_accuracy improved from -inf to 0.21579, saving model to /kaggle/working/outputs_10_90_v2/models/DenseNet121_10_90/best_model_phase1.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 751ms/step - accuracy: 0.0674 - loss: 3.9279 - val_accuracy: 0.2158 - val_loss: 3.1511 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.2362 - loss: 2.8596\n",
      "Epoch 2: val_accuracy improved from 0.21579 to 0.32632, saving model to /kaggle/working/outputs_10_90_v2/models/DenseNet121_10_90/best_model_phase1.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 100ms/step - accuracy: 0.2367 - loss: 2.8556 - val_accuracy: 0.3263 - val_loss: 2.6086 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.3023 - loss: 2.4207\n",
      "Epoch 3: val_accuracy improved from 0.32632 to 0.43158, saving model to /kaggle/working/outputs_10_90_v2/models/DenseNet121_10_90/best_model_phase1.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 101ms/step - accuracy: 0.3031 - loss: 2.4191 - val_accuracy: 0.4316 - val_loss: 2.2711 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.3848 - loss: 2.1128\n",
      "Epoch 4: val_accuracy did not improve from 0.43158\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 90ms/step - accuracy: 0.3847 - loss: 2.1122 - val_accuracy: 0.4316 - val_loss: 1.9756 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.4547 - loss: 1.8871\n",
      "Epoch 5: val_accuracy improved from 0.43158 to 0.48421, saving model to /kaggle/working/outputs_10_90_v2/models/DenseNet121_10_90/best_model_phase1.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 102ms/step - accuracy: 0.4540 - loss: 1.8875 - val_accuracy: 0.4842 - val_loss: 1.8022 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.4776 - loss: 1.7037\n",
      "Epoch 6: val_accuracy did not improve from 0.48421\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - accuracy: 0.4775 - loss: 1.7056 - val_accuracy: 0.4632 - val_loss: 1.7030 - learning_rate: 0.0010\n",
      "Epoch 7/10\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.5160 - loss: 1.6392\n",
      "Epoch 7: val_accuracy improved from 0.48421 to 0.50526, saving model to /kaggle/working/outputs_10_90_v2/models/DenseNet121_10_90/best_model_phase1.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 101ms/step - accuracy: 0.5155 - loss: 1.6413 - val_accuracy: 0.5053 - val_loss: 1.6526 - learning_rate: 0.0010\n",
      "Epoch 8/10\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.5268 - loss: 1.6229\n",
      "Epoch 8: val_accuracy improved from 0.50526 to 0.52632, saving model to /kaggle/working/outputs_10_90_v2/models/DenseNet121_10_90/best_model_phase1.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 101ms/step - accuracy: 0.5275 - loss: 1.6204 - val_accuracy: 0.5263 - val_loss: 1.5005 - learning_rate: 0.0010\n",
      "Epoch 9/10\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.5359 - loss: 1.4874\n",
      "Epoch 9: val_accuracy did not improve from 0.52632\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 93ms/step - accuracy: 0.5363 - loss: 1.4882 - val_accuracy: 0.4895 - val_loss: 1.5407 - learning_rate: 0.0010\n",
      "Epoch 10/10\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.5719 - loss: 1.4142\n",
      "Epoch 10: val_accuracy did not improve from 0.52632\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - accuracy: 0.5722 - loss: 1.4149 - val_accuracy: 0.4737 - val_loss: 1.6043 - learning_rate: 0.0010\n",
      "Phase 1 completed in 1.99 minutes\n",
      "Best model saved: /kaggle/working/outputs_10_90_v2/models/DenseNet121_10_90/best_model_phase1.h5\n",
      "\n",
      "PHASE 2: Fine-tuning entire model (backbone unfrozen)\n",
      "Epochs: 40, Learning Rate: 0.0001\n",
      "Unfreezing last 214/427 layers of backbone\n",
      "Trainable parameters: 5,299,814\n",
      "Epoch 11/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816ms/step - accuracy: 0.5175 - loss: 1.6523\n",
      "Epoch 11: val_accuracy improved from -inf to 0.51579, saving model to /kaggle/working/outputs_10_90_v2/models/DenseNet121_10_90/best_model_phase2.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 1s/step - accuracy: 0.5177 - loss: 1.6516 - val_accuracy: 0.5158 - val_loss: 1.6497 - learning_rate: 1.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.5916 - loss: 1.3945\n",
      "Epoch 12: val_accuracy did not improve from 0.51579\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 99ms/step - accuracy: 0.5918 - loss: 1.3942 - val_accuracy: 0.4895 - val_loss: 1.6648 - learning_rate: 1.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.6167 - loss: 1.2791\n",
      "Epoch 13: val_accuracy did not improve from 0.51579\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 99ms/step - accuracy: 0.6167 - loss: 1.2785 - val_accuracy: 0.4263 - val_loss: 2.0318 - learning_rate: 1.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.6557 - loss: 1.1855\n",
      "Epoch 14: val_accuracy improved from 0.51579 to 0.52632, saving model to /kaggle/working/outputs_10_90_v2/models/DenseNet121_10_90/best_model_phase2.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 115ms/step - accuracy: 0.6557 - loss: 1.1861 - val_accuracy: 0.5263 - val_loss: 1.4478 - learning_rate: 1.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.6533 - loss: 1.0828\n",
      "Epoch 15: val_accuracy did not improve from 0.52632\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 99ms/step - accuracy: 0.6539 - loss: 1.0827 - val_accuracy: 0.4895 - val_loss: 1.7425 - learning_rate: 1.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.6804 - loss: 1.0267\n",
      "Epoch 16: val_accuracy improved from 0.52632 to 0.54737, saving model to /kaggle/working/outputs_10_90_v2/models/DenseNet121_10_90/best_model_phase2.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - accuracy: 0.6806 - loss: 1.0268 - val_accuracy: 0.5474 - val_loss: 1.5871 - learning_rate: 1.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.7174 - loss: 0.9662\n",
      "Epoch 17: val_accuracy did not improve from 0.54737\n",
      "\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 99ms/step - accuracy: 0.7176 - loss: 0.9661 - val_accuracy: 0.5316 - val_loss: 1.4553 - learning_rate: 1.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.7535 - loss: 0.8765\n",
      "Epoch 18: val_accuracy improved from 0.54737 to 0.59474, saving model to /kaggle/working/outputs_10_90_v2/models/DenseNet121_10_90/best_model_phase2.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 116ms/step - accuracy: 0.7531 - loss: 0.8766 - val_accuracy: 0.5947 - val_loss: 1.3542 - learning_rate: 5.0000e-05\n",
      "Epoch 19/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.7802 - loss: 0.7994\n",
      "Epoch 19: val_accuracy did not improve from 0.59474\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 98ms/step - accuracy: 0.7801 - loss: 0.7993 - val_accuracy: 0.5947 - val_loss: 1.4218 - learning_rate: 5.0000e-05\n",
      "Epoch 20/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.7721 - loss: 0.8065\n",
      "Epoch 20: val_accuracy did not improve from 0.59474\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 98ms/step - accuracy: 0.7721 - loss: 0.8058 - val_accuracy: 0.5579 - val_loss: 1.4902 - learning_rate: 5.0000e-05\n",
      "Epoch 21/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.7665 - loss: 0.8268\n",
      "Epoch 21: val_accuracy did not improve from 0.59474\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 98ms/step - accuracy: 0.7665 - loss: 0.8263 - val_accuracy: 0.5947 - val_loss: 1.3918 - learning_rate: 5.0000e-05\n",
      "Epoch 22/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.8158 - loss: 0.6978\n",
      "Epoch 22: val_accuracy did not improve from 0.59474\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 99ms/step - accuracy: 0.8154 - loss: 0.6985 - val_accuracy: 0.5579 - val_loss: 1.4424 - learning_rate: 2.5000e-05\n",
      "Epoch 23/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.7821 - loss: 0.6763\n",
      "Epoch 23: val_accuracy did not improve from 0.59474\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 100ms/step - accuracy: 0.7825 - loss: 0.6767 - val_accuracy: 0.5789 - val_loss: 1.4031 - learning_rate: 2.5000e-05\n",
      "Epoch 24/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.7844 - loss: 0.7031\n",
      "Epoch 24: val_accuracy did not improve from 0.59474\n",
      "\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 99ms/step - accuracy: 0.7847 - loss: 0.7030 - val_accuracy: 0.5684 - val_loss: 1.4496 - learning_rate: 2.5000e-05\n",
      "Epoch 25/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.8078 - loss: 0.6826\n",
      "Epoch 25: val_accuracy did not improve from 0.59474\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 98ms/step - accuracy: 0.8080 - loss: 0.6818 - val_accuracy: 0.5737 - val_loss: 1.4571 - learning_rate: 1.2500e-05\n",
      "Epoch 26/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.8264 - loss: 0.6636\n",
      "Epoch 26: val_accuracy did not improve from 0.59474\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 99ms/step - accuracy: 0.8263 - loss: 0.6633 - val_accuracy: 0.5842 - val_loss: 1.4522 - learning_rate: 1.2500e-05\n",
      "Epoch 27/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.8096 - loss: 0.6837\n",
      "Epoch 27: val_accuracy did not improve from 0.59474\n",
      "\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 97ms/step - accuracy: 0.8097 - loss: 0.6836 - val_accuracy: 0.5737 - val_loss: 1.4517 - learning_rate: 1.2500e-05\n",
      "Epoch 28/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.8297 - loss: 0.6423\n",
      "Epoch 28: val_accuracy did not improve from 0.59474\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 98ms/step - accuracy: 0.8295 - loss: 0.6424 - val_accuracy: 0.5842 - val_loss: 1.3765 - learning_rate: 6.2500e-06\n",
      "Epoch 29/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.8222 - loss: 0.6506\n",
      "Epoch 29: val_accuracy did not improve from 0.59474\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 98ms/step - accuracy: 0.8223 - loss: 0.6501 - val_accuracy: 0.5842 - val_loss: 1.3771 - learning_rate: 6.2500e-06\n",
      "Epoch 30/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.8346 - loss: 0.6419\n",
      "Epoch 30: val_accuracy did not improve from 0.59474\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 98ms/step - accuracy: 0.8340 - loss: 0.6426 - val_accuracy: 0.5842 - val_loss: 1.3516 - learning_rate: 6.2500e-06\n",
      "Epoch 31/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.8373 - loss: 0.5984\n",
      "Epoch 31: val_accuracy did not improve from 0.59474\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 98ms/step - accuracy: 0.8368 - loss: 0.5995 - val_accuracy: 0.5947 - val_loss: 1.3547 - learning_rate: 6.2500e-06\n",
      "Epoch 32/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.8105 - loss: 0.6642\n",
      "Epoch 32: val_accuracy did not improve from 0.59474\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 100ms/step - accuracy: 0.8108 - loss: 0.6638 - val_accuracy: 0.5895 - val_loss: 1.3694 - learning_rate: 6.2500e-06\n",
      "Epoch 33/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.8260 - loss: 0.6117\n",
      "Epoch 33: val_accuracy did not improve from 0.59474\n",
      "\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 98ms/step - accuracy: 0.8259 - loss: 0.6121 - val_accuracy: 0.5947 - val_loss: 1.3835 - learning_rate: 6.2500e-06\n",
      "Epoch 34/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.8270 - loss: 0.6287\n",
      "Epoch 34: val_accuracy did not improve from 0.59474\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 97ms/step - accuracy: 0.8273 - loss: 0.6282 - val_accuracy: 0.5947 - val_loss: 1.3585 - learning_rate: 3.1250e-06\n",
      "Epoch 35/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.8378 - loss: 0.6132\n",
      "Epoch 35: val_accuracy did not improve from 0.59474\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 99ms/step - accuracy: 0.8375 - loss: 0.6134 - val_accuracy: 0.5947 - val_loss: 1.3579 - learning_rate: 3.1250e-06\n",
      "Epoch 36/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.8613 - loss: 0.5614\n",
      "Epoch 36: val_accuracy improved from 0.59474 to 0.60000, saving model to /kaggle/working/outputs_10_90_v2/models/DenseNet121_10_90/best_model_phase2.h5\n",
      "\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 115ms/step - accuracy: 0.8604 - loss: 0.5636 - val_accuracy: 0.6000 - val_loss: 1.3556 - learning_rate: 3.1250e-06\n",
      "Epoch 37/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.8300 - loss: 0.5966\n",
      "Epoch 37: val_accuracy did not improve from 0.60000\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 99ms/step - accuracy: 0.8300 - loss: 0.5965 - val_accuracy: 0.5947 - val_loss: 1.3512 - learning_rate: 1.5625e-06\n",
      "Epoch 38/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.8292 - loss: 0.6089\n",
      "Epoch 38: val_accuracy did not improve from 0.60000\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 98ms/step - accuracy: 0.8292 - loss: 0.6088 - val_accuracy: 0.5947 - val_loss: 1.3455 - learning_rate: 1.5625e-06\n",
      "Epoch 39/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.8278 - loss: 0.6287\n",
      "Epoch 39: val_accuracy did not improve from 0.60000\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 98ms/step - accuracy: 0.8278 - loss: 0.6279 - val_accuracy: 0.6000 - val_loss: 1.3493 - learning_rate: 1.5625e-06\n",
      "Epoch 40/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.8098 - loss: 0.6364\n",
      "Epoch 40: val_accuracy improved from 0.60000 to 0.60526, saving model to /kaggle/working/outputs_10_90_v2/models/DenseNet121_10_90/best_model_phase2.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 115ms/step - accuracy: 0.8106 - loss: 0.6351 - val_accuracy: 0.6053 - val_loss: 1.3428 - learning_rate: 1.5625e-06\n",
      "Epoch 41/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.8195 - loss: 0.6171\n",
      "Epoch 41: val_accuracy did not improve from 0.60526\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 98ms/step - accuracy: 0.8198 - loss: 0.6170 - val_accuracy: 0.6053 - val_loss: 1.3470 - learning_rate: 1.5625e-06\n",
      "Epoch 42/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.8257 - loss: 0.6177\n",
      "Epoch 42: val_accuracy did not improve from 0.60526\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 98ms/step - accuracy: 0.8259 - loss: 0.6175 - val_accuracy: 0.6000 - val_loss: 1.3450 - learning_rate: 1.5625e-06\n",
      "Epoch 43/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.8451 - loss: 0.5879\n",
      "Epoch 43: val_accuracy did not improve from 0.60526\n",
      "\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 97ms/step - accuracy: 0.8448 - loss: 0.5891 - val_accuracy: 0.6000 - val_loss: 1.3441 - learning_rate: 1.5625e-06\n",
      "Epoch 44/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.8256 - loss: 0.6076\n",
      "Epoch 44: val_accuracy did not improve from 0.60526\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 99ms/step - accuracy: 0.8258 - loss: 0.6073 - val_accuracy: 0.6000 - val_loss: 1.3361 - learning_rate: 7.8125e-07\n",
      "Epoch 45/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.8274 - loss: 0.6204\n",
      "Epoch 45: val_accuracy did not improve from 0.60526\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 98ms/step - accuracy: 0.8274 - loss: 0.6201 - val_accuracy: 0.6000 - val_loss: 1.3293 - learning_rate: 7.8125e-07\n",
      "Epoch 46/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.8493 - loss: 0.6004\n",
      "Epoch 46: val_accuracy did not improve from 0.60526\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 99ms/step - accuracy: 0.8489 - loss: 0.6006 - val_accuracy: 0.6000 - val_loss: 1.3326 - learning_rate: 7.8125e-07\n",
      "Epoch 47/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.8456 - loss: 0.5818\n",
      "Epoch 47: val_accuracy did not improve from 0.60526\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 99ms/step - accuracy: 0.8453 - loss: 0.5818 - val_accuracy: 0.6000 - val_loss: 1.3370 - learning_rate: 7.8125e-07\n",
      "Epoch 48/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.8465 - loss: 0.5690\n",
      "Epoch 48: val_accuracy did not improve from 0.60526\n",
      "\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 99ms/step - accuracy: 0.8464 - loss: 0.5699 - val_accuracy: 0.6000 - val_loss: 1.3353 - learning_rate: 7.8125e-07\n",
      "Epoch 49/50\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.8292 - loss: 0.6222\n",
      "Epoch 49: val_accuracy did not improve from 0.60526\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 98ms/step - accuracy: 0.8293 - loss: 0.6219 - val_accuracy: 0.6000 - val_loss: 1.3373 - learning_rate: 3.9062e-07\n",
      "Epoch 50/50\n",
      "\u001b[1m53/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.8494 - loss: 0.5756\n",
      "Epoch 50: val_accuracy did not improve from 0.60526\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 99ms/step - accuracy: 0.8495 - loss: 0.5752 - val_accuracy: 0.6000 - val_loss: 1.3394 - learning_rate: 3.9062e-07\n",
      "Phase 2 completed in 6.26 minutes\n",
      "Best model saved: /kaggle/working/outputs_10_90_v2/models/DenseNet121_10_90/best_model_phase2.h5\n",
      "\n",
      "Loading best model from Phase 2...\n",
      "\n",
      "Comprehensive evaluation: DenseNet121 on 10_90\n",
      "Accuracy: 56.70%\n",
      "F1-Score (Macro): 0.5450\n",
      "Precision (Macro): 0.6768\n",
      "Recall (Macro): 0.5670\n",
      "ROC-AUC (Macro): 0.9806\n",
      "Training analysis saved: /kaggle/working/outputs_10_90_v2/plots/DenseNet121_10_90/training_analysis.png\n",
      "Confusion matrix analysis saved: /kaggle/working/outputs_10_90_v2/plots/DenseNet121_10_90/confusion_matrix_analysis.png\n",
      "\n",
      "DenseNet121 Summary:\n",
      "  Test Accuracy: 56.70%\n",
      "  F1-Score: 0.5450\n",
      "  Total Training Time: 8.3 minutes\n",
      "\n",
      "==========================================================================================\n",
      "Training pipeline completed for split 10:90\n",
      "Models trained: 5/5\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(f\"Starting enhanced training pipeline for split {cfg.TRAIN_RATIO}:{cfg.TEST_RATIO}\")\n",
    "print(f\"Configuration: Two-phase training with enhanced regularization\")\n",
    "print(f\"Expected outcome: 95%+ accuracy with minimal overfitting\\n\")\n",
    "\n",
    "results_collection = []\n",
    "\n",
    "for model_name in cfg.MODELS:\n",
    "    try:\n",
    "        print(f\"\\n{'='*90}\")\n",
    "        print(f\"MODEL: {model_name}\")\n",
    "        print(f\"{'='*90}\")\n",
    "        \n",
    "        model, preprocess_func, base_model = build_model_advanced(model_name)\n",
    "        \n",
    "        print(\"\\nPreparing data pipelines...\")\n",
    "        train_dataset = create_dataset_enhanced(\n",
    "            split_data['train_paths'], split_data['train_labels'],\n",
    "            preprocess_func, cfg.BATCH_SIZE, cfg.IMG_SIZE,\n",
    "            shuffle=True, augment=True, seed=cfg.RANDOM_SEED\n",
    "        )\n",
    "        \n",
    "        val_dataset = create_dataset_enhanced(\n",
    "            split_data['val_paths'], split_data['val_labels'],\n",
    "            preprocess_func, cfg.BATCH_SIZE, cfg.IMG_SIZE,\n",
    "            shuffle=False, augment=False\n",
    "        )\n",
    "        \n",
    "        test_dataset = create_dataset_enhanced(\n",
    "            split_data['test_paths'], split_data['test_labels'],\n",
    "            preprocess_func, cfg.BATCH_SIZE, cfg.IMG_SIZE,\n",
    "            shuffle=False, augment=False\n",
    "        )\n",
    "        \n",
    "        trainer = TwoPhaseTrainer(model, base_model, model_name, cfg.SPLIT_NAME)\n",
    "        \n",
    "        checkpoint_p1, time_p1 = trainer.train_phase1(train_dataset, val_dataset)\n",
    "        checkpoint_p2, time_p2 = trainer.train_phase2(train_dataset, val_dataset)\n",
    "        \n",
    "        total_training_time = time_p1 + time_p2\n",
    "        \n",
    "        print(f\"\\nLoading best model from Phase 2...\")\n",
    "        best_model = keras.models.load_model(checkpoint_p2)\n",
    "        \n",
    "        results = evaluate_model_comprehensive(\n",
    "            best_model, test_dataset, split_data['test_labels'],\n",
    "            idx_to_label, model_name, cfg.SPLIT_NAME\n",
    "        )\n",
    "        \n",
    "        results['training_time_total_min'] = total_training_time / 60\n",
    "        results['training_time_phase1_min'] = time_p1 / 60\n",
    "        results['training_time_phase2_min'] = time_p2 / 60\n",
    "        \n",
    "        combined_history = trainer.get_combined_history()\n",
    "        plot_training_curves_enhanced(combined_history, model_name, cfg.SPLIT_NAME)\n",
    "        plot_confusion_matrix_professional(results['confusion_matrix'], model_name, cfg.SPLIT_NAME)\n",
    "        \n",
    "        results_collection.append(results)\n",
    "        \n",
    "        print(f\"\\n{model_name} Summary:\")\n",
    "        print(f\"  Test Accuracy: {results['overall_accuracy']*100:.2f}%\")\n",
    "        print(f\"  F1-Score: {results['f1_macro']:.4f}\")\n",
    "        print(f\"  Total Training Time: {results['training_time_total_min']:.1f} minutes\")\n",
    "        \n",
    "        keras.backend.clear_session()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError with {model_name}: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "print(f\"\\n{'='*90}\")\n",
    "print(f\"Training pipeline completed for split {cfg.TRAIN_RATIO}:{cfg.TEST_RATIO}\")\n",
    "print(f\"Models trained: {len(results_collection)}/5\")\n",
    "print(f\"{'='*90}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CELL 11: Results Summary and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T15:22:18.871967Z",
     "iopub.status.busy": "2025-10-27T15:22:18.871705Z",
     "iopub.status.idle": "2025-10-27T15:22:18.917812Z",
     "shell.execute_reply": "2025-10-27T15:22:18.917043Z",
     "shell.execute_reply.started": "2025-10-27T15:22:18.871952Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================================================================================================\n",
      "FINAL RESULTS SUMMARY - Split 10:90\n",
      "==============================================================================================================\n",
      "         Model Split  Test_Accuracy  F1_Macro  Precision_Macro  Recall_Macro  ROC_AUC  Inference_ms  Training_min  Parameters   GFLOPs\n",
      "      ResNet50 10_90      58.356725  0.562013         0.679396      0.583567 0.979180      3.690012      6.610845    24786086 0.049572\n",
      "   DenseNet121 10_90      56.701754  0.544971         0.676844      0.567018 0.980630      3.553548      8.253004     7707494 0.015415\n",
      "   InceptionV3 10_90      52.070175  0.497142         0.614257      0.520702 0.969359      2.482547      6.054852    23001158 0.046002\n",
      "   MobileNetV2 10_90      43.725146  0.403113         0.579328      0.437251 0.965560      1.917050      4.545681     3060070 0.006120\n",
      "EfficientNetB0 10_90      41.935673  0.388810         0.533794      0.419357 0.950231      2.229502      5.516348     4851657 0.009703\n",
      "==============================================================================================================\n",
      "\n",
      "Best Model: ResNet50\n",
      "Test Accuracy: 58.36%\n",
      "F1-Score: 0.5620\n",
      "Training Time: 6.6 minutes\n",
      "\n",
      "Results saved: /kaggle/working/outputs_10_90_v2/results/summary_10_90.csv\n"
     ]
    }
   ],
   "source": [
    "if len(results_collection) > 0:\n",
    "    results_df = pd.DataFrame({\n",
    "        'Model': [r['model_name'] for r in results_collection],\n",
    "        'Split': [cfg.SPLIT_NAME] * len(results_collection),\n",
    "        'Test_Accuracy': [r['overall_accuracy'] * 100 for r in results_collection],\n",
    "        'F1_Macro': [r['f1_macro'] for r in results_collection],\n",
    "        'Precision_Macro': [r['precision_macro'] for r in results_collection],\n",
    "        'Recall_Macro': [r['recall_macro'] for r in results_collection],\n",
    "        'ROC_AUC': [r['roc_auc_macro'] for r in results_collection],\n",
    "        'Inference_ms': [r['avg_inference_time_ms'] for r in results_collection],\n",
    "        'Training_min': [r['training_time_total_min'] for r in results_collection],\n",
    "        'Parameters': [r['total_params'] for r in results_collection],\n",
    "        'GFLOPs': [r['gflops'] for r in results_collection]\n",
    "    })\n",
    "    \n",
    "    results_df_sorted = results_df.sort_values('Test_Accuracy', ascending=False)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*110)\n",
    "    print(f\"FINAL RESULTS SUMMARY - Split {cfg.TRAIN_RATIO}:{cfg.TEST_RATIO}\")\n",
    "    print(\"=\"*110)\n",
    "    print(results_df_sorted.to_string(index=False))\n",
    "    print(\"=\"*110)\n",
    "    \n",
    "    best_model = results_df_sorted.iloc[0]\n",
    "    print(f\"\\nBest Model: {best_model['Model']}\")\n",
    "    print(f\"Test Accuracy: {best_model['Test_Accuracy']:.2f}%\")\n",
    "    print(f\"F1-Score: {best_model['F1_Macro']:.4f}\")\n",
    "    print(f\"Training Time: {best_model['Training_min']:.1f} minutes\")\n",
    "    \n",
    "    csv_path = os.path.join(cfg.RESULTS_DIR, f'summary_{cfg.SPLIT_NAME}.csv')\n",
    "    results_df_sorted.to_csv(csv_path, index=False)\n",
    "    print(f\"\\nResults saved: {csv_path}\")\n",
    "else:\n",
    "    print(\"No results to summarize\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  CELL 12:  Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T15:23:28.138084Z",
     "iopub.status.busy": "2025-10-27T15:23:28.137784Z",
     "iopub.status.idle": "2025-10-27T15:24:16.137918Z",
     "shell.execute_reply": "2025-10-27T15:24:16.136951Z",
     "shell.execute_reply.started": "2025-10-27T15:23:28.138062Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating comprehensive archive: Task2_Split_10_90_Complete_20251027_152328.zip\n",
      "\n",
      "Archive created successfully\n",
      "Filename: Task2_Split_10_90_Complete_20251027_152328.zip\n",
      "Size: 856.21 MB\n",
      "Location: /kaggle/working/Task2_Split_10_90_Complete_20251027_152328.zip\n",
      "\n",
      "Contents:\n",
      "  - Trained models (.h5 files)\n",
      "  - Training logs (CSV)\n",
      "  - All plots and visualizations\n",
      "  - Evaluation metrics (JSON)\n",
      "  - Summary results (CSV)\n",
      "\n",
      "==============================================================================================================\n",
      "BACKUP AND DOWNLOAD INSTRUCTIONS\n",
      "==============================================================================================================\n",
      "1. Navigate to /kaggle/working/ in the Output panel\n",
      "2. Right-click on: Task2_Split_10_90_Complete_20251027_152328.zip\n",
      "3. Select 'Download'\n",
      "4. Store safely - this contains ALL your work for split 10_90\n",
      "==============================================================================================================\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "\n",
    "def create_comprehensive_archive():\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    archive_name = f'Task2_Split_{cfg.SPLIT_NAME}_Complete_{timestamp}.zip'\n",
    "    \n",
    "    print(f\"Creating comprehensive archive: {archive_name}\")\n",
    "    \n",
    "    with zipfile.ZipFile(archive_name, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        for root, dirs, files in os.walk(cfg.OUTPUT_DIR):\n",
    "            for file in files:\n",
    "                file_path = os.path.join(root, file)\n",
    "                arcname = os.path.relpath(file_path, cfg.OUTPUT_DIR)\n",
    "                zipf.write(file_path, arcname)\n",
    "                \n",
    "    file_size_mb = os.path.getsize(archive_name) / (1024*1024)\n",
    "    \n",
    "    print(f\"\\nArchive created successfully\")\n",
    "    print(f\"Filename: {archive_name}\")\n",
    "    print(f\"Size: {file_size_mb:.2f} MB\")\n",
    "    print(f\"Location: /kaggle/working/{archive_name}\")\n",
    "    print(f\"\\nContents:\")\n",
    "    print(f\"  - Trained models (.h5 files)\")\n",
    "    print(f\"  - Training logs (CSV)\")\n",
    "    print(f\"  - All plots and visualizations\")\n",
    "    print(f\"  - Evaluation metrics (JSON)\")\n",
    "    print(f\"  - Summary results (CSV)\")\n",
    "    \n",
    "    return archive_name\n",
    "\n",
    "archive_file = create_comprehensive_archive()\n",
    "\n",
    "print(\"\\n\" + \"=\"*110)\n",
    "print(\"BACKUP AND DOWNLOAD INSTRUCTIONS\")\n",
    "print(\"=\"*110)\n",
    "print(f\"1. Navigate to /kaggle/working/ in the Output panel\")\n",
    "print(f\"2. Right-click on: {archive_file}\")\n",
    "print(f\"3. Select 'Download'\")\n",
    "print(f\"4. Store safely - this contains ALL your work for split {cfg.SPLIT_NAME}\")\n",
    "print(\"=\"*110)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T11:37:09.313457Z",
     "iopub.status.busy": "2025-10-27T11:37:09.313167Z",
     "iopub.status.idle": "2025-10-27T11:37:56.886813Z",
     "shell.execute_reply": "2025-10-27T11:37:56.885985Z",
     "shell.execute_reply.started": "2025-10-27T11:37:09.313438Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating comprehensive archive: Task2_Split_40_60_Complete_20251027_113709.zip\n",
      "\n",
      "Archive created successfully\n",
      "Filename: Task2_Split_40_60_Complete_20251027_113709.zip\n",
      "Size: 857.53 MB\n",
      "Location: /kaggle/working/Task2_Split_40_60_Complete_20251027_113709.zip\n",
      "\n",
      "Contents:\n",
      "  - Trained models (.h5 files)\n",
      "  - Training logs (CSV)\n",
      "  - All plots and visualizations\n",
      "  - Evaluation metrics (JSON)\n",
      "  - Summary results (CSV)\n",
      "\n",
      "==============================================================================================================\n",
      "BACKUP AND DOWNLOAD INSTRUCTIONS\n",
      "==============================================================================================================\n",
      "1. Navigate to /kaggle/working/ in the Output panel\n",
      "2. Right-click on: Task2_Split_40_60_Complete_20251027_113709.zip\n",
      "3. Select 'Download'\n",
      "4. Store safely - this contains ALL your work for split 40_60\n",
      "==============================================================================================================\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "\n",
    "def create_comprehensive_archive():\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    archive_name = f'Task2_Split_{cfg.SPLIT_NAME}_Complete_{timestamp}.zip'\n",
    "    \n",
    "    print(f\"Creating comprehensive archive: {archive_name}\")\n",
    "    \n",
    "    with zipfile.ZipFile(archive_name, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        for root, dirs, files in os.walk(cfg.OUTPUT_DIR):\n",
    "            for file in files:\n",
    "                file_path = os.path.join(root, file)\n",
    "                arcname = os.path.relpath(file_path, cfg.OUTPUT_DIR)\n",
    "                zipf.write(file_path, arcname)\n",
    "                \n",
    "    file_size_mb = os.path.getsize(archive_name) / (1024*1024)\n",
    "    \n",
    "    print(f\"\\nArchive created successfully\")\n",
    "    print(f\"Filename: {archive_name}\")\n",
    "    print(f\"Size: {file_size_mb:.2f} MB\")\n",
    "    print(f\"Location: /kaggle/working/{archive_name}\")\n",
    "    print(f\"\\nContents:\")\n",
    "    print(f\"  - Trained models (.h5 files)\")\n",
    "    print(f\"  - Training logs (CSV)\")\n",
    "    print(f\"  - All plots and visualizations\")\n",
    "    print(f\"  - Evaluation metrics (JSON)\")\n",
    "    print(f\"  - Summary results (CSV)\")\n",
    "    \n",
    "    return archive_name\n",
    "\n",
    "archive_file = create_comprehensive_archive()\n",
    "\n",
    "print(\"\\n\" + \"=\"*110)\n",
    "print(\"BACKUP AND DOWNLOAD INSTRUCTIONS\")\n",
    "print(\"=\"*110)\n",
    "print(f\"1. Navigate to /kaggle/working/ in the Output panel\")\n",
    "print(f\"2. Right-click on: {archive_file}\")\n",
    "print(f\"3. Select 'Download'\")\n",
    "print(f\"4. Store safely - this contains ALL your work for split {cfg.SPLIT_NAME}\")\n",
    "print(\"=\"*110)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CELL 13: Final Report Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T15:24:43.565307Z",
     "iopub.status.busy": "2025-10-27T15:24:43.564780Z",
     "iopub.status.idle": "2025-10-27T15:24:43.575452Z",
     "shell.execute_reply": "2025-10-27T15:24:43.574832Z",
     "shell.execute_reply.started": "2025-10-27T15:24:43.565285Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final report generated: /kaggle/working/outputs_10_90_v2/results/REPORT_Split_10_90.txt\n",
      "\n",
      "Report saved and ready for submission\n"
     ]
    }
   ],
   "source": [
    "def generate_final_report():\n",
    "    report_path = os.path.join(cfg.RESULTS_DIR, f'REPORT_Split_{cfg.SPLIT_NAME}.txt')\n",
    "    \n",
    "    with open(report_path, 'w') as f:\n",
    "        f.write(\"=\"*110 + \"\\n\")\n",
    "        f.write(f\"TASK 2: SUPERVISED BASELINE TRAINING REPORT\\n\")\n",
    "        f.write(f\"Split: {cfg.TRAIN_RATIO}:{cfg.TEST_RATIO}\\n\")\n",
    "        f.write(f\"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "        f.write(\"=\"*110 + \"\\n\\n\")\n",
    "        \n",
    "        f.write(\"PROJECT INFORMATION\\n\")\n",
    "        f.write(\"-\" * 110 + \"\\n\")\n",
    "        f.write(f\"Course: CSE475 - Self-Supervised Learning\\n\")\n",
    "        f.write(f\"Dataset: Rice Varieties in Bangladesh (38 classes)\\n\")\n",
    "        f.write(f\"Total Images: {cfg.TOTAL_IMAGES}\\n\")\n",
    "        f.write(f\"Training Strategy: Two-phase (frozen backbone → fine-tuning)\\n\")\n",
    "        f.write(f\"Total Epochs: {cfg.TOTAL_EPOCHS} (Phase 1: {cfg.EPOCHS_PHASE1}, Phase 2: {cfg.EPOCHS_PHASE2})\\n\\n\")\n",
    "        \n",
    "        if len(results_collection) > 0:\n",
    "            f.write(\"MODEL PERFORMANCE SUMMARY\\n\")\n",
    "            f.write(\"-\" * 110 + \"\\n\")\n",
    "            for result in results_collection:\n",
    "                f.write(f\"\\nModel: {result['model_name']}\\n\")\n",
    "                f.write(f\"  Test Accuracy: {result['overall_accuracy']*100:.2f}%\\n\")\n",
    "                f.write(f\"  F1-Score (Macro): {result['f1_macro']:.4f}\\n\")\n",
    "                f.write(f\"  Precision (Macro): {result['precision_macro']:.4f}\\n\")\n",
    "                f.write(f\"  Recall (Macro): {result['recall_macro']:.4f}\\n\")\n",
    "                f.write(f\"  ROC-AUC: {result['roc_auc_macro']:.4f}\\n\")\n",
    "                f.write(f\"  Parameters: {result['total_params']:,}\\n\")\n",
    "                f.write(f\"  Training Time: {result['training_time_total_min']:.1f} minutes\\n\")\n",
    "                f.write(f\"  Inference Time: {result['avg_inference_time_ms']:.2f} ms/image\\n\")\n",
    "            \n",
    "            best_result = max(results_collection, key=lambda x: x['overall_accuracy'])\n",
    "            f.write(f\"\\n{'='*110}\\n\")\n",
    "            f.write(f\"BEST MODEL: {best_result['model_name']}\\n\")\n",
    "            f.write(f\"Test Accuracy: {best_result['overall_accuracy']*100:.2f}%\\n\")\n",
    "            f.write(f\"F1-Score: {best_result['f1_macro']:.4f}\\n\")\n",
    "            f.write(f\"{'='*110}\\n\")\n",
    "        \n",
    "        f.write(\"\\nFILES GENERATED\\n\")\n",
    "        f.write(\"-\" * 110 + \"\\n\")\n",
    "        f.write(\"- Trained model files (.h5)\\n\")\n",
    "        f.write(\"- Training logs (CSV)\\n\")\n",
    "        f.write(\"- Training curves and analysis plots\\n\")\n",
    "        f.write(\"- Confusion matrices\\n\")\n",
    "        f.write(\"- ROC curves\\n\")\n",
    "        f.write(\"- Evaluation metrics (JSON)\\n\")\n",
    "        f.write(\"- Summary table (CSV)\\n\")\n",
    "    \n",
    "    print(f\"Final report generated: {report_path}\")\n",
    "    return report_path\n",
    "\n",
    "report_file = generate_final_report()\n",
    "print(f\"\\nReport saved and ready for submission\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 8486055,
     "sourceId": 13375708,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13375674,"sourceType":"datasetVersion","datasetId":8486036}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# CELL 1: Installation & Environment Setup","metadata":{}},{"cell_type":"code","source":"\nimport subprocess\nimport sys\nimport warnings\nimport os\n\nprint(\"=\"*80)\nprint(\"ENVIRONMENT SETUP - FINAL VERSION\")\nprint(\"=\"*80)\n\n# 1. Clean install\nprint(\"\\n[1/4] Cleaning old packages...\")\nsubprocess.run([\"pip\", \"uninstall\", \"-y\", \"-q\", \n                \"scipy\", \"scikit-learn\", \"scikit-image\", \"pillow\", \"torchvision\", \"torch\"], \n               stderr=subprocess.DEVNULL, stdout=subprocess.DEVNULL)\n\n# 2. Install PyTorch ONLY (no torchvision)\nprint(\"[2/4] Installing PyTorch 2.0.1...\")\nsubprocess.run([\"pip\", \"install\", \"--no-cache-dir\", \"-q\", \"torch==2.0.1\"], \n               stderr=subprocess.DEVNULL)\n\n# 3. Install NumPy & basics\nprint(\"[3/4] Installing NumPy, Pillow, OpenCV...\")\nsubprocess.run([\"pip\", \"install\", \"--no-cache-dir\", \"-q\",\n                \"numpy==1.24.3\",\n                \"pillow==10.0.0\",\n                \"matplotlib==3.7.1\",\n                \"seaborn==0.12.2\",\n                \"pandas==2.0.3\",\n                \"tqdm==4.66.1\",\n                \"opencv-python==4.8.0.74\",\n                \"scikit-image==0.21.0\"],\n               stderr=subprocess.DEVNULL)\n\n# 4. Install SciPy\nprint(\"[4/4] Installing SciPy...\")\nsubprocess.run([\"pip\", \"install\", \"--no-cache-dir\", \"-q\", \"scipy==1.11.0\"],\n               stderr=subprocess.DEVNULL)\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"VERIFYING IMPORTS...\")\nprint(\"=\"*80 + \"\\n\")\n\nwarnings.filterwarnings('ignore')\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n\n# Import PyTorch core\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\nprint(f\"✓ PyTorch {torch.__version__}\")\n\n# Import data science libraries\nimport numpy as np\nimport pandas as pd\nimport scipy\nimport cv2\nfrom PIL import Image\n\nprint(f\"✓ NumPy {np.__version__}\")\nprint(f\"✓ Pandas {pd.__version__}\")\nprint(f\"✓ SciPy {scipy.__version__}\")\nprint(f\"✓ OpenCV available\")\nprint(f\"✓ PIL available\")\n\n# Import visualization\nimport matplotlib\nmatplotlib.use('Agg')\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nprint(f\"✓ Matplotlib {matplotlib.__version__}\")\nprint(f\"✓ Seaborn available\")\n\n# Import utilities\nfrom tqdm import tqdm\nimport json\nimport time\nimport random\nimport gc\nfrom collections import defaultdict\nfrom pathlib import Path\n\nprint(f\"✓ Utilities imported\")\n\n# Manual torchvision.transforms replacement using OpenCV\nclass transforms:\n    \"\"\"Manual transforms implementation using OpenCV (no torchvision dependency)\"\"\"\n    \n    class Normalize:\n        def __init__(self, mean, std):\n            self.mean = np.array(mean)\n            self.std = np.array(std)\n        \n        def __call__(self, img):\n            return (img - self.mean) / self.std\n    \n    class ToTensor:\n        def __call__(self, img):\n            if isinstance(img, np.ndarray):\n                img = torch.from_numpy(img).float()\n                if len(img.shape) == 2:\n                    img = img.unsqueeze(0)\n                elif img.shape[2] == 3:\n                    img = img.permute(2, 0, 1)\n                return img\n            return torch.from_numpy(np.array(img)).float()\n    \n    class RandomHorizontalFlip:\n        def __init__(self, p=0.5):\n            self.p = p\n        \n        def __call__(self, img):\n            if random.random() < self.p:\n                img = cv2.flip(img, 1)\n            return img\n    \n    class RandomVerticalFlip:\n        def __init__(self, p=0.5):\n            self.p = p\n        \n        def __call__(self, img):\n            if random.random() < self.p:\n                img = cv2.flip(img, 0)\n            return img\n    \n    class RandomResizedCrop:\n        def __init__(self, size, scale=(0.08, 1.0), ratio=(3./4., 4./3.)):\n            self.size = size\n            self.scale = scale\n            self.ratio = ratio\n        \n        def __call__(self, img):\n            h, w = img.shape[:2]\n            area = h * w\n            \n            for _ in range(10):\n                target_area = area * random.uniform(*self.scale)\n                log_ratio = (np.log(self.ratio[0]), np.log(self.ratio[1]))\n                aspect_ratio = np.exp(random.uniform(*log_ratio))\n                \n                w_crop = int(np.sqrt(target_area * aspect_ratio))\n                h_crop = int(np.sqrt(target_area / aspect_ratio))\n                \n                if w_crop < w and h_crop < h:\n                    top = random.randint(0, h - h_crop)\n                    left = random.randint(0, w - w_crop)\n                    img = img[top:top+h_crop, left:left+w_crop]\n                    img = cv2.resize(img, (self.size, self.size))\n                    return img\n            \n            return cv2.resize(img, (self.size, self.size))\n    \n    class ColorJitter:\n        def __init__(self, brightness=0, contrast=0, saturation=0, hue=0):\n            self.brightness = brightness\n            self.contrast = contrast\n            self.saturation = saturation\n            self.hue = hue\n        \n        def __call__(self, img):\n            # Simple brightness adjustment\n            if self.brightness > 0:\n                factor = random.uniform(1-self.brightness, 1+self.brightness)\n                img = np.clip(img * factor, 0, 255).astype(np.uint8)\n            return img\n    \n    class GaussianBlur:\n        def __init__(self, kernel_size=5, sigma=(0.1, 2.0)):\n            self.kernel_size = kernel_size\n            self.sigma = sigma\n        \n        def __call__(self, img):\n            if random.random() < 0.5:\n                sig = random.uniform(*self.sigma)\n                img = cv2.GaussianBlur(img, (self.kernel_size, self.kernel_size), sig)\n            return img\n    \n    class RandomRotation:\n        def __init__(self, degrees=15):\n            self.degrees = degrees\n        \n        def __call__(self, img):\n            if random.random() < 0.5:\n                angle = random.uniform(-self.degrees, self.degrees)\n                h, w = img.shape[:2]\n                M = cv2.getRotationMatrix2D((w/2, h/2), angle, 1.0)\n                img = cv2.warpAffine(img, M, (w, h))\n            return img\n    \n    class Compose:\n        def __init__(self, transforms_list):\n            self.transforms = transforms_list\n        \n        def __call__(self, img):\n            for t in self.transforms:\n                img = t(img)\n            return img\n\n# Manual ResNet50 loading (just use torch's built-in)\ndef resnet50(pretrained=True):\n    \"\"\"Load ResNet50 backbone\"\"\"\n    try:\n        # Try using torchvision if available\n        from torchvision.models import resnet50 as tv_resnet50\n        return tv_resnet50(pretrained=pretrained)\n    except:\n        # Fallback: create empty ResNet50 without weights\n        print(\"⚠ Using ResNet50 without pretrained weights (torchvision unavailable)\")\n        # For now, we'll create a simple backbone\n        raise ImportError(\"Please install torchvision separately\")\n\nprint(f\"✓ Manual transforms implementation loaded\")\n\n# Set reproducibility\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed_all(SEED)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\n# Set device\nif torch.cuda.is_available():\n    device = torch.device(\"cuda\")\n    print(f\"\\n✓ CUDA Available: {torch.cuda.get_device_name(0)}\")\n    print(f\"✓ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\nelse:\n    device = torch.device(\"cpu\")\n    print(f\"\\n⚠ CPU mode (no CUDA)\")\n\nprint(f\"✓ Device: {str(device).upper()}\")\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"✓✓✓ ENVIRONMENT READY ✓✓✓\")\nprint(\"=\"*80 + \"\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T08:54:05.880664Z","iopub.execute_input":"2025-12-03T08:54:05.881252Z","iopub.status.idle":"2025-12-03T08:54:48.722305Z","shell.execute_reply.started":"2025-12-03T08:54:05.881227Z","shell.execute_reply":"2025-12-03T08:54:48.721451Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nENVIRONMENT SETUP - FINAL VERSION\n================================================================================\n\n[1/4] Cleaning old packages...\n[2/4] Installing PyTorch 2.0.1...\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 619.9/619.9 MB 366.4 MB/s eta 0:00:00\n[3/4] Installing NumPy, Pillow, OpenCV...\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.0/62.0 kB 3.8 MB/s eta 0:00:00\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.0/62.0 kB 36.6 MB/s eta 0:00:00\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.0/62.0 kB 64.7 MB/s eta 0:00:00\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 61.9/61.9 kB 36.9 MB/s eta 0:00:00\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.0/62.0 kB 49.2 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.4/3.4 MB 59.9 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13.7/13.7 MB 150.4 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 37.7/37.7 MB 279.5 MB/s eta 0:00:00\n[4/4] Installing SciPy...\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 59.1/59.1 kB 4.0 MB/s eta 0:00:00\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 36.2/36.2 MB 356.7 MB/s eta 0:00:00\n\n================================================================================\nVERIFYING IMPORTS...\n================================================================================\n\n✓ PyTorch 2.6.0+cu124\n✓ NumPy 1.26.4\n✓ Pandas 2.0.3\n✓ SciPy 1.11.0\n✓ OpenCV available\n✓ PIL available\n✓ Matplotlib 3.7.2\n✓ Seaborn available\n✓ Utilities imported\n✓ Manual transforms implementation loaded\n\n✓ CUDA Available: Tesla P100-PCIE-16GB\n✓ GPU Memory: 17.06 GB\n✓ Device: CUDA\n\n================================================================================\n✓✓✓ ENVIRONMENT READY ✓✓✓\n================================================================================\n\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"# CELL 2: DATASET SETUP & LOADING","metadata":{}},{"cell_type":"code","source":"# CELL 2: DATASET SETUP & LOADING\n\nimport os\nfrom pathlib import Path\n\n# Setup directories\nDATA_DIR = \"/kaggle/input/dataset-for-classifying-rice-varieties-in-bd/Rice Varieties in Bangladesh/Original\" \nOUTPUT_DIR = \"/kaggle/working\"\ncheckpoint_dir = os.path.join(OUTPUT_DIR, \"checkpoints\")\n\nos.makedirs(checkpoint_dir, exist_ok=True)\nos.makedirs(OUTPUT_DIR, exist_ok=True)\n\nprint(\"=\"*80)\nprint(\"DATASET SETUP\")\nprint(\"=\"*80 + \"\\n\")\n\n# Get all class names from directory\nclass_names = sorted([d for d in os.listdir(DATA_DIR) if os.path.isdir(os.path.join(DATA_DIR, d))])\nnum_classes = len(class_names)\n\nprint(f\"Classes found: {num_classes}\")\nprint(f\"Classes: {class_names}\\n\")\n\n# Count images per class\nclass_counts = {}\nfor cls in class_names:\n    cls_path = os.path.join(DATA_DIR, cls)\n    count = len([f for f in os.listdir(cls_path) if f.lower().endswith(('.jpg', '.png', '.jpeg'))])\n    class_counts[cls] = count\n    print(f\"  {cls}: {count} images\")\n\ntotal_images = sum(class_counts.values())\nprint(f\"\\nTotal images: {total_images}\\n\")\n\nprint(\"=\"*80)\nprint(\"✓ Dataset ready\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T08:57:45.301291Z","iopub.execute_input":"2025-12-03T08:57:45.301577Z","iopub.status.idle":"2025-12-03T08:57:45.751466Z","shell.execute_reply.started":"2025-12-03T08:57:45.301556Z","shell.execute_reply":"2025-12-03T08:57:45.750722Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nDATASET SETUP\n================================================================================\n\nClasses found: 38\nClasses: ['BD30', 'BD33', 'BD39', 'BD49', 'BD51', 'BD52', 'BD56', 'BD57', 'BD70', 'BD72', 'BD75', 'BD76', 'BD79', 'BD85', 'BD87', 'BD91', 'BD93', 'BD95', 'BR22', 'BR23', 'BRRI102', 'BRRI67', 'BRRI74', 'Binadhan10', 'Binadhan11', 'Binadhan12', 'Binadhan14', 'Binadhan16', 'Binadhan17', 'Binadhan19', 'Binadhan20', 'Binadhan21', 'Binadhan23', 'Binadhan24', 'Binadhan25', 'Binadhan26', 'Binadhan7', 'Binadhan8']\n\n  BD30: 500 images\n  BD33: 500 images\n  BD39: 500 images\n  BD49: 500 images\n  BD51: 500 images\n  BD52: 500 images\n  BD56: 500 images\n  BD57: 500 images\n  BD70: 500 images\n  BD72: 500 images\n  BD75: 500 images\n  BD76: 500 images\n  BD79: 500 images\n  BD85: 500 images\n  BD87: 500 images\n  BD91: 500 images\n  BD93: 500 images\n  BD95: 500 images\n  BR22: 500 images\n  BR23: 500 images\n  BRRI102: 500 images\n  BRRI67: 500 images\n  BRRI74: 500 images\n  Binadhan10: 500 images\n  Binadhan11: 500 images\n  Binadhan12: 500 images\n  Binadhan14: 500 images\n  Binadhan16: 500 images\n  Binadhan17: 500 images\n  Binadhan19: 500 images\n  Binadhan20: 500 images\n  Binadhan21: 500 images\n  Binadhan23: 500 images\n  Binadhan24: 500 images\n  Binadhan25: 500 images\n  Binadhan26: 500 images\n  Binadhan7: 500 images\n  Binadhan8: 500 images\n\nTotal images: 19000\n\n================================================================================\n✓ Dataset ready\n\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"# CELL 3: CUSTOM DATASET & DATA AUGMENTATION","metadata":{}},{"cell_type":"code","source":"# CELL 3: CUSTOM DATASET & DATA AUGMENTATION\n\nclass RiceDataset(Dataset):\n    def __init__(self, data_dir, class_names, transform=None, img_size=224):\n        self.data_dir = data_dir\n        self.class_names = class_names\n        self.transform = transform\n        self.img_size = img_size\n        self.images = []\n        self.labels = []\n        \n        # Load all images\n        for class_idx, class_name in enumerate(class_names):\n            class_dir = os.path.join(data_dir, class_name)\n            for img_file in os.listdir(class_dir):\n                if img_file.lower().endswith(('.jpg', '.png', '.jpeg')):\n                    self.images.append(os.path.join(class_dir, img_file))\n                    self.labels.append(class_idx)\n        \n        print(f\"Loaded {len(self.images)} images\")\n    \n    def __len__(self):\n        return len(self.images)\n    \n    def __getitem__(self, idx):\n        img_path = self.images[idx]\n        label = self.labels[idx]\n        \n        # Load image\n        try:\n            img = cv2.imread(img_path)\n            if img is None:\n                img = cv2.imread(self.images[0])\n            \n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n            img = cv2.resize(img, (self.img_size, self.img_size))\n            img = img.astype(np.float32) / 255.0\n            \n        except Exception as e:\n            print(f\"Error loading {img_path}: {e}\")\n            img = np.random.rand(self.img_size, self.img_size, 3).astype(np.float32)\n        \n        if self.transform:\n            img = self.transform(img)\n        \n        # Convert to tensor\n        img = torch.from_numpy(img.transpose(2, 0, 1)).float()\n        \n        return {\n            'image': img,\n            'label': torch.tensor(label, dtype=torch.long)\n        }\n\n\nclass AugmentationPipeline:\n    def __init__(self, img_size=224):\n        self.img_size = img_size\n    \n    def __call__(self, img):\n        # Random horizontal flip\n        if random.random() < 0.5:\n            img = cv2.flip(img, 1)\n        \n        # Random vertical flip\n        if random.random() < 0.3:\n            img = cv2.flip(img, 0)\n        \n        # Random rotation\n        if random.random() < 0.5:\n            angle = random.uniform(-15, 15)\n            h, w = img.shape[:2]\n            M = cv2.getRotationMatrix2D((w/2, h/2), angle, 1.0)\n            img = cv2.warpAffine(img, M, (w, h))\n        \n        # Random brightness\n        if random.random() < 0.5:\n            brightness_factor = random.uniform(0.85, 1.15)\n            img = np.clip(img * brightness_factor, 0, 1)\n        \n        # Random contrast\n        if random.random() < 0.5:\n            contrast_factor = random.uniform(0.85, 1.15)\n            img = np.clip(img * contrast_factor, 0, 1)\n        \n        # Random Gaussian blur\n        if random.random() < 0.3:\n            img = cv2.GaussianBlur(img, (5, 5), 0)\n        \n        return img\n\n\nprint(\"=\"*80)\nprint(\"CREATING DATASETS\")\nprint(\"=\"*80 + \"\\n\")\n\n# Create datasets\ntrain_transform = AugmentationPipeline(img_size=224)\ntrain_dataset = RiceDataset(DATA_DIR, class_names, transform=train_transform, img_size=224)\n\nprint(f\"✓ Dataset created: {len(train_dataset)} images, {num_classes} classes\\n\")\n\n# DataLoader\nBATCH_SIZE = 32\nNUM_WORKERS = 4\n\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    num_workers=NUM_WORKERS,\n    pin_memory=True\n)\n\nprint(f\"✓ DataLoader created\")\nprint(f\"  Batch size: {BATCH_SIZE}\")\nprint(f\"  Batches per epoch: {len(train_loader)}\")\nprint(f\"  Total samples: {len(train_dataset)}\\n\")\n\nprint(\"=\"*80)\nprint(\"✓ Data loading complete\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T08:58:13.279004Z","iopub.execute_input":"2025-12-03T08:58:13.279588Z","iopub.status.idle":"2025-12-03T08:58:13.339250Z","shell.execute_reply.started":"2025-12-03T08:58:13.279561Z","shell.execute_reply":"2025-12-03T08:58:13.338494Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nCREATING DATASETS\n================================================================================\n\nLoaded 19000 images\n✓ Dataset created: 19000 images, 38 classes\n\n✓ DataLoader created\n  Batch size: 32\n  Batches per epoch: 594\n  Total samples: 19000\n\n================================================================================\n✓ Data loading complete\n\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"# CELL 4: DINO MODEL IMPLEMENTATION\n","metadata":{}},{"cell_type":"code","source":"# CELL 4: DINO MODEL IMPLEMENTATION\n\nclass DINO_Backbone(nn.Module):\n    def __init__(self, img_size=224, patch_size=16, embed_dim=384, depth=12, num_heads=12):\n        super().__init__()\n        self.img_size = img_size\n        self.patch_size = patch_size\n        self.num_patches = (img_size // patch_size) ** 2\n        self.embed_dim = embed_dim\n        \n        # Patch embedding\n        self.patch_embed = nn.Conv2d(3, embed_dim, kernel_size=patch_size, stride=patch_size)\n        \n        # Class token\n        self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n        \n        # Position embedding\n        self.pos_embed = nn.Parameter(torch.zeros(1, self.num_patches + 1, embed_dim))\n        nn.init.trunc_normal_(self.pos_embed, std=0.02)\n        \n        # Transformer\n        encoder_layer = nn.TransformerEncoderLayer(\n            d_model=embed_dim,\n            nhead=num_heads,\n            dim_feedforward=embed_dim * 4,\n            dropout=0.1,\n            batch_first=True,\n            activation='gelu'\n        )\n        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=depth)\n        \n        # Layer norm\n        self.norm = nn.LayerNorm(embed_dim)\n        \n        self.apply(self._init_weights)\n    \n    def _init_weights(self, m):\n        if isinstance(m, nn.Linear):\n            nn.init.trunc_normal_(m.weight, std=0.02)\n            if m.bias is not None:\n                nn.init.constant_(m.bias, 0)\n        elif isinstance(m, nn.LayerNorm):\n            nn.init.constant_(m.bias, 0)\n            nn.init.constant_(m.weight, 1.0)\n    \n    def forward(self, x):\n        B = x.shape[0]\n        \n        # Patch embedding\n        x = self.patch_embed(x)\n        x = x.flatten(2).transpose(1, 2)\n        \n        # Add class token\n        cls_tokens = self.cls_token.expand(B, -1, -1)\n        x = torch.cat([cls_tokens, x], dim=1)\n        \n        # Add position embedding\n        x = x + self.pos_embed\n        \n        # Transformer\n        x = self.transformer(x)\n        x = self.norm(x)\n        \n        return x[:, 0]\n\n\nclass DINOHead(nn.Module):\n    def __init__(self, in_dim=384, out_dim=4096, hidden_dim=2048, num_layers=3):\n        super().__init__()\n        layers = []\n        for i in range(num_layers):\n            if i == 0:\n                layers.append(nn.Linear(in_dim, hidden_dim))\n            elif i == num_layers - 1:\n                layers.append(nn.Linear(hidden_dim, out_dim))\n            else:\n                layers.append(nn.Linear(hidden_dim, hidden_dim))\n            \n            if i < num_layers - 1:\n                layers.append(nn.GELU())\n                layers.append(nn.BatchNorm1d(hidden_dim))\n        \n        self.mlp = nn.Sequential(*layers)\n    \n    def forward(self, x):\n        return self.mlp(x)\n\n\nclass DINOModel(nn.Module):\n    def __init__(self, backbone_dim=384, proj_dim=4096):\n        super().__init__()\n        self.backbone = DINO_Backbone(embed_dim=backbone_dim)\n        self.student_head = DINOHead(in_dim=backbone_dim, out_dim=proj_dim)\n        self.teacher_backbone = DINO_Backbone(embed_dim=backbone_dim)\n        self.teacher_head = DINOHead(in_dim=backbone_dim, out_dim=proj_dim)\n        \n        # Freeze teacher\n        for p in self.teacher_backbone.parameters():\n            p.requires_grad = False\n        for p in self.teacher_head.parameters():\n            p.requires_grad = False\n    \n    def forward(self, x_student, x_teacher):\n        # Student forward\n        student_feat = self.backbone(x_student)\n        student_out = self.student_head(student_feat)\n        \n        # Teacher forward (no grad)\n        with torch.no_grad():\n            teacher_feat = self.teacher_backbone(x_teacher)\n            teacher_out = self.teacher_head(teacher_feat)\n        \n        return student_out, teacher_out, student_feat\n\n\nprint(\"=\"*80)\nprint(\"DINO MODEL ARCHITECTURE\")\nprint(\"=\"*80 + \"\\n\")\n\n# Model params\nEMBED_DIM = 384\nPROJ_DIM = 4096\nBACKBONE_DIM = 384\n\n# Create model\ndino_model = DINOModel(backbone_dim=BACKBONE_DIM, proj_dim=PROJ_DIM).to(device)\n\nprint(f\"✓ DINO Model created\")\nprint(f\"  Backbone: Vision Transformer\")\nprint(f\"  Embedding dim: {EMBED_DIM}\")\nprint(f\"  Projection dim: {PROJ_DIM}\")\nprint(f\"  Device: {device}\\n\")\n\n# Count parameters\ntotal_params = sum(p.numel() for p in dino_model.parameters())\nstudent_params_count = sum(p.numel() for p in dino_model.backbone.parameters()) + sum(p.numel() for p in dino_model.student_head.parameters())\n\nprint(f\"  Total parameters: {total_params:,}\")\nprint(f\"  Student parameters (trainable): {student_params_count:,}\\n\")\n\nprint(\"=\"*80)\nprint(\"✓ Model ready\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T08:58:42.358547Z","iopub.execute_input":"2025-12-03T08:58:42.358823Z","iopub.status.idle":"2025-12-03T08:58:43.187019Z","shell.execute_reply.started":"2025-12-03T08:58:42.358804Z","shell.execute_reply":"2025-12-03T08:58:43.186365Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nDINO MODEL ARCHITECTURE\n================================================================================\n\n✓ DINO Model created\n  Backbone: Vision Transformer\n  Embedding dim: 384\n  Projection dim: 4096\n  Device: cuda\n\n  Total parameters: 70,102,784\n  Student parameters (trainable): 35,051,392\n\n================================================================================\n✓ Model ready\n\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"# CELL 5: TRAINING SETUP & LOSS FUNCTION\n","metadata":{}},{"cell_type":"code","source":"# CELL 5: TRAINING SETUP & LOSS FUNCTION (PATCHED)\n\n# CRITICAL FIX: Disable ONNX imports manually to prevent PyTorch crash\nimport sys\nimport types\n# Mock the missing ONNX module to bypass the error\nsys.modules['torch.onnx'] = types.ModuleType('torch.onnx')\nsys.modules['torch.onnx'].is_in_onnx_export = False\n\nclass DINOLoss(nn.Module):\n    def __init__(self, out_dim=4096, warmup_teacher_temp=0.04, teacher_temp=0.07, student_temp=0.1):\n        super().__init__()\n        self.student_temp = student_temp\n        self.teacher_temp = teacher_temp\n        self.center = torch.zeros(1, out_dim).to(device)\n    \n    def forward(self, student_output, teacher_output):\n        # Normalize\n        student_output = torch.nn.functional.normalize(student_output, dim=-1, p=2)\n        teacher_output = torch.nn.functional.normalize(teacher_output, dim=-1, p=2)\n        \n        # DINO loss: cross entropy with temperature\n        student_out = student_output / self.student_temp\n        teacher_out = teacher_output / self.teacher_temp\n        \n        # Compute cross-entropy\n        loss = torch.mean(torch.sum(-teacher_out * torch.nn.functional.log_softmax(student_out, dim=-1), dim=-1))\n        \n        return loss\n\n\nprint(\"=\"*80)\nprint(\"TRAINING SETUP (PATCHED)\")\nprint(\"=\"*80 + \"\\n\")\n\n# Training params\nNUM_EPOCHS = 35\nLEARNING_RATE = 0.02\nMOMENTUM = 0.9\nWARMUP_EPOCHS = 3\nWEIGHT_DECAY = 1e-4\n\n# Optimizer (using SGD)\nstudent_params_list = list(dino_model.backbone.parameters()) + list(dino_model.student_head.parameters())\n\n# Use raw SGD implementation if torch.optim fails\ntry:\n    optimizer = torch.optim.SGD(student_params_list, lr=LEARNING_RATE, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\nexcept Exception as e:\n    print(f\"⚠ Standard optimizer failed, using minimal custom SGD: {e}\")\n    # Minimal SGD implementation as fallback\n    class MinimalSGD:\n        def __init__(self, params, lr=0.01, momentum=0.9, weight_decay=0):\n            self.params = list(params)\n            self.lr = lr\n            self.momentum = momentum\n            self.weight_decay = weight_decay\n            self.velocities = [torch.zeros_like(p) for p in self.params]\n            self.param_groups = [{'lr': lr}] # Compatibility\n        \n        def zero_grad(self):\n            for p in self.params:\n                if p.grad is not None:\n                    p.grad.detach_()\n                    p.grad.zero_()\n        \n        def step(self):\n            with torch.no_grad():\n                for i, p in enumerate(self.params):\n                    if p.grad is None: continue\n                    grad = p.grad\n                    if self.weight_decay != 0:\n                        grad = grad.add(p, alpha=self.weight_decay)\n                    \n                    vel = self.velocities[i]\n                    vel.mul_(self.momentum).add_(grad)\n                    p.add_(vel, alpha=-self.lr)\n        \n        def state_dict(self): return {} # Dummy\n        def load_state_dict(self, state_dict): pass # Dummy\n\n    optimizer = MinimalSGD(student_params_list, lr=LEARNING_RATE, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n\n\n# Loss\ncriterion = DINOLoss(out_dim=PROJ_DIM).to(device)\n\n# Learning rate scheduler\ntry:\n    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS, eta_min=1e-5)\nexcept:\n    # Fallback simple scheduler\n    class SimpleScheduler:\n        def __init__(self, optimizer): self.optimizer = optimizer\n        def step(self): pass\n    scheduler = SimpleScheduler(optimizer)\n\nprint(f\"✓ Training configured\")\nprint(f\"  Epochs: {NUM_EPOCHS}\")\nprint(f\"  Base learning rate: {LEARNING_RATE}\")\nprint(f\"  Optimizer: SGD (patched)\")\nprint(f\"  Loss: DINO Cross-Entropy\\n\")\n\nprint(\"=\"*80)\nprint(\"✓ Setup complete\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T09:01:43.649377Z","iopub.execute_input":"2025-12-03T09:01:43.650071Z","iopub.status.idle":"2025-12-03T09:01:43.960346Z","shell.execute_reply.started":"2025-12-03T09:01:43.650049Z","shell.execute_reply":"2025-12-03T09:01:43.959637Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nTRAINING SETUP (PATCHED)\n================================================================================\n\n⚠ Standard optimizer failed, using minimal custom SGD: cannot import name 'set_guard_fail_hook' from 'torch._dynamo.eval_frame' (/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py)\n✓ Training configured\n  Epochs: 35\n  Base learning rate: 0.02\n  Optimizer: SGD (patched)\n  Loss: DINO Cross-Entropy\n\n================================================================================\n✓ Setup complete\n\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"# CELL 6: TRAINING LOOP","metadata":{}},{"cell_type":"code","source":"# CELL 6: TRAINING LOOP (35 EPOCHS)\n\nprint(\"=\"*80)\nprint(\"DINO PRETRAINING STARTED\")\nprint(\"=\"*80 + \"\\n\")\n\ntrain_losses = []\nbest_loss = float('inf')\npatience = 7\npatience_counter = 0\nstart_time = time.time()\n\n# EMA (Exponential Moving Average) for teacher\nEMA_TAU = 0.999\n\nfor epoch in range(NUM_EPOCHS):\n    epoch_loss = 0.0\n    epoch_samples = 0\n    \n    dino_model.train()\n    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS}\", leave=False)\n    \n    for batch_idx, batch in enumerate(pbar):\n        # Get images\n        images = batch['image'].to(device)\n        B = images.shape[0]\n        \n        # Create two augmented crops\n        crop1 = images\n        crop2 = images.clone()\n        \n        # Random augmentation on crop2\n        if random.random() < 0.5:\n            crop2 = torch.flip(crop2, [3])\n        \n        # Forward pass\n        student_out, teacher_out, student_feat = dino_model(crop1, crop2)\n        \n        # Loss\n        loss = criterion(student_out, teacher_out)\n        \n        # Backward\n        optimizer.zero_grad()\n        loss.backward()\n        \n        # Gradient clipping\n        torch.nn.utils.clip_grad_norm_(student_params_list, max_norm=1.0)\n        \n        optimizer.step()\n        \n        # Update teacher (exponential moving average)\n        with torch.no_grad():\n            for param_s, param_t in zip(dino_model.backbone.parameters(), dino_model.teacher_backbone.parameters()):\n                param_t.data = EMA_TAU * param_t.data + (1 - EMA_TAU) * param_s.data.detach()\n            \n            for param_s, param_t in zip(dino_model.student_head.parameters(), dino_model.teacher_head.parameters()):\n                param_t.data = EMA_TAU * param_t.data + (1 - EMA_TAU) * param_s.data.detach()\n        \n        epoch_loss += loss.item() * B\n        epoch_samples += B\n        \n        pbar.set_postfix({'loss': f'{epoch_loss/max(epoch_samples, 1):.4f}'})\n    \n    # Epoch metrics\n    avg_loss = epoch_loss / epoch_samples\n    train_losses.append(avg_loss)\n    \n    # Learning rate update\n    try:\n        scheduler.step()\n    except:\n        pass\n    \n    current_lr = optimizer.param_groups[0]['lr']\n    print(f\"Epoch {epoch+1}/{NUM_EPOCHS} | Loss: {avg_loss:.4f} | LR: {current_lr:.6f}\")\n    \n    # Save checkpoint\n    if avg_loss < best_loss:\n        best_loss = avg_loss\n        patience_counter = 0\n        torch.save({\n            'epoch': epoch,\n            'student_state': dino_model.backbone.state_dict(),\n            'teacher_state': dino_model.teacher_backbone.state_dict(),\n            'optimizer_state': optimizer.param_groups if hasattr(optimizer, 'param_groups') else {},\n            'loss': avg_loss,\n            'train_losses': train_losses,\n        }, os.path.join(checkpoint_dir, 'best_checkpoint.pt'))\n        print(f\"  ✓ Saved best checkpoint (loss: {avg_loss:.4f})\")\n    else:\n        patience_counter += 1\n        if patience_counter >= patience:\n            print(f\"\\n✓ Early stopping triggered after {patience} epochs without improvement\")\n            break\n\ntotal_training_time = (time.time() - start_time) / 3600\n\nprint(f\"\\n{'='*80}\")\nprint(f\"TRAINING COMPLETED\")\nprint(f\"{'='*80}\")\nprint(f\"✓ Total time: {total_training_time:.2f} hours\")\nprint(f\"✓ Best loss: {best_loss:.4f}\")\nprint(f\"✓ Epochs trained: {len(train_losses)}\")\nprint(f\"✓ Checkpoint saved to {checkpoint_dir}\\n\")\n\n# Save training losses for visualization\nnp.save(os.path.join(OUTPUT_DIR, 'train_losses.npy'), np.array(train_losses))\nprint(f\"✓ Training losses saved\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T09:03:34.250677Z","iopub.execute_input":"2025-12-03T09:03:34.251270Z","iopub.status.idle":"2025-12-03T09:36:28.328707Z","shell.execute_reply.started":"2025-12-03T09:03:34.251246Z","shell.execute_reply":"2025-12-03T09:36:28.327926Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nDINO PRETRAINING STARTED\n================================================================================\n\n","output_type":"stream"},{"name":"stderr","text":"                                                                            \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1/35 | Loss: -43.0315 | LR: 0.020000\n  ✓ Saved best checkpoint (loss: -43.0315)\n","output_type":"stream"},{"name":"stderr","text":"                                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2/35 | Loss: -121.6097 | LR: 0.020000\n  ✓ Saved best checkpoint (loss: -121.6097)\n","output_type":"stream"},{"name":"stderr","text":"                                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3/35 | Loss: -143.6975 | LR: 0.020000\n  ✓ Saved best checkpoint (loss: -143.6975)\n","output_type":"stream"},{"name":"stderr","text":"                                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 4/35 | Loss: -143.4943 | LR: 0.020000\n","output_type":"stream"},{"name":"stderr","text":"                                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 5/35 | Loss: -143.1436 | LR: 0.020000\n","output_type":"stream"},{"name":"stderr","text":"                                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 6/35 | Loss: -142.9534 | LR: 0.020000\n","output_type":"stream"},{"name":"stderr","text":"                                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 7/35 | Loss: -142.8529 | LR: 0.020000\n","output_type":"stream"},{"name":"stderr","text":"                                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 8/35 | Loss: -142.7935 | LR: 0.020000\n","output_type":"stream"},{"name":"stderr","text":"                                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 9/35 | Loss: -142.7681 | LR: 0.020000\n","output_type":"stream"},{"name":"stderr","text":"                                                                              ","output_type":"stream"},{"name":"stdout","text":"Epoch 10/35 | Loss: -142.7732 | LR: 0.020000\n\n✓ Early stopping triggered after 7 epochs without improvement\n\n================================================================================\nTRAINING COMPLETED\n================================================================================\n✓ Total time: 0.55 hours\n✓ Best loss: -143.6975\n✓ Epochs trained: 10\n✓ Checkpoint saved to /kaggle/working/checkpoints\n\n✓ Training losses saved\n\n","output_type":"stream"},{"name":"stderr","text":"\r","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"# CELL 7: FEATURE EXTRACTION\n","metadata":{}},{"cell_type":"code","source":"# CELL 7: FEATURE EXTRACTION\n\nprint(\"=\"*80)\nprint(\"FEATURE EXTRACTION\")\nprint(\"=\"*80 + \"\\n\")\n\n# Load best model\nbest_checkpoint = torch.load(os.path.join(checkpoint_dir, 'best_checkpoint.pt'), map_location=device)\ndino_model.backbone.load_state_dict(best_checkpoint['student_state'])\nprint(f\"✓ Loaded best student checkpoint (loss: {best_checkpoint['loss']:.4f})\\n\")\n\n# Extract features\ndef extract_features(model, dataloader, device):\n    model.eval()\n    all_features = []\n    all_labels = []\n    \n    with torch.no_grad():\n        for batch in tqdm(dataloader, desc=\"Extracting features\"):\n            images = batch['image'].to(device)\n            labels = batch['label']\n            \n            features = model.backbone(images)\n            \n            all_features.append(features.cpu().numpy())\n            all_labels.append(labels.numpy())\n    \n    features = np.concatenate(all_features, axis=0)\n    labels = np.concatenate(all_labels, axis=0)\n    \n    return features, labels\n\nprint(\"Extracting training features...\")\ntrain_features, train_labels = extract_features(dino_model, train_loader, device)\n\nprint(f\"\\n✓ Extracted features successfully\")\nprint(f\"  Feature shape: {train_features.shape}\")\nprint(f\"  Feature dimension: {train_features.shape[1]}\")\nprint(f\"  Number of samples: {train_features.shape[0]}\")\nprint(f\"  Label shape: {train_labels.shape}\")\nprint(f\"  Unique classes: {len(np.unique(train_labels))}\\n\")\n\n# Save features\nnp.save(os.path.join(OUTPUT_DIR, 'train_features.npy'), train_features)\nnp.save(os.path.join(OUTPUT_DIR, 'train_labels.npy'), train_labels)\nprint(f\"✓ Features saved to {OUTPUT_DIR}\\n\")\n\nprint(\"=\"*80)\nprint(\"✓ Feature extraction complete\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T09:51:57.728292Z","iopub.execute_input":"2025-12-03T09:51:57.729046Z","iopub.status.idle":"2025-12-03T09:53:24.028713Z","shell.execute_reply.started":"2025-12-03T09:51:57.729011Z","shell.execute_reply":"2025-12-03T09:53:24.027755Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nFEATURE EXTRACTION\n================================================================================\n\n✓ Loaded best student checkpoint (loss: -143.6975)\n\nExtracting training features...\n","output_type":"stream"},{"name":"stderr","text":"Extracting features: 100%|██████████| 594/594 [01:26<00:00,  6.90it/s]","output_type":"stream"},{"name":"stdout","text":"\n✓ Extracted features successfully\n  Feature shape: (19000, 384)\n  Feature dimension: 384\n  Number of samples: 19000\n  Label shape: (19000,)\n  Unique classes: 38\n\n✓ Features saved to /kaggle/working\n\n================================================================================\n✓ Feature extraction complete\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"# CELL 8: LINEAR PROBE EVALUATION\n","metadata":{}},{"cell_type":"code","source":"# CELL 8: LINEAR PROBE EVALUATION\n\nprint(\"=\"*80)\nprint(\"LINEAR PROBE TRAINING\")\nprint(\"=\"*80 + \"\\n\")\n\n# Manual train-test split\ndef manual_train_test_split(X, y, test_size=0.2, random_state=42):\n    np.random.seed(random_state)\n    indices = np.arange(len(X))\n    np.random.shuffle(indices)\n    split_idx = int(len(X) * (1 - test_size))\n    train_idx = indices[:split_idx]\n    test_idx = indices[split_idx:]\n    return X[train_idx], X[test_idx], y[train_idx], y[test_idx]\n\nX_train_lp, X_val_lp, y_train_lp, y_val_lp = manual_train_test_split(train_features, train_labels, test_size=0.2)\n\nprint(f\"Linear Probe split:\")\nprint(f\"  Train: {X_train_lp.shape[0]} samples\")\nprint(f\"  Val: {X_val_lp.shape[0]} samples\\n\")\n\n# Linear probe classifier\nclass LinearProbe(nn.Module):\n    def __init__(self, input_dim, num_classes):\n        super().__init__()\n        self.fc = nn.Linear(input_dim, num_classes)\n    \n    def forward(self, x):\n        return self.fc(x)\n\nlr_model = LinearProbe(X_train_lp.shape[1], num_classes).to(device)\n\n# Convert to tensors\nX_train_tensor = torch.from_numpy(X_train_lp).float().to(device)\ny_train_tensor = torch.from_numpy(y_train_lp).long().to(device)\nX_val_tensor = torch.from_numpy(X_val_lp).float().to(device)\ny_val_tensor = torch.from_numpy(y_val_lp).long()\n\n# Create dataloader\nlr_dataset = torch.utils.data.TensorDataset(X_train_tensor, y_train_tensor)\nlr_loader_lp = torch.utils.data.DataLoader(lr_dataset, batch_size=128, shuffle=True)\n\n# Loss and optimizer\nlr_criterion = nn.CrossEntropyLoss()\n\n# Use custom optimizer if needed\ntry:\n    lr_optimizer = torch.optim.Adam(lr_model.parameters(), lr=0.01)\nexcept:\n    class MinimalAdam:\n        def __init__(self, params, lr=0.01):\n            self.params = list(params)\n            self.lr = lr\n            self.t = 0\n            self.m = [torch.zeros_like(p) for p in self.params]\n            self.v = [torch.zeros_like(p) for p in self.params]\n            self.param_groups = [{'lr': lr}]\n        \n        def zero_grad(self):\n            for p in self.params:\n                if p.grad is not None:\n                    p.grad.zero_()\n        \n        def step(self):\n            self.t += 1\n            with torch.no_grad():\n                for i, p in enumerate(self.params):\n                    if p.grad is None: continue\n                    grad = p.grad\n                    self.m[i] = 0.9 * self.m[i] + 0.1 * grad\n                    self.v[i] = 0.999 * self.v[i] + 0.001 * grad**2\n                    m_hat = self.m[i] / (1 - 0.9**self.t)\n                    v_hat = self.v[i] / (1 - 0.999**self.t)\n                    p.add_(m_hat / (torch.sqrt(v_hat) + 1e-8), alpha=-self.lr)\n    \n    lr_optimizer = MinimalAdam(lr_model.parameters(), lr=0.01)\n\n# Train linear probe\nprint(\"Training linear probe...\")\nfor epoch in range(50):\n    lr_model.train()\n    for features, labels in lr_loader_lp:\n        lr_optimizer.zero_grad()\n        logits = lr_model(features)\n        loss = lr_criterion(logits, labels)\n        loss.backward()\n        lr_optimizer.step()\n\n# Evaluate\nlr_model.eval()\nwith torch.no_grad():\n    val_logits = lr_model(X_val_tensor.to(device))\n    y_val_pred = val_logits.argmax(dim=1).cpu().numpy()\n\n# Metrics\nlinear_probe_acc = np.mean(y_val_pred == y_val_lp)\nlinear_probe_precision = np.mean([np.mean(y_val_pred[y_val_lp == c] == c) for c in range(num_classes) if np.sum(y_val_lp == c) > 0])\nlinear_probe_recall = np.mean([np.mean(y_val_lp[y_val_lp == c] == y_val_pred[y_val_lp == c]) for c in range(num_classes) if np.sum(y_val_lp == c) > 0])\nlinear_probe_f1 = 2 * (linear_probe_precision * linear_probe_recall) / (linear_probe_precision + linear_probe_recall + 1e-8)\n\nprint(f\"\\n✓ Linear Probe Results:\")\nprint(f\"  Accuracy:  {linear_probe_acc:.4f}\")\nprint(f\"  Precision: {linear_probe_precision:.4f}\")\nprint(f\"  Recall:    {linear_probe_recall:.4f}\")\nprint(f\"  F1-Score:  {linear_probe_f1:.4f}\\n\")\n\nprint(\"=\"*80)\nprint(\"✓ Linear probe evaluation complete\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T10:00:18.192451Z","iopub.execute_input":"2025-12-03T10:00:18.193171Z","iopub.status.idle":"2025-12-03T10:00:29.707777Z","shell.execute_reply.started":"2025-12-03T10:00:18.193140Z","shell.execute_reply":"2025-12-03T10:00:29.707036Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nLINEAR PROBE TRAINING\n================================================================================\n\nLinear Probe split:\n  Train: 15200 samples\n  Val: 3800 samples\n\nTraining linear probe...\n\n✓ Linear Probe Results:\n  Accuracy:  0.2887\n  Precision: 0.2862\n  Recall:    0.2862\n  F1-Score:  0.2862\n\n================================================================================\n✓ Linear probe evaluation complete\n\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"# CELL 9: MLP CLASSIFIER\n","metadata":{}},{"cell_type":"code","source":"# CELL 9: MLP CLASSIFIER\n\nprint(\"=\"*80)\nprint(\"MLP CLASSIFIER TRAINING\")\nprint(\"=\"*80 + \"\\n\")\n\nclass SimpleMLPClassifier(nn.Module):\n    def __init__(self, input_dim, num_classes, hidden_dim=1024):\n        super().__init__()\n        self.mlp = nn.Sequential(\n            nn.Linear(input_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(hidden_dim, hidden_dim // 2),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(hidden_dim // 2, num_classes)\n        )\n    \n    def forward(self, x):\n        return self.mlp(x)\n\nmlp = SimpleMLPClassifier(X_train_lp.shape[1], num_classes, hidden_dim=1024).to(device)\n\n# Loss and optimizer\nmlp_criterion = nn.CrossEntropyLoss()\n\ntry:\n    mlp_optimizer = torch.optim.Adam(mlp.parameters(), lr=0.001)\nexcept:\n    class MinimalAdam:\n        def __init__(self, params, lr=0.001):\n            self.params = list(params)\n            self.lr = lr\n            self.t = 0\n            self.m = [torch.zeros_like(p) for p in self.params]\n            self.v = [torch.zeros_like(p) for p in self.params]\n            self.param_groups = [{'lr': lr}]\n        \n        def zero_grad(self):\n            for p in self.params:\n                if p.grad is not None:\n                    p.grad.zero_()\n        \n        def step(self):\n            self.t += 1\n            with torch.no_grad():\n                for i, p in enumerate(self.params):\n                    if p.grad is None: continue\n                    grad = p.grad\n                    self.m[i] = 0.9 * self.m[i] + 0.1 * grad\n                    self.v[i] = 0.999 * self.v[i] + 0.001 * grad**2\n                    m_hat = self.m[i] / (1 - 0.9**self.t)\n                    v_hat = self.v[i] / (1 - 0.999**self.t)\n                    p.add_(m_hat / (torch.sqrt(v_hat) + 1e-8), alpha=-self.lr)\n    \n    mlp_optimizer = MinimalAdam(mlp.parameters(), lr=0.001)\n\n# Create dataloader for MLP\nmlp_dataset = torch.utils.data.TensorDataset(X_train_tensor, y_train_tensor)\nmlp_loader = torch.utils.data.DataLoader(mlp_dataset, batch_size=128, shuffle=True)\n\n# Train MLP\nprint(\"Training MLP classifier...\")\nbest_mlp_loss = float('inf')\npatience_mlp = 5\npatience_counter_mlp = 0\n\nfor epoch in range(50):\n    mlp.train()\n    total_loss = 0\n    for features, labels in mlp_loader:\n        mlp_optimizer.zero_grad()\n        logits = mlp(features)\n        loss = mlp_criterion(logits, labels)\n        loss.backward()\n        mlp_optimizer.step()\n        total_loss += loss.item()\n    \n    avg_loss = total_loss / len(mlp_loader)\n    \n    if avg_loss < best_mlp_loss:\n        best_mlp_loss = avg_loss\n        patience_counter_mlp = 0\n    else:\n        patience_counter_mlp += 1\n        if patience_counter_mlp >= patience_mlp:\n            break\n    \n    if (epoch + 1) % 10 == 0:\n        print(f\"  Epoch {epoch+1}/50 - Loss: {avg_loss:.4f}\")\n\n# Evaluate MLP\nmlp.eval()\nwith torch.no_grad():\n    mlp_val_logits = mlp(X_val_tensor.to(device))\n    mlp_val_pred = mlp_val_logits.argmax(dim=1).cpu().numpy()\n\nmlp_acc = np.mean(mlp_val_pred == y_val_lp)\nmlp_precision = np.mean([np.mean(mlp_val_pred[y_val_lp == c] == c) for c in range(num_classes) if np.sum(y_val_lp == c) > 0])\nmlp_recall = np.mean([np.mean(y_val_lp[y_val_lp == c] == mlp_val_pred[y_val_lp == c]) for c in range(num_classes) if np.sum(y_val_lp == c) > 0])\nmlp_f1 = 2 * (mlp_precision * mlp_recall) / (mlp_precision + mlp_recall + 1e-8)\n\nprint(f\"\\n✓ MLP Classifier Results:\")\nprint(f\"  Accuracy:  {mlp_acc:.4f}\")\nprint(f\"  Precision: {mlp_precision:.4f}\")\nprint(f\"  Recall:    {mlp_recall:.4f}\")\nprint(f\"  F1-Score:  {mlp_f1:.4f}\\n\")\n\nprint(\"=\"*80)\nprint(\"✓ MLP evaluation complete\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T10:02:53.547201Z","iopub.execute_input":"2025-12-03T10:02:53.547732Z","iopub.status.idle":"2025-12-03T10:03:09.442139Z","shell.execute_reply.started":"2025-12-03T10:02:53.547706Z","shell.execute_reply":"2025-12-03T10:03:09.441418Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nMLP CLASSIFIER TRAINING\n================================================================================\n\nTraining MLP classifier...\n  Epoch 10/50 - Loss: 2.2375\n  Epoch 20/50 - Loss: 2.0587\n  Epoch 30/50 - Loss: 2.0217\n  Epoch 40/50 - Loss: 1.9970\n\n✓ MLP Classifier Results:\n  Accuracy:  0.3582\n  Precision: 0.3598\n  Recall:    0.3598\n  F1-Score:  0.3598\n\n================================================================================\n✓ MLP evaluation complete\n\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"# CELL 10: SVM CLASSIFIER (Manual Implementation)","metadata":{}},{"cell_type":"code","source":"# CELL 10: SVM CLASSIFIER (Manual Implementation)\n\nprint(\"=\"*80)\nprint(\"SVM CLASSIFIER TRAINING\")\nprint(\"=\"*80 + \"\\n\")\n\nclass SimpleSVM(nn.Module):\n    def __init__(self, input_dim, num_classes, C=0.01):\n        super().__init__()\n        self.fc = nn.Linear(input_dim, num_classes)\n        self.C = C\n    \n    def forward(self, x):\n        return self.fc(x)\n    \n    def hinge_loss(self, output, target):\n        one_hot = torch.zeros_like(output)\n        one_hot.scatter_(1, target.unsqueeze(1), 1)\n        \n        margin = 1.0 - (output * one_hot - output * (1 - one_hot))\n        loss = torch.clamp(margin, min=0).sum(dim=1).mean()\n        \n        l2_reg = torch.sum(self.fc.weight ** 2)\n        return loss + self.C * l2_reg\n\nsvm_model = SimpleSVM(X_train_lp.shape[1], num_classes, C=0.01).to(device)\n\ntry:\n    svm_optimizer = torch.optim.SGD(svm_model.parameters(), lr=0.01, momentum=0.9)\nexcept:\n    class MinimalSGD:\n        def __init__(self, params, lr=0.01, momentum=0.9):\n            self.params = list(params)\n            self.lr = lr\n            self.momentum = momentum\n            self.velocities = [torch.zeros_like(p) for p in self.params]\n            self.param_groups = [{'lr': lr}]\n        \n        def zero_grad(self):\n            for p in self.params:\n                if p.grad is not None:\n                    p.grad.zero_()\n        \n        def step(self):\n            with torch.no_grad():\n                for i, p in enumerate(self.params):\n                    if p.grad is None: continue\n                    vel = self.velocities[i]\n                    vel.mul_(self.momentum).add_(p.grad)\n                    p.add_(vel, alpha=-self.lr)\n    \n    svm_optimizer = MinimalSGD(svm_model.parameters(), lr=0.01, momentum=0.9)\n\n# Train SVM\nprint(\"Training SVM classifier...\")\nfor epoch in range(50):\n    svm_model.train()\n    total_loss = 0\n    for features, labels in mlp_loader:\n        svm_optimizer.zero_grad()\n        logits = svm_model(features)\n        loss = svm_model.hinge_loss(logits, labels)\n        loss.backward()\n        svm_optimizer.step()\n        total_loss += loss.item()\n    \n    if (epoch + 1) % 10 == 0:\n        print(f\"  Epoch {epoch+1}/50 - Loss: {total_loss/len(mlp_loader):.4f}\")\n\n# Evaluate SVM\nsvm_model.eval()\nwith torch.no_grad():\n    svm_val_logits = svm_model(X_val_tensor.to(device))\n    svm_val_pred = svm_val_logits.argmax(dim=1).cpu().numpy()\n\nsvm_acc = np.mean(svm_val_pred == y_val_lp)\nsvm_precision = np.mean([np.mean(svm_val_pred[y_val_lp == c] == c) for c in range(num_classes) if np.sum(y_val_lp == c) > 0])\nsvm_recall = np.mean([np.mean(y_val_lp[y_val_lp == c] == svm_val_pred[y_val_lp == c]) for c in range(num_classes) if np.sum(y_val_lp == c) > 0])\nsvm_f1 = 2 * (svm_precision * svm_recall) / (svm_precision + svm_recall + 1e-8)\n\nprint(f\"\\n✓ SVM Classifier Results:\")\nprint(f\"  Accuracy:  {svm_acc:.4f}\")\nprint(f\"  Precision: {svm_precision:.4f}\")\nprint(f\"  Recall:    {svm_recall:.4f}\")\nprint(f\"  F1-Score:  {svm_f1:.4f}\\n\")\n\nprint(\"=\"*80)\nprint(\"✓ SVM evaluation complete\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T10:03:29.747039Z","iopub.execute_input":"2025-12-03T10:03:29.747318Z","iopub.status.idle":"2025-12-03T10:03:42.177693Z","shell.execute_reply.started":"2025-12-03T10:03:29.747298Z","shell.execute_reply":"2025-12-03T10:03:42.176993Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nSVM CLASSIFIER TRAINING\n================================================================================\n\nTraining SVM classifier...\n  Epoch 10/50 - Loss: 3.6463\n  Epoch 20/50 - Loss: 3.6320\n  Epoch 30/50 - Loss: 3.6171\n  Epoch 40/50 - Loss: 3.5840\n  Epoch 50/50 - Loss: 3.3947\n\n✓ SVM Classifier Results:\n  Accuracy:  0.1079\n  Precision: 0.1044\n  Recall:    0.1044\n  F1-Score:  0.1044\n\n================================================================================\n✓ SVM evaluation complete\n\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"# CELL 11: CONFUSION MATRIX & PER-CLASS ANALYSIS\n","metadata":{}},{"cell_type":"code","source":"# CELL 11: CONFUSION MATRIX & PER-CLASS ANALYSIS\n\nprint(\"=\"*80)\nprint(\"PER-CLASS ANALYSIS\")\nprint(\"=\"*80 + \"\\n\")\n\ndef compute_confusion_matrix(y_true, y_pred, num_classes):\n    cm = np.zeros((num_classes, num_classes))\n    for i in range(len(y_true)):\n        cm[y_true[i], y_pred[i]] += 1\n    return cm\n\n# Confusion matrices\ncm_linear = compute_confusion_matrix(y_val_lp, y_val_pred, num_classes)\ncm_mlp = compute_confusion_matrix(y_val_lp, mlp_val_pred, num_classes)\ncm_svm = compute_confusion_matrix(y_val_lp, svm_val_pred, num_classes)\n\n# Per-class accuracy\nprint(\"Per-Class Accuracy (MLP):\\n\")\nper_class_acc_mlp = []\nfor c in range(num_classes):\n    if np.sum(cm_mlp[c, :]) > 0:\n        acc = cm_mlp[c, c] / np.sum(cm_mlp[c, :])\n        per_class_acc_mlp.append(acc)\n        print(f\"  {class_names[c]:<30} {acc:.4f}\")\n    else:\n        per_class_acc_mlp.append(0)\n\nprint(f\"\\nTop-5 Best Classes:\")\ntop_5_idx = np.argsort(per_class_acc_mlp)[-5:][::-1]\nfor idx in top_5_idx:\n    if idx < len(class_names):\n        print(f\"  {class_names[idx]:<30} {per_class_acc_mlp[idx]:.4f}\")\n\nprint(f\"\\nBottom-5 Worst Classes:\")\nbottom_5_idx = np.argsort(per_class_acc_mlp)[:5]\nfor idx in bottom_5_idx:\n    if idx < len(class_names):\n        print(f\"  {class_names[idx]:<30} {per_class_acc_mlp[idx]:.4f}\")\n\nprint(f\"\\n\" + \"=\"*80)\nprint(\"✓ Per-class analysis complete\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T10:04:01.421144Z","iopub.execute_input":"2025-12-03T10:04:01.421843Z","iopub.status.idle":"2025-12-03T10:04:01.436848Z","shell.execute_reply.started":"2025-12-03T10:04:01.421817Z","shell.execute_reply":"2025-12-03T10:04:01.436175Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nPER-CLASS ANALYSIS\n================================================================================\n\nPer-Class Accuracy (MLP):\n\n  BD30                           0.0603\n  BD33                           0.0714\n  BD39                           0.9032\n  BD49                           0.3178\n  BD51                           0.5437\n  BD52                           0.2404\n  BD56                           0.1207\n  BD57                           0.0288\n  BD70                           0.0714\n  BD72                           0.3810\n  BD75                           0.1111\n  BD76                           0.7500\n  BD79                           0.5532\n  BD85                           0.0000\n  BD87                           0.4348\n  BD91                           0.4091\n  BD93                           0.4536\n  BD95                           0.6484\n  BR22                           0.0526\n  BR23                           0.8073\n  BRRI102                        0.0625\n  BRRI67                         0.0577\n  BRRI74                         0.0000\n  Binadhan10                     0.2889\n  Binadhan11                     0.8000\n  Binadhan12                     0.0291\n  Binadhan14                     0.0000\n  Binadhan16                     0.4946\n  Binadhan17                     0.4831\n  Binadhan19                     0.8247\n  Binadhan20                     1.0000\n  Binadhan21                     0.3182\n  Binadhan23                     0.4778\n  Binadhan24                     0.2115\n  Binadhan25                     0.5312\n  Binadhan26                     0.2315\n  Binadhan7                      0.4404\n  Binadhan8                      0.4630\n\nTop-5 Best Classes:\n  Binadhan20                     1.0000\n  BD39                           0.9032\n  Binadhan19                     0.8247\n  BR23                           0.8073\n  Binadhan11                     0.8000\n\nBottom-5 Worst Classes:\n  BD85                           0.0000\n  BRRI74                         0.0000\n  Binadhan14                     0.0000\n  BD57                           0.0288\n  Binadhan12                     0.0291\n\n================================================================================\n✓ Per-class analysis complete\n\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"# CELL 12: CLASSIFIER COMPARISON\n","metadata":{}},{"cell_type":"code","source":"# CELL 12: CLASSIFIER COMPARISON\n\nprint(\"=\"*80)\nprint(\"CLASSIFIER COMPARISON\")\nprint(\"=\"*80 + \"\\n\")\n\ncomparison_data = {\n    'Linear Probe': {\n        'Accuracy': linear_probe_acc,\n        'Precision': linear_probe_precision,\n        'Recall': linear_probe_recall,\n        'F1': linear_probe_f1\n    },\n    'MLP': {\n        'Accuracy': mlp_acc,\n        'Precision': mlp_precision,\n        'Recall': mlp_recall,\n        'F1': mlp_f1\n    },\n    'SVM': {\n        'Accuracy': svm_acc,\n        'Precision': svm_precision,\n        'Recall': svm_recall,\n        'F1': svm_f1\n    }\n}\n\nprint(\"Metrics Comparison:\\n\")\nprint(f\"{'Classifier':<15} {'Accuracy':<12} {'Precision':<12} {'Recall':<12} {'F1-Score':<12}\")\nprint(\"-\" * 70)\nfor clf_name, metrics in comparison_data.items():\n    print(f\"{clf_name:<15} {metrics['Accuracy']:<12.4f} {metrics['Precision']:<12.4f} {metrics['Recall']:<12.4f} {metrics['F1']:<12.4f}\")\n\nprint(\"-\" * 70)\n\nbest_clf = max(comparison_data.items(), key=lambda x: x[1]['Accuracy'])\nprint(f\"\\n✓ Best Classifier: {best_clf[0]} (Accuracy: {best_clf[1]['Accuracy']:.4f})\\n\")\n\nprint(\"=\"*80)\nprint(\"✓ Comparison complete\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T10:04:50.068242Z","iopub.execute_input":"2025-12-03T10:04:50.068946Z","iopub.status.idle":"2025-12-03T10:04:50.075455Z","shell.execute_reply.started":"2025-12-03T10:04:50.068916Z","shell.execute_reply":"2025-12-03T10:04:50.074861Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nCLASSIFIER COMPARISON\n================================================================================\n\nMetrics Comparison:\n\nClassifier      Accuracy     Precision    Recall       F1-Score    \n----------------------------------------------------------------------\nLinear Probe    0.2887       0.2862       0.2862       0.2862      \nMLP             0.3582       0.3598       0.3598       0.3598      \nSVM             0.1079       0.1044       0.1044       0.1044      \n----------------------------------------------------------------------\n\n✓ Best Classifier: MLP (Accuracy: 0.3582)\n\n================================================================================\n✓ Comparison complete\n\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"# CELL 13: TRAINING LOSS VISUALIZATION","metadata":{}},{"cell_type":"code","source":"# CELL 13: TRAINING LOSS VISUALIZATION\n\nprint(\"=\"*80)\nprint(\"VISUALIZATION: TRAINING LOSS\")\nprint(\"=\"*80 + \"\\n\")\n\n# Load saved losses\ntrain_losses = np.load(os.path.join(OUTPUT_DIR, 'train_losses.npy'))\n\n# Plot training loss\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# Loss curve\naxes[0].plot(range(1, len(train_losses) + 1), train_losses, linewidth=2.5, color='#3498db', marker='o')\naxes[0].set_xlabel('Epoch', fontsize=12, fontweight='bold')\naxes[0].set_ylabel('Loss', fontsize=12, fontweight='bold')\naxes[0].set_title('DINO Pretraining Loss', fontsize=14, fontweight='bold')\naxes[0].grid(True, alpha=0.3)\naxes[0].axhline(y=np.min(train_losses), color='r', linestyle='--', linewidth=2, label=f'Best: {np.min(train_losses):.4f}')\naxes[0].legend(fontsize=11)\n\n# Comparison bar chart\nclf_names = list(comparison_data.keys())\naccuracies = [comparison_data[clf]['Accuracy'] for clf in clf_names]\ncolors = ['#3498db', '#2ecc71', '#e74c3c']\nbars = axes[1].bar(clf_names, accuracies, color=colors, edgecolor='black', linewidth=2)\naxes[1].set_ylabel('Accuracy', fontsize=12, fontweight='bold')\naxes[1].set_title('Downstream Classifier Accuracy', fontsize=14, fontweight='bold')\naxes[1].set_ylim([0, 1])\naxes[1].grid(axis='y', alpha=0.3)\n\n# Add value labels on bars\nfor bar in bars:\n    height = bar.get_height()\n    axes[1].text(bar.get_x() + bar.get_width()/2., height,\n                f'{height:.4f}', ha='center', va='bottom', fontsize=11, fontweight='bold')\n\nplt.tight_layout()\nplt.savefig(os.path.join(OUTPUT_DIR, 'training_comparison.png'), dpi=150, bbox_inches='tight')\nprint(f\"✓ Saved visualization to {OUTPUT_DIR}/training_comparison.png\\n\")\nplt.close()\n\nprint(\"=\"*80)\nprint(\"✓ Visualization complete\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T10:05:19.773451Z","iopub.execute_input":"2025-12-03T10:05:19.773722Z","iopub.status.idle":"2025-12-03T10:05:20.242524Z","shell.execute_reply.started":"2025-12-03T10:05:19.773702Z","shell.execute_reply":"2025-12-03T10:05:20.241824Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nVISUALIZATION: TRAINING LOSS\n================================================================================\n\n✓ Saved visualization to /kaggle/working/training_comparison.png\n\n================================================================================\n✓ Visualization complete\n\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"# CELL 14: CONFUSION MATRIX HEATMAP","metadata":{}},{"cell_type":"code","source":"# CELL 14: CONFUSION MATRIX HEATMAP\n\nprint(\"=\"*80)\nprint(\"CONFUSION MATRIX VISUALIZATION\")\nprint(\"=\"*80 + \"\\n\")\n\nfig, axes = plt.subplots(1, 3, figsize=(18, 5))\n\nmatrices = [cm_linear, cm_mlp, cm_svm]\ntitles = ['Linear Probe', 'MLP', 'SVM']\nnames = [y_val_pred, mlp_val_pred, svm_val_pred]\n\nfor idx, (cm, title, ax) in enumerate(zip(matrices, titles, axes)):\n    # Normalize confusion matrix\n    cm_norm = cm.astype('float') / (cm.sum(axis=1)[:, np.newaxis] + 1e-8)\n    \n    # Plot heatmap\n    im = ax.imshow(cm_norm, cmap='Blues', aspect='auto')\n    ax.set_title(f'{title} Confusion Matrix', fontsize=12, fontweight='bold')\n    ax.set_xlabel('Predicted', fontsize=11)\n    ax.set_ylabel('True', fontsize=11)\n    \n    # Add colorbar\n    cbar = plt.colorbar(im, ax=ax)\n    cbar.set_label('Normalized Count', fontsize=10)\n\nplt.tight_layout()\nplt.savefig(os.path.join(OUTPUT_DIR, 'confusion_matrices.png'), dpi=150, bbox_inches='tight')\nprint(f\"✓ Saved confusion matrices to {OUTPUT_DIR}/confusion_matrices.png\\n\")\nplt.close()\n\nprint(\"=\"*80)\nprint(\"✓ Confusion matrix visualization complete\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T10:05:47.953750Z","iopub.execute_input":"2025-12-03T10:05:47.954474Z","iopub.status.idle":"2025-12-03T10:05:48.925346Z","shell.execute_reply.started":"2025-12-03T10:05:47.954445Z","shell.execute_reply":"2025-12-03T10:05:48.924625Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nCONFUSION MATRIX VISUALIZATION\n================================================================================\n\n✓ Saved confusion matrices to /kaggle/working/confusion_matrices.png\n\n================================================================================\n✓ Confusion matrix visualization complete\n\n","output_type":"stream"}],"execution_count":22},{"cell_type":"markdown","source":"# CELL 15: FINAL SUMMARY REPORT","metadata":{}},{"cell_type":"code","source":"# CELL 15: FINAL SUMMARY REPORT\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"DINO RICE LEAF DISEASE CLASSIFICATION - FINAL REPORT\")\nprint(\"=\"*80 + \"\\n\")\n\nprint(\"1. DATASET STATISTICS:\")\nprint(f\"   • Total images: {len(train_dataset)}\")\nprint(f\"   • Classes: {num_classes}\")\nprint(f\"   • Class names: {', '.join(class_names[:5])}{'...' if num_classes > 5 else ''}\\n\")\n\nprint(\"2. DINO PRETRAINING:\")\nprint(f\"   • Epochs trained: {len(train_losses)}\")\nprint(f\"   • Final loss: {train_losses[-1]:.4f}\")\nprint(f\"   • Best loss: {np.min(train_losses):.4f}\")\nprint(f\"   • Feature dimension: {train_features.shape[1]}\")\nprint(f\"   • Total training samples: {train_features.shape[0]}\\n\")\n\nprint(\"3. DOWNSTREAM EVALUATION (80-20 split):\")\nprint(f\"   • Training samples: {X_train_lp.shape[0]}\")\nprint(f\"   • Validation samples: {X_val_lp.shape[0]}\\n\")\n\nprint(\"4. LINEAR PROBE RESULTS:\")\nprint(f\"   ✓ Accuracy:  {linear_probe_acc:.4f}\")\nprint(f\"   ✓ Precision: {linear_probe_precision:.4f}\")\nprint(f\"   ✓ Recall:    {linear_probe_recall:.4f}\")\nprint(f\"   ✓ F1-Score:  {linear_probe_f1:.4f}\\n\")\n\nprint(\"5. MLP CLASSIFIER RESULTS:\")\nprint(f\"   ✓ Accuracy:  {mlp_acc:.4f}\")\nprint(f\"   ✓ Precision: {mlp_precision:.4f}\")\nprint(f\"   ✓ Recall:    {mlp_recall:.4f}\")\nprint(f\"   ✓ F1-Score:  {mlp_f1:.4f}\\n\")\n\nprint(\"6. SVM CLASSIFIER RESULTS:\")\nprint(f\"   ✓ Accuracy:  {svm_acc:.4f}\")\nprint(f\"   ✓ Precision: {svm_precision:.4f}\")\nprint(f\"   ✓ Recall:    {svm_recall:.4f}\")\nprint(f\"   ✓ F1-Score:  {svm_f1:.4f}\\n\")\n\nprint(\"7. BEST CLASSIFIER:\")\nprint(f\"   🏆 {best_clf[0]} with {best_clf[1]['Accuracy']:.4f} accuracy\\n\")\n\nprint(\"8. OUTPUT FILES:\")\nprint(f\"   ✓ Best checkpoint: {os.path.join(checkpoint_dir, 'best_checkpoint.pt')}\")\nprint(f\"   ✓ Training losses: {os.path.join(OUTPUT_DIR, 'train_losses.npy')}\")\nprint(f\"   ✓ Features: {os.path.join(OUTPUT_DIR, 'train_features.npy')}\")\nprint(f\"   ✓ Labels: {os.path.join(OUTPUT_DIR, 'train_labels.npy')}\")\nprint(f\"   ✓ Visualizations: {OUTPUT_DIR}/*.png\\n\")\n\nprint(\"=\"*80)\nprint(\"✓✓✓ PIPELINE COMPLETE - ALL ANALYSIS FINISHED ✓✓✓\")\nprint(\"=\"*80 + \"\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T10:06:18.816971Z","iopub.execute_input":"2025-12-03T10:06:18.817759Z","iopub.status.idle":"2025-12-03T10:06:18.827935Z","shell.execute_reply.started":"2025-12-03T10:06:18.817734Z","shell.execute_reply":"2025-12-03T10:06:18.827239Z"}},"outputs":[{"name":"stdout","text":"\n================================================================================\nDINO RICE LEAF DISEASE CLASSIFICATION - FINAL REPORT\n================================================================================\n\n1. DATASET STATISTICS:\n   • Total images: 19000\n   • Classes: 38\n   • Class names: BD30, BD33, BD39, BD49, BD51...\n\n2. DINO PRETRAINING:\n   • Epochs trained: 10\n   • Final loss: -142.7732\n   • Best loss: -143.6975\n   • Feature dimension: 384\n   • Total training samples: 19000\n\n3. DOWNSTREAM EVALUATION (80-20 split):\n   • Training samples: 15200\n   • Validation samples: 3800\n\n4. LINEAR PROBE RESULTS:\n   ✓ Accuracy:  0.2887\n   ✓ Precision: 0.2862\n   ✓ Recall:    0.2862\n   ✓ F1-Score:  0.2862\n\n5. MLP CLASSIFIER RESULTS:\n   ✓ Accuracy:  0.3582\n   ✓ Precision: 0.3598\n   ✓ Recall:    0.3598\n   ✓ F1-Score:  0.3598\n\n6. SVM CLASSIFIER RESULTS:\n   ✓ Accuracy:  0.1079\n   ✓ Precision: 0.1044\n   ✓ Recall:    0.1044\n   ✓ F1-Score:  0.1044\n\n7. BEST CLASSIFIER:\n   🏆 MLP with 0.3582 accuracy\n\n8. OUTPUT FILES:\n   ✓ Best checkpoint: /kaggle/working/checkpoints/best_checkpoint.pt\n   ✓ Training losses: /kaggle/working/train_losses.npy\n   ✓ Features: /kaggle/working/train_features.npy\n   ✓ Labels: /kaggle/working/train_labels.npy\n   ✓ Visualizations: /kaggle/working/*.png\n\n================================================================================\n✓✓✓ PIPELINE COMPLETE - ALL ANALYSIS FINISHED ✓✓✓\n================================================================================\n\n","output_type":"stream"}],"execution_count":23},{"cell_type":"markdown","source":"# CELL 13: TRAINING LOSS & ACCURACY COMPARISON (INLINE)","metadata":{}},{"cell_type":"code","source":"# CELL 13: TRAINING LOSS & ACCURACY COMPARISON (INLINE)\n\nprint(\"=\"*80)\nprint(\"VISUALIZATION: TRAINING LOSS & CLASSIFIER COMPARISON\")\nprint(\"=\"*80 + \"\\n\")\n\n# Load saved losses\ntrain_losses = np.load(os.path.join(OUTPUT_DIR, 'train_losses.npy'))\n\n# Create figure with subplots\nfig, axes = plt.subplots(2, 2, figsize=(15, 12))\n\n# 1. Training Loss Curve\naxes[0, 0].plot(range(1, len(train_losses) + 1), train_losses, linewidth=3, \n                color='#3498db', marker='o', markersize=8, label='Training Loss')\naxes[0, 0].set_xlabel('Epoch', fontsize=12, fontweight='bold')\naxes[0, 0].set_ylabel('Loss Value', fontsize=12, fontweight='bold')\naxes[0, 0].set_title('DINO Pretraining Loss Curve', fontsize=14, fontweight='bold')\naxes[0, 0].grid(True, alpha=0.3, linestyle='--')\naxes[0, 0].axhline(y=np.min(train_losses), color='r', linestyle='--', linewidth=2.5, \n                   label=f'Best Loss: {np.min(train_losses):.4f}')\naxes[0, 0].legend(fontsize=11, loc='best')\naxes[0, 0].fill_between(range(1, len(train_losses) + 1), train_losses, alpha=0.2, color='#3498db')\n\n# 2. Classifier Accuracy Comparison\nclf_names = list(comparison_data.keys())\naccuracies = [comparison_data[clf]['Accuracy'] for clf in clf_names]\ncolors_bar = ['#3498db', '#2ecc71', '#e74c3c']\nbars = axes[0, 1].bar(clf_names, accuracies, color=colors_bar, edgecolor='black', linewidth=2.5, alpha=0.8)\naxes[0, 1].set_ylabel('Accuracy', fontsize=12, fontweight='bold')\naxes[0, 1].set_title('Downstream Classifier Accuracy Comparison', fontsize=14, fontweight='bold')\naxes[0, 1].set_ylim([0, 1])\naxes[0, 1].grid(axis='y', alpha=0.3, linestyle='--')\n\n# Add value labels on bars\nfor bar in bars:\n    height = bar.get_height()\n    axes[0, 1].text(bar.get_x() + bar.get_width()/2., height + 0.02,\n                   f'{height:.4f}\\n({height*100:.2f}%)', \n                   ha='center', va='bottom', fontsize=11, fontweight='bold')\n\n# 3. F1-Score Comparison\nf1_scores = [comparison_data[clf]['F1'] for clf in clf_names]\nbars2 = axes[1, 0].bar(clf_names, f1_scores, color=colors_bar, edgecolor='black', linewidth=2.5, alpha=0.8)\naxes[1, 0].set_ylabel('F1-Score', fontsize=12, fontweight='bold')\naxes[1, 0].set_title('F1-Score Comparison', fontsize=14, fontweight='bold')\naxes[1, 0].set_ylim([0, 1])\naxes[1, 0].grid(axis='y', alpha=0.3, linestyle='--')\n\nfor bar in bars2:\n    height = bar.get_height()\n    axes[1, 0].text(bar.get_x() + bar.get_width()/2., height + 0.02,\n                   f'{height:.4f}', ha='center', va='bottom', fontsize=11, fontweight='bold')\n\n# 4. Precision vs Recall\nprecisions = [comparison_data[clf]['Precision'] for clf in clf_names]\nrecalls = [comparison_data[clf]['Recall'] for clf in clf_names]\n\nx_pos = np.arange(len(clf_names))\nwidth = 0.35\n\nbars_prec = axes[1, 1].bar(x_pos - width/2, precisions, width, label='Precision', \n                           color='#9b59b6', edgecolor='black', linewidth=2, alpha=0.8)\nbars_recall = axes[1, 1].bar(x_pos + width/2, recalls, width, label='Recall', \n                            color='#f39c12', edgecolor='black', linewidth=2, alpha=0.8)\n\naxes[1, 1].set_ylabel('Score', fontsize=12, fontweight='bold')\naxes[1, 1].set_title('Precision vs Recall Comparison', fontsize=14, fontweight='bold')\naxes[1, 1].set_xticks(x_pos)\naxes[1, 1].set_xticklabels(clf_names)\naxes[1, 1].set_ylim([0, 1])\naxes[1, 1].legend(fontsize=11, loc='best')\naxes[1, 1].grid(axis='y', alpha=0.3, linestyle='--')\n\nplt.tight_layout()\nplt.show()\n\nprint(\"✓ Visualization displayed inline\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T10:08:49.309818Z","iopub.execute_input":"2025-12-03T10:08:49.310335Z","iopub.status.idle":"2025-12-03T10:08:49.608472Z","shell.execute_reply.started":"2025-12-03T10:08:49.310313Z","shell.execute_reply":"2025-12-03T10:08:49.607921Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nVISUALIZATION: TRAINING LOSS & CLASSIFIER COMPARISON\n================================================================================\n\n✓ Visualization displayed inline\n\n","output_type":"stream"}],"execution_count":24},{"cell_type":"markdown","source":"# CELL 14: CONFUSION MATRICES (INLINE - LARGE VIEW)","metadata":{}},{"cell_type":"code","source":"# CELL 14: CONFUSION MATRICES (INLINE - LARGE VIEW)\n\nprint(\"=\"*80)\nprint(\"CONFUSION MATRICES VISUALIZATION\")\nprint(\"=\"*80 + \"\\n\")\n\nfig, axes = plt.subplots(1, 3, figsize=(20, 6))\n\nmatrices = [cm_linear, cm_mlp, cm_svm]\ntitles = ['Linear Probe', 'MLP', 'SVM']\naccs = [linear_probe_acc, mlp_acc, svm_acc]\n\nfor idx, (cm, title, ax, acc) in enumerate(zip(matrices, titles, axes, accs)):\n    # Normalize confusion matrix\n    cm_norm = cm.astype('float') / (cm.sum(axis=1)[:, np.newaxis] + 1e-8)\n    \n    # Plot heatmap\n    im = ax.imshow(cm_norm, cmap='YlOrRd', aspect='auto', vmin=0, vmax=1)\n    ax.set_title(f'{title} - Accuracy: {acc:.4f}', fontsize=13, fontweight='bold', pad=10)\n    ax.set_xlabel('Predicted Class', fontsize=11, fontweight='bold')\n    ax.set_ylabel('True Class', fontsize=11, fontweight='bold')\n    \n    # Set tick labels\n    ax.set_xticks(range(num_classes))\n    ax.set_yticks(range(num_classes))\n    ax.set_xticklabels([f'C{i}' for i in range(num_classes)], fontsize=9)\n    ax.set_yticklabels([f'C{i}' for i in range(num_classes)], fontsize=9)\n    \n    # Add colorbar\n    cbar = plt.colorbar(im, ax=ax)\n    cbar.set_label('Normalized Count', fontsize=10, fontweight='bold')\n\nplt.tight_layout()\nplt.show()\n\nprint(\"✓ Confusion matrices displayed inline\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T10:09:22.595054Z","iopub.execute_input":"2025-12-03T10:09:22.595709Z","iopub.status.idle":"2025-12-03T10:09:23.325783Z","shell.execute_reply.started":"2025-12-03T10:09:22.595683Z","shell.execute_reply":"2025-12-03T10:09:23.325014Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nCONFUSION MATRICES VISUALIZATION\n================================================================================\n\n✓ Confusion matrices displayed inline\n\n","output_type":"stream"}],"execution_count":25},{"cell_type":"markdown","source":"# CELL 15: PER-CLASS PERFORMANCE HEATMAP (INLINE)","metadata":{}},{"cell_type":"code","source":"# CELL 15: PER-CLASS PERFORMANCE HEATMAP (INLINE)\n\nprint(\"=\"*80)\nprint(\"PER-CLASS PERFORMANCE ANALYSIS\")\nprint(\"=\"*80 + \"\\n\")\n\n# Compute per-class metrics for each classifier\ndef compute_per_class_metrics(y_true, y_pred, num_classes):\n    accuracy = []\n    precision = []\n    recall = []\n    f1 = []\n    \n    for c in range(num_classes):\n        mask_true = y_true == c\n        mask_pred = y_pred == c\n        \n        if np.sum(mask_true) > 0:\n            acc = np.mean(y_pred[mask_true] == y_true[mask_true])\n            accuracy.append(acc)\n            \n            if np.sum(mask_pred) > 0:\n                prec = np.sum((y_pred[mask_true] == c)) / np.sum(mask_pred)\n                precision.append(prec)\n            else:\n                precision.append(0)\n            \n            rec = np.sum((y_pred[mask_true] == c)) / np.sum(mask_true)\n            recall.append(rec)\n            \n            if precision[-1] + recall[-1] > 0:\n                f1.append(2 * precision[-1] * recall[-1] / (precision[-1] + recall[-1]))\n            else:\n                f1.append(0)\n        else:\n            accuracy.append(0)\n            precision.append(0)\n            recall.append(0)\n            f1.append(0)\n    \n    return np.array(accuracy), np.array(precision), np.array(recall), np.array(f1)\n\n# Compute metrics\nlinear_acc, linear_prec, linear_rec, linear_f1 = compute_per_class_metrics(y_val_lp, y_val_pred, num_classes)\nmlp_acc, mlp_prec, mlp_rec, mlp_f1 = compute_per_class_metrics(y_val_lp, mlp_val_pred, num_classes)\nsvm_acc, svm_prec, svm_rec, svm_f1 = compute_per_class_metrics(y_val_lp, svm_val_pred, num_classes)\n\n# Create heatmap\nfig, axes = plt.subplots(2, 2, figsize=(16, 12))\n\nmetrics_list = [linear_acc, mlp_acc, svm_acc, mlp_f1]\ntitles_heatmap = ['Linear Probe - Accuracy', 'MLP - Accuracy', 'SVM - Accuracy', 'MLP - F1-Score']\n\nfor idx, (metric, title, ax) in enumerate(zip(metrics_list, titles_heatmap, axes.flat)):\n    # Create heatmap data (reshape for visualization)\n    heatmap_data = metric.reshape(-1, 1)\n    \n    im = ax.imshow(heatmap_data, cmap='RdYlGn', aspect='auto', vmin=0, vmax=1)\n    ax.set_yticks(range(num_classes))\n    ax.set_yticklabels([class_names[i] if i < len(class_names) else f'Class {i}' for i in range(num_classes)], fontsize=9)\n    ax.set_xticks([0])\n    ax.set_xticklabels(['Score'], fontsize=11, fontweight='bold')\n    ax.set_title(title, fontsize=12, fontweight='bold', pad=10)\n    \n    # Add value labels\n    for i in range(num_classes):\n        ax.text(0, i, f'{metric[i]:.3f}', ha='center', va='center', \n               color='white' if metric[i] < 0.5 else 'black', fontweight='bold', fontsize=10)\n    \n    cbar = plt.colorbar(im, ax=ax)\n    cbar.set_label('Score', fontsize=10, fontweight='bold')\n\nplt.tight_layout()\nplt.show()\n\nprint(\"✓ Per-class heatmaps displayed inline\\n\")\n\n# Print detailed per-class analysis\nprint(\"\\nDETAILED PER-CLASS PERFORMANCE (MLP - Best Classifier):\\n\")\nprint(f\"{'Class':<30} {'Accuracy':<12} {'Precision':<12} {'Recall':<12} {'F1-Score':<12}\")\nprint(\"-\" * 80)\nfor i in range(num_classes):\n    class_name = class_names[i] if i < len(class_names) else f'Class {i}'\n    print(f\"{class_name:<30} {mlp_acc[i]:<12.4f} {mlp_prec[i]:<12.4f} {mlp_rec[i]:<12.4f} {mlp_f1[i]:<12.4f}\")\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"✓ Per-class analysis complete\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T10:09:50.829109Z","iopub.execute_input":"2025-12-03T10:09:50.829411Z","iopub.status.idle":"2025-12-03T10:09:51.865038Z","shell.execute_reply.started":"2025-12-03T10:09:50.829388Z","shell.execute_reply":"2025-12-03T10:09:51.864413Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nPER-CLASS PERFORMANCE ANALYSIS\n================================================================================\n\n✓ Per-class heatmaps displayed inline\n\n\nDETAILED PER-CLASS PERFORMANCE (MLP - Best Classifier):\n\nClass                          Accuracy     Precision    Recall       F1-Score    \n--------------------------------------------------------------------------------\nBD30                           0.0603       0.1556       0.0603       0.0870      \nBD33                           0.0714       0.0959       0.0714       0.0819      \nBD39                           0.9032       0.7500       0.9032       0.8195      \nBD49                           0.3178       0.2012       0.3178       0.2464      \nBD51                           0.5437       0.2545       0.5437       0.3467      \nBD52                           0.2404       0.2119       0.2404       0.2252      \nBD56                           0.1207       0.2692       0.1207       0.1667      \nBD57                           0.0288       0.2308       0.0288       0.0513      \nBD70                           0.0714       0.2800       0.0714       0.1138      \nBD72                           0.3810       0.5333       0.3810       0.4444      \nBD75                           0.1111       0.1282       0.1111       0.1190      \nBD76                           0.7500       0.6818       0.7500       0.7143      \nBD79                           0.5532       0.1787       0.5532       0.2701      \nBD85                           0.0000       0.0000       0.0000       0.0000      \nBD87                           0.4348       0.3540       0.4348       0.3902      \nBD91                           0.4091       0.1846       0.4091       0.2544      \nBD93                           0.4536       0.2028       0.4536       0.2803      \nBD95                           0.6484       0.3856       0.6484       0.4836      \nBR22                           0.0526       0.1389       0.0526       0.0763      \nBR23                           0.8073       0.6111       0.8073       0.6957      \nBRRI102                        0.0625       0.2857       0.0625       0.1026      \nBRRI67                         0.0577       0.3000       0.0577       0.0968      \nBRRI74                         0.0000       0.0000       0.0000       0.0000      \nBinadhan10                     0.2889       0.6341       0.2889       0.3969      \nBinadhan11                     0.8000       0.5556       0.8000       0.6557      \nBinadhan12                     0.0291       0.3000       0.0291       0.0531      \nBinadhan14                     0.0000       0.0000       0.0000       0.0000      \nBinadhan16                     0.4946       0.3129       0.4946       0.3833      \nBinadhan17                     0.4831       0.3440       0.4831       0.4019      \nBinadhan19                     0.8247       0.9639       0.8247       0.8889      \nBinadhan20                     1.0000       1.0000       1.0000       1.0000      \nBinadhan21                     0.3182       0.2917       0.3182       0.3043      \nBinadhan23                     0.4778       0.2945       0.4778       0.3644      \nBinadhan24                     0.2115       0.3667       0.2115       0.2683      \nBinadhan25                     0.5312       0.5312       0.5312       0.5312      \nBinadhan26                     0.2315       0.3378       0.2315       0.2747      \nBinadhan7                      0.4404       0.3057       0.4404       0.3609      \nBinadhan8                      0.4630       0.2475       0.4630       0.3226      \n\n================================================================================\n✓ Per-class analysis complete\n\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"# CELL 16: FINAL SUMMARY WITH ALL METRICS (INLINE)\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"FINAL SUMMARY - DINO RICE LEAF DISEASE CLASSIFICATION\")\nprint(\"=\"*80 + \"\\n\")\n\n# Summary statistics\nprint(\"📊 PRETRAINING SUMMARY:\")\nprint(f\"   • Epochs trained: {len(train_losses)}\")\nprint(f\"   • Initial loss: {train_losses[0]:.4f}\")\nprint(f\"   • Final loss: {train_losses[-1]:.4f}\")\nprint(f\"   • Best loss: {np.min(train_losses):.4f}\")\nprint(f\"   • Improvement: {abs(train_losses[-1] - train_losses[0]):.4f}\\n\")\n\nprint(\"📈 DATASET BREAKDOWN:\")\nprint(f\"   • Total images: {len(train_dataset)}\")\nprint(f\"   • Number of classes: {num_classes}\")\nprint(f\"   • Feature dimension: {train_features.shape[1]}\")\nprint(f\"   • Training samples (80%): {X_train_lp.shape[0]}\")\nprint(f\"   • Validation samples (20%): {X_val_lp.shape[0]}\\n\")\n\nprint(\"🏆 CLASSIFIER PERFORMANCE RANKINGS:\\n\")\n\n# Rank by accuracy\nranking = sorted(comparison_data.items(), key=lambda x: x[1]['Accuracy'], reverse=True)\nfor idx, (name, metrics) in enumerate(ranking, 1):\n    print(f\"   {idx}. {name}\")\n    print(f\"      ├─ Accuracy:  {metrics['Accuracy']:.4f} ({metrics['Accuracy']*100:.2f}%)\")\n    print(f\"      ├─ Precision: {metrics['Precision']:.4f}\")\n    print(f\"      ├─ Recall:    {metrics['Recall']:.4f}\")\n    print(f\"      └─ F1-Score:  {metrics['F1']:.4f}\\n\")\n\nprint(\"🎯 BEST CLASSIFIER DETAILS:\")\nbest_name, best_metrics = ranking[0]\nprint(f\"   🏅 {best_name.upper()}\")\nprint(f\"      • Accuracy:  {best_metrics['Accuracy']:.4f}\")\nprint(f\"      • Precision: {best_metrics['Precision']:.4f}\")\nprint(f\"      • Recall:    {best_metrics['Recall']:.4f}\")\nprint(f\"      • F1-Score:  {best_metrics['F1']:.4f}\\n\")\n\n# Top and bottom performing classes\nprint(\"📍 TOP 5 BEST PERFORMING CLASSES (MLP):\\n\")\ntop_5_idx = np.argsort(mlp_acc)[-5:][::-1]\nfor rank, idx in enumerate(top_5_idx, 1):\n    class_name = class_names[idx] if idx < len(class_names) else f'Class {idx}'\n    print(f\"   {rank}. {class_name:<30} Accuracy: {mlp_acc[idx]:.4f}\")\n\nprint(\"\\n📍 TOP 5 WORST PERFORMING CLASSES (MLP):\\n\")\nbottom_5_idx = np.argsort(mlp_acc)[:5]\nfor rank, idx in enumerate(bottom_5_idx, 1):\n    class_name = class_names[idx] if idx < len(class_names) else f'Class {idx}'\n    print(f\"   {rank}. {class_name:<30} Accuracy: {mlp_acc[idx]:.4f}\")\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"✅ PIPELINE COMPLETED SUCCESSFULLY\")\nprint(\"=\"*80 + \"\\n\")\n\n# Create final summary visualization\nfig, ax = plt.subplots(figsize=(12, 8))\nax.axis('off')\n\nsummary_text = f\"\"\"\nDINO RICE LEAF DISEASE CLASSIFICATION - FINAL REPORT\n\nPRETRAINING RESULTS\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n• Model Architecture: Vision Transformer (DINO)\n• Epochs Trained: {len(train_losses)}\n• Final Loss: {train_losses[-1]:.4f}\n• Best Loss: {np.min(train_losses):.4f}\n\nDOWNSTREAM CLASSIFICATION RESULTS\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n1. {ranking[0][0]:<20} - Accuracy: {ranking[0][1]['Accuracy']:.4f} ⭐ BEST\n2. {ranking[1][0]:<20} - Accuracy: {ranking[1][1]['Accuracy']:.4f}\n3. {ranking[2][0]:<20} - Accuracy: {ranking[2][1]['Accuracy']:.4f}\n\nBEST CLASSIFIER METRICS (MLP)\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n• Accuracy:  {best_metrics['Accuracy']:.4f} ({best_metrics['Accuracy']*100:.2f}%)\n• Precision: {best_metrics['Precision']:.4f}\n• Recall:    {best_metrics['Recall']:.4f}\n• F1-Score:  {best_metrics['F1']:.4f}\n\nDATASET STATISTICS\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n• Total Images: {len(train_dataset)}\n• Classes: {num_classes}\n• Feature Dimension: {train_features.shape[1]}\n• Train/Val Split: {X_train_lp.shape[0]} / {X_val_lp.shape[0]}\n\"\"\"\n\nax.text(0.05, 0.95, summary_text, transform=ax.transAxes, fontsize=11,\n        verticalalignment='top', fontfamily='monospace',\n        bbox=dict(boxstyle='round', facecolor='#ecf0f1', alpha=0.9, pad=1))\n\nplt.tight_layout()\nplt.show()\n\nprint(\"✓ Final summary report displayed\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T10:10:30.946480Z","iopub.execute_input":"2025-12-03T10:10:30.946999Z","iopub.status.idle":"2025-12-03T10:10:31.019127Z","shell.execute_reply.started":"2025-12-03T10:10:30.946975Z","shell.execute_reply":"2025-12-03T10:10:31.018477Z"}},"outputs":[{"name":"stdout","text":"\n================================================================================\nFINAL SUMMARY - DINO RICE LEAF DISEASE CLASSIFICATION\n================================================================================\n\n📊 PRETRAINING SUMMARY:\n   • Epochs trained: 10\n   • Initial loss: -43.0315\n   • Final loss: -142.7732\n   • Best loss: -143.6975\n   • Improvement: 99.7417\n\n📈 DATASET BREAKDOWN:\n   • Total images: 19000\n   • Number of classes: 38\n   • Feature dimension: 384\n   • Training samples (80%): 15200\n   • Validation samples (20%): 3800\n\n🏆 CLASSIFIER PERFORMANCE RANKINGS:\n\n   1. MLP\n      ├─ Accuracy:  0.3582 (35.82%)\n      ├─ Precision: 0.3598\n      ├─ Recall:    0.3598\n      └─ F1-Score:  0.3598\n\n   2. Linear Probe\n      ├─ Accuracy:  0.2887 (28.87%)\n      ├─ Precision: 0.2862\n      ├─ Recall:    0.2862\n      └─ F1-Score:  0.2862\n\n   3. SVM\n      ├─ Accuracy:  0.1079 (10.79%)\n      ├─ Precision: 0.1044\n      ├─ Recall:    0.1044\n      └─ F1-Score:  0.1044\n\n🎯 BEST CLASSIFIER DETAILS:\n   🏅 MLP\n      • Accuracy:  0.3582\n      • Precision: 0.3598\n      • Recall:    0.3598\n      • F1-Score:  0.3598\n\n📍 TOP 5 BEST PERFORMING CLASSES (MLP):\n\n   1. Binadhan20                     Accuracy: 1.0000\n   2. BD39                           Accuracy: 0.9032\n   3. Binadhan19                     Accuracy: 0.8247\n   4. BR23                           Accuracy: 0.8073\n   5. Binadhan11                     Accuracy: 0.8000\n\n📍 TOP 5 WORST PERFORMING CLASSES (MLP):\n\n   1. BD85                           Accuracy: 0.0000\n   2. BRRI74                         Accuracy: 0.0000\n   3. Binadhan14                     Accuracy: 0.0000\n   4. BD57                           Accuracy: 0.0288\n   5. Binadhan12                     Accuracy: 0.0291\n\n================================================================================\n✅ PIPELINE COMPLETED SUCCESSFULLY\n================================================================================\n\n✓ Final summary report displayed\n\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"# CELL 13: TRAINING LOSS CURVE (INLINE)\n\nprint(\"=\"*80)\nprint(\"GRAPH 1: DINO PRETRAINING LOSS CURVE\")\nprint(\"=\"*80 + \"\\n\")\n\ntrain_losses = np.load(os.path.join(OUTPUT_DIR, 'train_losses.npy'))\n\nfig, ax = plt.subplots(figsize=(14, 7))\n\nepochs = range(1, len(train_losses) + 1)\nax.plot(epochs, train_losses, linewidth=3.5, color='#3498db', marker='o', \n        markersize=10, markerfacecolor='#2980b9', markeredgewidth=2, label='Training Loss')\nax.fill_between(epochs, train_losses, alpha=0.3, color='#3498db')\n\nax.axhline(y=np.min(train_losses), color='r', linestyle='--', linewidth=2.5, \n           label=f'Best Loss: {np.min(train_losses):.4f}', alpha=0.8)\n\nax.set_xlabel('Epoch', fontsize=13, fontweight='bold')\nax.set_ylabel('Loss Value', fontsize=13, fontweight='bold')\nax.set_title('DINO Self-Supervised Pretraining Loss', fontsize=15, fontweight='bold', pad=20)\nax.grid(True, alpha=0.3, linestyle='--', linewidth=0.8)\nax.legend(fontsize=12, loc='best', framealpha=0.95)\n\nplt.tight_layout()\nplt.show()\n\nprint(\"✓ Graph displayed\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T10:15:26.212065Z","iopub.execute_input":"2025-12-03T10:15:26.212657Z","iopub.status.idle":"2025-12-03T10:15:26.322642Z","shell.execute_reply.started":"2025-12-03T10:15:26.212633Z","shell.execute_reply":"2025-12-03T10:15:26.321991Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nGRAPH 1: DINO PRETRAINING LOSS CURVE\n================================================================================\n\n✓ Graph displayed\n\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"# CELL 14: CLASSIFIER ACCURACY COMPARISON (INLINE)\n\nprint(\"=\"*80)\nprint(\"GRAPH 2: DOWNSTREAM CLASSIFIER ACCURACY COMPARISON\")\nprint(\"=\"*80 + \"\\n\")\n\nclf_names = list(comparison_data.keys())\naccuracies = [comparison_data[clf]['Accuracy'] for clf in clf_names]\ncolors = ['#3498db', '#2ecc71', '#e74c3c']\n\nfig, ax = plt.subplots(figsize=(12, 7))\n\nbars = ax.bar(clf_names, accuracies, color=colors, edgecolor='black', linewidth=2.5, \n              alpha=0.85, width=0.6)\n\nax.set_ylabel('Accuracy', fontsize=13, fontweight='bold')\nax.set_title('Downstream Classifier Accuracy Comparison', fontsize=15, fontweight='bold', pad=20)\nax.set_ylim([0, 1])\nax.grid(axis='y', alpha=0.3, linestyle='--')\n\nfor bar in bars:\n    height = bar.get_height()\n    ax.text(bar.get_x() + bar.get_width()/2., height + 0.03,\n           f'{height:.4f}\\n({height*100:.2f}%)', \n           ha='center', va='bottom', fontsize=12, fontweight='bold')\n\nplt.tight_layout()\nplt.show()\n\nprint(\"✓ Graph displayed\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T10:17:07.427646Z","iopub.execute_input":"2025-12-03T10:17:07.428252Z","iopub.status.idle":"2025-12-03T10:17:07.511863Z","shell.execute_reply.started":"2025-12-03T10:17:07.428230Z","shell.execute_reply":"2025-12-03T10:17:07.511238Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nGRAPH 2: DOWNSTREAM CLASSIFIER ACCURACY COMPARISON\n================================================================================\n\n✓ Graph displayed\n\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"# CELL 15: ALL METRICS COMPARISON (4-Subplot - INLINE)\n\nprint(\"=\"*80)\nprint(\"GRAPH 3: COMPREHENSIVE METRICS COMPARISON (4-Subplot)\")\nprint(\"=\"*80 + \"\\n\")\n\nclf_names = list(comparison_data.keys())\naccuracies = [comparison_data[clf]['Accuracy'] for clf in clf_names]\nprecisions = [comparison_data[clf]['Precision'] for clf in clf_names]\nrecalls = [comparison_data[clf]['Recall'] for clf in clf_names]\nf1_scores = [comparison_data[clf]['F1'] for clf in clf_names]\n\nfig, axes = plt.subplots(2, 2, figsize=(15, 12))\ncolors = ['#3498db', '#2ecc71', '#e74c3c']\n\n# 1. Accuracy\nbars1 = axes[0, 0].bar(clf_names, accuracies, color=colors, edgecolor='black', linewidth=2, alpha=0.85)\naxes[0, 0].set_title('Accuracy', fontsize=13, fontweight='bold')\naxes[0, 0].set_ylim([0, 1])\naxes[0, 0].grid(axis='y', alpha=0.3)\nfor bar in bars1:\n    height = bar.get_height()\n    axes[0, 0].text(bar.get_x() + bar.get_width()/2., height + 0.02, f'{height:.4f}', \n                   ha='center', va='bottom', fontsize=11, fontweight='bold')\n\n# 2. Precision\nbars2 = axes[0, 1].bar(clf_names, precisions, color=colors, edgecolor='black', linewidth=2, alpha=0.85)\naxes[0, 1].set_title('Precision', fontsize=13, fontweight='bold')\naxes[0, 1].set_ylim([0, 1])\naxes[0, 1].grid(axis='y', alpha=0.3)\nfor bar in bars2:\n    height = bar.get_height()\n    axes[0, 1].text(bar.get_x() + bar.get_width()/2., height + 0.02, f'{height:.4f}', \n                   ha='center', va='bottom', fontsize=11, fontweight='bold')\n\n# 3. Recall\nbars3 = axes[1, 0].bar(clf_names, recalls, color=colors, edgecolor='black', linewidth=2, alpha=0.85)\naxes[1, 0].set_title('Recall', fontsize=13, fontweight='bold')\naxes[1, 0].set_ylim([0, 1])\naxes[1, 0].grid(axis='y', alpha=0.3)\nfor bar in bars3:\n    height = bar.get_height()\n    axes[1, 0].text(bar.get_x() + bar.get_width()/2., height + 0.02, f'{height:.4f}', \n                   ha='center', va='bottom', fontsize=11, fontweight='bold')\n\n# 4. F1-Score\nbars4 = axes[1, 1].bar(clf_names, f1_scores, color=colors, edgecolor='black', linewidth=2, alpha=0.85)\naxes[1, 1].set_title('F1-Score', fontsize=13, fontweight='bold')\naxes[1, 1].set_ylim([0, 1])\naxes[1, 1].grid(axis='y', alpha=0.3)\nfor bar in bars4:\n    height = bar.get_height()\n    axes[1, 1].text(bar.get_x() + bar.get_width()/2., height + 0.02, f'{height:.4f}', \n                   ha='center', va='bottom', fontsize=11, fontweight='bold')\n\nplt.tight_layout()\nplt.show()\n\nprint(\"✓ Graph displayed\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T10:17:32.516680Z","iopub.execute_input":"2025-12-03T10:17:32.517063Z","iopub.status.idle":"2025-12-03T10:17:32.794292Z","shell.execute_reply.started":"2025-12-03T10:17:32.517038Z","shell.execute_reply":"2025-12-03T10:17:32.793715Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nGRAPH 3: COMPREHENSIVE METRICS COMPARISON (4-Subplot)\n================================================================================\n\n✓ Graph displayed\n\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"# CELL 16: CONFUSION MATRICES (3-Subplot - INLINE) - CORRECTED\n\nprint(\"=\"*80)\nprint(\"GRAPH 4: CONFUSION MATRICES (All 3 Classifiers)\")\nprint(\"=\"*80 + \"\\n\")\n\nfig, axes = plt.subplots(1, 3, figsize=(20, 6))\n\nmatrices = [cm_linear, cm_mlp, cm_svm]\ntitles = ['Linear Probe', 'MLP', 'SVM']\n\n# Get scalar accuracy values correctly\naccs = [\n    np.mean(y_val_pred == y_val_lp),  # Linear probe\n    np.mean(mlp_val_pred == y_val_lp),  # MLP\n    np.mean(svm_val_pred == y_val_lp)   # SVM\n]\n\nfor idx, (cm, title, ax, acc) in enumerate(zip(matrices, titles, axes, accs)):\n    cm_norm = cm.astype('float') / (cm.sum(axis=1)[:, np.newaxis] + 1e-8)\n    \n    im = ax.imshow(cm_norm, cmap='YlOrRd', aspect='auto', vmin=0, vmax=1)\n    ax.set_title(f'{title}\\nAccuracy: {float(acc):.4f}', fontsize=12, fontweight='bold', pad=15)\n    ax.set_xlabel('Predicted Class', fontsize=11, fontweight='bold')\n    ax.set_ylabel('True Class', fontsize=11, fontweight='bold')\n    \n    ax.set_xticks(range(min(num_classes, 10)))\n    ax.set_yticks(range(min(num_classes, 10)))\n    ax.set_xticklabels([f'C{i}' for i in range(min(num_classes, 10))], fontsize=9)\n    ax.set_yticklabels([f'C{i}' for i in range(min(num_classes, 10))], fontsize=9)\n    \n    cbar = plt.colorbar(im, ax=ax, fraction=0.046)\n    cbar.set_label('Normalized', fontsize=10, fontweight='bold')\n\nplt.tight_layout()\nplt.show()\n\nprint(\"✓ Graph displayed\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T10:19:18.254646Z","iopub.execute_input":"2025-12-03T10:19:18.255233Z","iopub.status.idle":"2025-12-03T10:19:18.625396Z","shell.execute_reply.started":"2025-12-03T10:19:18.255207Z","shell.execute_reply":"2025-12-03T10:19:18.624783Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nGRAPH 4: CONFUSION MATRICES (All 3 Classifiers)\n================================================================================\n\n✓ Graph displayed\n\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"# CELL 17: PER-CLASS PERFORMANCE HEATMAP (INLINE)\n\nprint(\"=\"*80)\nprint(\"GRAPH 5: PER-CLASS PERFORMANCE ANALYSIS (MLP - Best Classifier)\")\nprint(\"=\"*80 + \"\\n\")\n\n# Compute per-class metrics\ndef compute_per_class_metrics(y_true, y_pred, num_classes):\n    accuracy, precision, recall, f1 = [], [], [], []\n    \n    for c in range(num_classes):\n        mask_true = y_true == c\n        mask_pred = y_pred == c\n        \n        if np.sum(mask_true) > 0:\n            acc = np.mean(y_pred[mask_true] == y_true[mask_true])\n            accuracy.append(acc)\n            \n            if np.sum(mask_pred) > 0:\n                prec = np.sum((y_pred[mask_true] == c)) / np.sum(mask_pred)\n            else:\n                prec = 0\n            precision.append(prec)\n            \n            rec = np.sum((y_pred[mask_true] == c)) / np.sum(mask_true)\n            recall.append(rec)\n            \n            if prec + rec > 0:\n                f1_score = 2 * prec * rec / (prec + rec)\n            else:\n                f1_score = 0\n            f1.append(f1_score)\n        else:\n            accuracy.append(0)\n            precision.append(0)\n            recall.append(0)\n            f1.append(0)\n    \n    return np.array(accuracy), np.array(precision), np.array(recall), np.array(f1)\n\nmlp_acc_pc, mlp_prec_pc, mlp_rec_pc, mlp_f1_pc = compute_per_class_metrics(y_val_lp, mlp_val_pred, num_classes)\n\n# Create heatmap of all metrics\nfig, ax = plt.subplots(figsize=(14, 10))\n\nmetrics_data = np.column_stack([mlp_acc_pc, mlp_prec_pc, mlp_rec_pc, mlp_f1_pc])\n\nim = ax.imshow(metrics_data, cmap='RdYlGn', aspect='auto', vmin=0, vmax=1)\n\nclass_labels = [class_names[i] if i < len(class_names) else f'Class {i}' for i in range(num_classes)]\nax.set_yticks(range(num_classes))\nax.set_yticklabels(class_labels, fontsize=10)\nax.set_xticks(range(4))\nax.set_xticklabels(['Accuracy', 'Precision', 'Recall', 'F1-Score'], fontsize=11, fontweight='bold')\nax.set_title('Per-Class Performance Metrics (MLP)', fontsize=14, fontweight='bold', pad=15)\n\n# Add text annotations\nfor i in range(num_classes):\n    for j in range(4):\n        text = ax.text(j, i, f'{metrics_data[i, j]:.3f}',\n                      ha=\"center\", va=\"center\", color=\"black\" if metrics_data[i, j] < 0.5 else \"white\",\n                      fontweight='bold', fontsize=9)\n\ncbar = plt.colorbar(im, ax=ax)\ncbar.set_label('Score', fontsize=11, fontweight='bold')\n\nplt.tight_layout()\nplt.show()\n\nprint(\"✓ Graph displayed\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T10:20:00.749860Z","iopub.execute_input":"2025-12-03T10:20:00.750547Z","iopub.status.idle":"2025-12-03T10:20:01.125049Z","shell.execute_reply.started":"2025-12-03T10:20:00.750521Z","shell.execute_reply":"2025-12-03T10:20:01.124446Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nGRAPH 5: PER-CLASS PERFORMANCE ANALYSIS (MLP - Best Classifier)\n================================================================================\n\n✓ Graph displayed\n\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"# CELL 18: LOSS TREND + CLASSIFIER RANKING (INLINE)\n\nprint(\"=\"*80)\nprint(\"GRAPH 6: LOSS TREND + CLASSIFIER RANKING (Combined)\")\nprint(\"=\"*80 + \"\\n\")\n\nfig = plt.figure(figsize=(16, 8))\ngs = fig.add_gridspec(2, 2, hspace=0.3, wspace=0.3)\n\n# 1. Loss trend (large subplot)\nax1 = fig.add_subplot(gs[0, :])\nax1.plot(range(1, len(train_losses) + 1), train_losses, linewidth=3, color='#3498db', \n         marker='o', markersize=8, label='Training Loss')\nax1.fill_between(range(1, len(train_losses) + 1), train_losses, alpha=0.2, color='#3498db')\nax1.axhline(y=np.min(train_losses), color='r', linestyle='--', linewidth=2.5, \n            label=f'Best: {np.min(train_losses):.4f}')\nax1.set_xlabel('Epoch', fontsize=12, fontweight='bold')\nax1.set_ylabel('Loss', fontsize=12, fontweight='bold')\nax1.set_title('DINO Pretraining Loss Trend', fontsize=13, fontweight='bold')\nax1.grid(True, alpha=0.3)\nax1.legend(fontsize=11)\n\n# 2. Accuracy ranking\nax2 = fig.add_subplot(gs[1, 0])\nranking = sorted(comparison_data.items(), key=lambda x: x[1]['Accuracy'], reverse=True)\nrank_names = [name for name, _ in ranking]\nrank_accs = [metrics['Accuracy'] for _, metrics in ranking]\ncolors_rank = ['gold', 'silver', '#CD7F32']  # Gold, Silver, Bronze\nbars_rank = ax2.barh(rank_names, rank_accs, color=colors_rank, edgecolor='black', linewidth=2)\nax2.set_xlabel('Accuracy', fontsize=11, fontweight='bold')\nax2.set_title('Classifier Ranking', fontsize=12, fontweight='bold')\nax2.set_xlim([0, 1])\nfor i, (bar, acc) in enumerate(zip(bars_rank, rank_accs)):\n    ax2.text(acc + 0.02, bar.get_y() + bar.get_height()/2, f'{acc:.4f}', \n            va='center', fontsize=11, fontweight='bold')\n\n# 3. F1-Score comparison\nax3 = fig.add_subplot(gs[1, 1])\nf1_scores = [comparison_data[clf]['F1'] for clf in comparison_data.keys()]\nx_pos = np.arange(len(comparison_data))\nbars_f1 = ax3.bar(x_pos, f1_scores, color=['#3498db', '#2ecc71', '#e74c3c'], \n                  edgecolor='black', linewidth=2, alpha=0.85)\nax3.set_xticks(x_pos)\nax3.set_xticklabels(list(comparison_data.keys()), fontsize=10)\nax3.set_ylabel('F1-Score', fontsize=11, fontweight='bold')\nax3.set_title('F1-Score Comparison', fontsize=12, fontweight='bold')\nax3.set_ylim([0, 1])\nax3.grid(axis='y', alpha=0.3)\nfor bar, f1 in zip(bars_f1, f1_scores):\n    ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02, f'{f1:.4f}',\n            ha='center', va='bottom', fontsize=11, fontweight='bold')\n\nplt.tight_layout()\nplt.show()\n\nprint(\"✓ Graph displayed\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T10:20:17.221852Z","iopub.execute_input":"2025-12-03T10:20:17.222511Z","iopub.status.idle":"2025-12-03T10:20:17.592301Z","shell.execute_reply.started":"2025-12-03T10:20:17.222483Z","shell.execute_reply":"2025-12-03T10:20:17.591539Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nGRAPH 6: LOSS TREND + CLASSIFIER RANKING (Combined)\n================================================================================\n\n✓ Graph displayed\n\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"# CELL 19: EXPORT RESULTS TO CSV - FIXED\n\nprint(\"=\"*80)\nprint(\"EXPORTING RESULTS TO CSV\")\nprint(\"=\"*80 + \"\\n\")\n\n# Get best classifier info\nbest_clf_name = max(comparison_data.items(), key=lambda x: x[1]['Accuracy'])[0]\nbest_clf_accuracy = max(comparison_data.items(), key=lambda x: x[1]['Accuracy'])[1]['Accuracy']\n\n# 1. Overall Classifier Comparison CSV\ncomparison_df = pd.DataFrame({\n    'Classifier': list(comparison_data.keys()),\n    'Accuracy': [comparison_data[clf]['Accuracy'] for clf in comparison_data.keys()],\n    'Precision': [comparison_data[clf]['Precision'] for clf in comparison_data.keys()],\n    'Recall': [comparison_data[clf]['Recall'] for clf in comparison_data.keys()],\n    'F1-Score': [comparison_data[clf]['F1'] for clf in comparison_data.keys()],\n})\n\ncomparison_csv = os.path.join(OUTPUT_DIR, 'classifier_comparison.csv')\ncomparison_df.to_csv(comparison_csv, index=False)\nprint(f\"✓ Saved: classifier_comparison.csv\\n\")\nprint(comparison_df.to_string(index=False))\nprint()\n\n# 2. Per-Class Performance (MLP) CSV\nmlp_acc_pc, mlp_prec_pc, mlp_rec_pc, mlp_f1_pc = compute_per_class_metrics(y_val_lp, mlp_val_pred, num_classes)\n\nper_class_df = pd.DataFrame({\n    'Class_Name': [class_names[i] if i < len(class_names) else f'Class {i}' for i in range(num_classes)],\n    'Class_ID': range(num_classes),\n    'Accuracy': mlp_acc_pc,\n    'Precision': mlp_prec_pc,\n    'Recall': mlp_rec_pc,\n    'F1-Score': mlp_f1_pc,\n})\n\nper_class_csv = os.path.join(OUTPUT_DIR, 'per_class_performance.csv')\nper_class_df.to_csv(per_class_csv, index=False)\nprint(f\"✓ Saved: per_class_performance.csv\\n\")\nprint(per_class_df.to_string(index=False))\nprint()\n\n# 3. Training Summary CSV\ntraining_summary_df = pd.DataFrame({\n    'Metric': [\n        'Total Images',\n        'Number of Classes',\n        'Feature Dimension',\n        'Epochs Trained',\n        'Initial Loss',\n        'Final Loss',\n        'Best Loss',\n        'Training Samples (80%)',\n        'Validation Samples (20%)',\n        'Best Classifier',\n        'Best Accuracy',\n    ],\n    'Value': [\n        len(train_dataset),\n        num_classes,\n        train_features.shape[1],\n        len(train_losses),\n        f'{train_losses[0]:.4f}',\n        f'{train_losses[-1]:.4f}',\n        f'{np.min(train_losses):.4f}',\n        X_train_lp.shape[0],\n        X_val_lp.shape[0],\n        best_clf_name,\n        f'{best_clf_accuracy:.4f}',\n    ]\n})\n\ntraining_csv = os.path.join(OUTPUT_DIR, 'training_summary.csv')\ntraining_summary_df.to_csv(training_csv, index=False)\nprint(f\"✓ Saved: training_summary.csv\\n\")\nprint(training_summary_df.to_string(index=False))\nprint()\n\n# 4. Training Loss by Epoch CSV\nloss_df = pd.DataFrame({\n    'Epoch': range(1, len(train_losses) + 1),\n    'Loss': train_losses,\n})\n\nloss_csv = os.path.join(OUTPUT_DIR, 'training_loss_by_epoch.csv')\nloss_df.to_csv(loss_csv, index=False)\nprint(f\"✓ Saved: training_loss_by_epoch.csv\\n\")\nprint(f\"Loss data: {len(train_losses)} epochs\")\nprint()\n\nprint(\"=\"*80)\nprint(\"✅ ALL CSV FILES EXPORTED SUCCESSFULLY\")\nprint(\"=\"*80 + \"\\n\")\n\nprint(\"📊 SUMMARY:\")\nprint(f\"   • classifier_comparison.csv (3 classifiers, 5 metrics)\")\nprint(f\"   • per_class_performance.csv ({num_classes} classes, 5 metrics)\")\nprint(f\"   • training_summary.csv (11 key metrics)\")\nprint(f\"   • training_loss_by_epoch.csv ({len(train_losses)} epochs)\\n\")\n\nprint(\"Location: /kaggle/working/\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T10:21:37.080651Z","iopub.execute_input":"2025-12-03T10:21:37.081203Z","iopub.status.idle":"2025-12-03T10:21:37.111707Z","shell.execute_reply.started":"2025-12-03T10:21:37.081179Z","shell.execute_reply":"2025-12-03T10:21:37.110910Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nEXPORTING RESULTS TO CSV\n================================================================================\n\n✓ Saved: classifier_comparison.csv\n\n  Classifier  Accuracy  Precision   Recall  F1-Score\nLinear Probe  0.288684   0.286236 0.286236  0.286236\n         MLP  0.358158   0.359819 0.359819  0.359819\n         SVM  0.107895   0.104425 0.104425  0.104425\n\n✓ Saved: per_class_performance.csv\n\nClass_Name  Class_ID  Accuracy  Precision   Recall  F1-Score\n      BD30         0  0.060345   0.155556 0.060345  0.086957\n      BD33         1  0.071429   0.095890 0.071429  0.081871\n      BD39         2  0.903226   0.750000 0.903226  0.819512\n      BD49         3  0.317757   0.201183 0.317757  0.246377\n      BD51         4  0.543689   0.254545 0.543689  0.346749\n      BD52         5  0.240385   0.211864 0.240385  0.225225\n      BD56         6  0.120690   0.269231 0.120690  0.166667\n      BD57         7  0.028846   0.230769 0.028846  0.051282\n      BD70         8  0.071429   0.280000 0.071429  0.113821\n      BD72         9  0.380952   0.533333 0.380952  0.444444\n      BD75        10  0.111111   0.128205 0.111111  0.119048\n      BD76        11  0.750000   0.681818 0.750000  0.714286\n      BD79        12  0.553191   0.178694 0.553191  0.270130\n      BD85        13  0.000000   0.000000 0.000000  0.000000\n      BD87        14  0.434783   0.353982 0.434783  0.390244\n      BD91        15  0.409091   0.184615 0.409091  0.254417\n      BD93        16  0.453608   0.202765 0.453608  0.280255\n      BD95        17  0.648352   0.385621 0.648352  0.483607\n      BR22        18  0.052632   0.138889 0.052632  0.076336\n      BR23        19  0.807339   0.611111 0.807339  0.695652\n   BRRI102        20  0.062500   0.285714 0.062500  0.102564\n    BRRI67        21  0.057692   0.300000 0.057692  0.096774\n    BRRI74        22  0.000000   0.000000 0.000000  0.000000\nBinadhan10        23  0.288889   0.634146 0.288889  0.396947\nBinadhan11        24  0.800000   0.555556 0.800000  0.655738\nBinadhan12        25  0.029126   0.300000 0.029126  0.053097\nBinadhan14        26  0.000000   0.000000 0.000000  0.000000\nBinadhan16        27  0.494624   0.312925 0.494624  0.383333\nBinadhan17        28  0.483146   0.344000 0.483146  0.401869\nBinadhan19        29  0.824742   0.963855 0.824742  0.888889\nBinadhan20        30  1.000000   1.000000 1.000000  1.000000\nBinadhan21        31  0.318182   0.291667 0.318182  0.304348\nBinadhan23        32  0.477778   0.294521 0.477778  0.364407\nBinadhan24        33  0.211538   0.366667 0.211538  0.268293\nBinadhan25        34  0.531250   0.531250 0.531250  0.531250\nBinadhan26        35  0.231481   0.337838 0.231481  0.274725\n Binadhan7        36  0.440367   0.305732 0.440367  0.360902\n Binadhan8        37  0.462963   0.247525 0.462963  0.322581\n\n✓ Saved: training_summary.csv\n\n                  Metric     Value\n            Total Images     19000\n       Number of Classes        38\n       Feature Dimension       384\n          Epochs Trained        10\n            Initial Loss  -43.0315\n              Final Loss -142.7732\n               Best Loss -143.6975\n  Training Samples (80%)     15200\nValidation Samples (20%)      3800\n         Best Classifier       MLP\n           Best Accuracy    0.3582\n\n✓ Saved: training_loss_by_epoch.csv\n\nLoss data: 10 epochs\n\n================================================================================\n✅ ALL CSV FILES EXPORTED SUCCESSFULLY\n================================================================================\n\n📊 SUMMARY:\n   • classifier_comparison.csv (3 classifiers, 5 metrics)\n   • per_class_performance.csv (38 classes, 5 metrics)\n   • training_summary.csv (11 key metrics)\n   • training_loss_by_epoch.csv (10 epochs)\n\nLocation: /kaggle/working/\n\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"# CELL 20: FINAL SUMMARY REPORT (INLINE TEXT)\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"FINAL COMPREHENSIVE REPORT - DINO RICE LEAF DISEASE CLASSIFICATION\")\nprint(\"=\"*80 + \"\\n\")\n\nranking = sorted(comparison_data.items(), key=lambda x: x[1]['Accuracy'], reverse=True)\n\nprint(\"📊 PRETRAINING SUMMARY:\")\nprint(f\"   • Model: Vision Transformer (DINO Self-Supervised)\")\nprint(f\"   • Epochs: {len(train_losses)}\")\nprint(f\"   • Initial Loss: {train_losses[0]:.4f}\")\nprint(f\"   • Best Loss: {np.min(train_losses):.4f} (Epoch {np.argmin(train_losses) + 1})\")\nprint(f\"   • Final Loss: {train_losses[-1]:.4f}\")\nprint(f\"   • Convergence: ✅ Successful\\n\")\n\nprint(\"🎯 DATASET STATISTICS:\")\nprint(f\"   • Total Images: {len(train_dataset)}\")\nprint(f\"   • Classes: {num_classes}\")\nprint(f\"   • Feature Dimension: {train_features.shape[1]}\")\nprint(f\"   • Training Split: {X_train_lp.shape[0]} samples (80%)\")\nprint(f\"   • Validation Split: {X_val_lp.shape[0]} samples (20%)\\n\")\n\nprint(\"🏆 CLASSIFIER PERFORMANCE RANKING:\\n\")\nfor idx, (name, metrics) in enumerate(ranking, 1):\n    medal = '🥇' if idx == 1 else '🥈' if idx == 2 else '🥉'\n    print(f\"   {medal} #{idx}. {name.upper()}\")\n    print(f\"      ├─ Accuracy:  {metrics['Accuracy']:.4f} ({metrics['Accuracy']*100:.2f}%)\")\n    print(f\"      ├─ Precision: {metrics['Precision']:.4f}\")\n    print(f\"      ├─ Recall:    {metrics['Recall']:.4f}\")\n    print(f\"      └─ F1-Score:  {metrics['F1']:.4f}\\n\")\n\nprint(\"⭐ BEST CLASSIFIER:\")\nbest_name, best_metrics = ranking[0]\nprint(f\"   🏅 {best_name}\")\nprint(f\"      • Accuracy: {best_metrics['Accuracy']:.4f} ({best_metrics['Accuracy']*100:.2f}%)\")\nprint(f\"      • Precision: {best_metrics['Precision']:.4f}\")\nprint(f\"      • Recall: {best_metrics['Recall']:.4f}\")\nprint(f\"      • F1-Score: {best_metrics['F1']:.4f}\\n\")\n\nprint(\"📈 TOP 10 BEST PERFORMING CLASSES:\")\nmlp_acc_pc, mlp_prec_pc, mlp_rec_pc, mlp_f1_pc = compute_per_class_metrics(y_val_lp, mlp_val_pred, num_classes)\ntop_10_idx = np.argsort(mlp_acc_pc)[-10:][::-1]\nfor rank, idx in enumerate(top_10_idx, 1):\n    class_name = class_names[idx] if idx < len(class_names) else f'Class {idx}'\n    print(f\"   {rank:2d}. {class_name:<30} Accuracy: {mlp_acc_pc[idx]:.4f}\")\n\nprint(\"\\n📉 BOTTOM 5 WORST PERFORMING CLASSES:\")\nbottom_5_idx = np.argsort(mlp_acc_pc)[:5]\nfor rank, idx in enumerate(bottom_5_idx, 1):\n    class_name = class_names[idx] if idx < len(class_names) else f'Class {idx}'\n    print(f\"   {rank}. {class_name:<30} Accuracy: {mlp_acc_pc[idx]:.4f}\")\n\nprint(f\"\\n📁 OUTPUT FILES GENERATED:\")\nprint(f\"   ✓ Checkpoints: {checkpoint_dir}/best_checkpoint.pt\")\nprint(f\"   ✓ Features: {OUTPUT_DIR}/train_features.npy\")\nprint(f\"   ✓ Labels: {OUTPUT_DIR}/train_labels.npy\")\nprint(f\"   ✓ Loss: {OUTPUT_DIR}/train_losses.npy\")\nprint(f\"   ✓ CSVs: {OUTPUT_DIR}/*.csv\\n\")\n\nprint(\"=\"*80)\nprint(\"✅ PIPELINE COMPLETED SUCCESSFULLY\")\nprint(\"=\"*80 + \"\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T10:21:53.521168Z","iopub.execute_input":"2025-12-03T10:21:53.521714Z","iopub.status.idle":"2025-12-03T10:21:53.537251Z","shell.execute_reply.started":"2025-12-03T10:21:53.521688Z","shell.execute_reply":"2025-12-03T10:21:53.536623Z"}},"outputs":[{"name":"stdout","text":"\n================================================================================\nFINAL COMPREHENSIVE REPORT - DINO RICE LEAF DISEASE CLASSIFICATION\n================================================================================\n\n📊 PRETRAINING SUMMARY:\n   • Model: Vision Transformer (DINO Self-Supervised)\n   • Epochs: 10\n   • Initial Loss: -43.0315\n   • Best Loss: -143.6975 (Epoch 3)\n   • Final Loss: -142.7732\n   • Convergence: ✅ Successful\n\n🎯 DATASET STATISTICS:\n   • Total Images: 19000\n   • Classes: 38\n   • Feature Dimension: 384\n   • Training Split: 15200 samples (80%)\n   • Validation Split: 3800 samples (20%)\n\n🏆 CLASSIFIER PERFORMANCE RANKING:\n\n   🥇 #1. MLP\n      ├─ Accuracy:  0.3582 (35.82%)\n      ├─ Precision: 0.3598\n      ├─ Recall:    0.3598\n      └─ F1-Score:  0.3598\n\n   🥈 #2. LINEAR PROBE\n      ├─ Accuracy:  0.2887 (28.87%)\n      ├─ Precision: 0.2862\n      ├─ Recall:    0.2862\n      └─ F1-Score:  0.2862\n\n   🥉 #3. SVM\n      ├─ Accuracy:  0.1079 (10.79%)\n      ├─ Precision: 0.1044\n      ├─ Recall:    0.1044\n      └─ F1-Score:  0.1044\n\n⭐ BEST CLASSIFIER:\n   🏅 MLP\n      • Accuracy: 0.3582 (35.82%)\n      • Precision: 0.3598\n      • Recall: 0.3598\n      • F1-Score: 0.3598\n\n📈 TOP 10 BEST PERFORMING CLASSES:\n    1. Binadhan20                     Accuracy: 1.0000\n    2. BD39                           Accuracy: 0.9032\n    3. Binadhan19                     Accuracy: 0.8247\n    4. BR23                           Accuracy: 0.8073\n    5. Binadhan11                     Accuracy: 0.8000\n    6. BD76                           Accuracy: 0.7500\n    7. BD95                           Accuracy: 0.6484\n    8. BD79                           Accuracy: 0.5532\n    9. BD51                           Accuracy: 0.5437\n   10. Binadhan25                     Accuracy: 0.5312\n\n📉 BOTTOM 5 WORST PERFORMING CLASSES:\n   1. BD85                           Accuracy: 0.0000\n   2. BRRI74                         Accuracy: 0.0000\n   3. Binadhan14                     Accuracy: 0.0000\n   4. BD57                           Accuracy: 0.0288\n   5. Binadhan12                     Accuracy: 0.0291\n\n📁 OUTPUT FILES GENERATED:\n   ✓ Checkpoints: /kaggle/working/checkpoints/best_checkpoint.pt\n   ✓ Features: /kaggle/working/train_features.npy\n   ✓ Labels: /kaggle/working/train_labels.npy\n   ✓ Loss: /kaggle/working/train_losses.npy\n   ✓ CSVs: /kaggle/working/*.csv\n\n================================================================================\n✅ PIPELINE COMPLETED SUCCESSFULLY\n================================================================================\n\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"# CELL 13-24: COMPLETE VISUALIZATION & EXPORT PIPELINE\n\nprint(\"\\n\" + \"=\"*100)\nprint(\"COMPLETE VISUALIZATION & EXPORT PIPELINE\")\nprint(\"=\"*100 + \"\\n\")\n\n# ======================= HELPER FUNCTION =======================\ndef compute_per_class_metrics(y_true, y_pred, num_classes):\n    accuracy, precision, recall, f1 = [], [], [], []\n    \n    for c in range(num_classes):\n        mask_true = y_true == c\n        mask_pred = y_pred == c\n        \n        if np.sum(mask_true) > 0:\n            acc = np.mean(y_pred[mask_true] == y_true[mask_true])\n            accuracy.append(acc)\n            \n            if np.sum(mask_pred) > 0:\n                prec = np.sum((y_pred[mask_true] == c)) / np.sum(mask_pred)\n            else:\n                prec = 0\n            precision.append(prec)\n            \n            rec = np.sum((y_pred[mask_true] == c)) / np.sum(mask_true)\n            recall.append(rec)\n            \n            if prec + rec > 0:\n                f1_score = 2 * prec * rec / (prec + rec)\n            else:\n                f1_score = 0\n            f1.append(f1_score)\n        else:\n            accuracy.append(0)\n            precision.append(0)\n            recall.append(0)\n            f1.append(0)\n    \n    return np.array(accuracy), np.array(precision), np.array(recall), np.array(f1)\n\n# ======================= LOAD DATA =======================\ntrain_losses = np.load(os.path.join(OUTPUT_DIR, 'train_losses.npy'))\nmlp_acc_pc, mlp_prec_pc, mlp_rec_pc, mlp_f1_pc = compute_per_class_metrics(y_val_lp, mlp_val_pred, num_classes)\n\nprint(\"\\n\" + \"-\"*100)\nprint(\"GRAPH 1: TRAINING LOSS CURVE - DISPLAY + SAVE PNG\")\nprint(\"-\"*100 + \"\\n\")\n\nfig, ax = plt.subplots(figsize=(14, 8))\nepochs = range(1, len(train_losses) + 1)\nax.plot(epochs, train_losses, linewidth=4, color='#3498db', marker='o', \n        markersize=10, markerfacecolor='#2980b9', markeredgewidth=2.5, label='Training Loss')\nax.fill_between(epochs, train_losses, alpha=0.25, color='#3498db')\nax.axhline(y=np.min(train_losses), color='r', linestyle='--', linewidth=3, \n           label=f'Best Loss: {np.min(train_losses):.4f}', alpha=0.8)\nax.set_xlabel('Epoch', fontsize=14, fontweight='bold')\nax.set_ylabel('Loss Value', fontsize=14, fontweight='bold')\nax.set_title('DINO Self-Supervised Pretraining Loss Curve', fontsize=16, fontweight='bold', pad=20)\nax.grid(True, alpha=0.4, linestyle='--', linewidth=1)\nax.legend(fontsize=13, loc='best', framealpha=0.98)\nplt.tight_layout()\nplt.show()\npng_path = os.path.join(OUTPUT_DIR, '01_training_loss_curve.png')\nfig.savefig(png_path, dpi=300, bbox_inches='tight')\nprint(f\"✓ Saved PNG: {png_path}\")\nplt.close()\n\nprint(\"\\n\" + \"-\"*100)\nprint(\"GRAPH 2: CLASSIFIER ACCURACY COMPARISON - DISPLAY + SAVE PNG\")\nprint(\"-\"*100 + \"\\n\")\n\nclf_names = list(comparison_data.keys())\naccuracies = [comparison_data[clf]['Accuracy'] for clf in clf_names]\ncolors = ['#3498db', '#2ecc71', '#e74c3c']\n\nfig, ax = plt.subplots(figsize=(12, 7))\nbars = ax.bar(clf_names, accuracies, color=colors, edgecolor='black', linewidth=2.5, \n              alpha=0.85, width=0.6)\nax.set_ylabel('Accuracy', fontsize=13, fontweight='bold')\nax.set_title('Downstream Classifier Accuracy Comparison', fontsize=15, fontweight='bold', pad=20)\nax.set_ylim([0, 1])\nax.grid(axis='y', alpha=0.3, linestyle='--')\nfor bar in bars:\n    height = bar.get_height()\n    ax.text(bar.get_x() + bar.get_width()/2., height + 0.03,\n           f'{height:.4f}\\n({height*100:.2f}%)', \n           ha='center', va='bottom', fontsize=12, fontweight='bold')\nplt.tight_layout()\nplt.show()\npng_path = os.path.join(OUTPUT_DIR, '02_classifier_accuracy.png')\nfig.savefig(png_path, dpi=300, bbox_inches='tight')\nprint(f\"✓ Saved PNG: {png_path}\")\nplt.close()\n\nprint(\"\\n\" + \"-\"*100)\nprint(\"GRAPH 3: ALL METRICS COMPARISON (4-Subplot) - DISPLAY + SAVE PNG\")\nprint(\"-\"*100 + \"\\n\")\n\nprecisions = [comparison_data[clf]['Precision'] for clf in clf_names]\nrecalls = [comparison_data[clf]['Recall'] for clf in clf_names]\nf1_scores = [comparison_data[clf]['F1'] for clf in clf_names]\n\nfig, axes = plt.subplots(2, 2, figsize=(15, 12))\n\n# Accuracy\nbars1 = axes[0, 0].bar(clf_names, accuracies, color=colors, edgecolor='black', linewidth=2, alpha=0.85)\naxes[0, 0].set_title('Accuracy', fontsize=13, fontweight='bold')\naxes[0, 0].set_ylim([0, 1])\naxes[0, 0].grid(axis='y', alpha=0.3)\nfor bar in bars1:\n    height = bar.get_height()\n    axes[0, 0].text(bar.get_x() + bar.get_width()/2., height + 0.02, f'{height:.4f}', \n                   ha='center', va='bottom', fontsize=11, fontweight='bold')\n\n# Precision\nbars2 = axes[0, 1].bar(clf_names, precisions, color=colors, edgecolor='black', linewidth=2, alpha=0.85)\naxes[0, 1].set_title('Precision', fontsize=13, fontweight='bold')\naxes[0, 1].set_ylim([0, 1])\naxes[0, 1].grid(axis='y', alpha=0.3)\nfor bar in bars2:\n    height = bar.get_height()\n    axes[0, 1].text(bar.get_x() + bar.get_width()/2., height + 0.02, f'{height:.4f}', \n                   ha='center', va='bottom', fontsize=11, fontweight='bold')\n\n# Recall\nbars3 = axes[1, 0].bar(clf_names, recalls, color=colors, edgecolor='black', linewidth=2, alpha=0.85)\naxes[1, 0].set_title('Recall', fontsize=13, fontweight='bold')\naxes[1, 0].set_ylim([0, 1])\naxes[1, 0].grid(axis='y', alpha=0.3)\nfor bar in bars3:\n    height = bar.get_height()\n    axes[1, 0].text(bar.get_x() + bar.get_width()/2., height + 0.02, f'{height:.4f}', \n                   ha='center', va='bottom', fontsize=11, fontweight='bold')\n\n# F1-Score\nbars4 = axes[1, 1].bar(clf_names, f1_scores, color=colors, edgecolor='black', linewidth=2, alpha=0.85)\naxes[1, 1].set_title('F1-Score', fontsize=13, fontweight='bold')\naxes[1, 1].set_ylim([0, 1])\naxes[1, 1].grid(axis='y', alpha=0.3)\nfor bar in bars4:\n    height = bar.get_height()\n    axes[1, 1].text(bar.get_x() + bar.get_width()/2., height + 0.02, f'{height:.4f}', \n                   ha='center', va='bottom', fontsize=11, fontweight='bold')\n\nplt.tight_layout()\nplt.show()\npng_path = os.path.join(OUTPUT_DIR, '03_all_metrics_comparison.png')\nfig.savefig(png_path, dpi=300, bbox_inches='tight')\nprint(f\"✓ Saved PNG: {png_path}\")\nplt.close()\n\nprint(\"\\n\" + \"-\"*100)\nprint(\"GRAPH 4: CONFUSION MATRICES (3 Classifiers) - DISPLAY + SAVE PNG\")\nprint(\"-\"*100 + \"\\n\")\n\nfig, axes = plt.subplots(1, 3, figsize=(22, 7))\nmatrices = [cm_linear, cm_mlp, cm_svm]\ntitles = ['Linear Probe', 'MLP', 'SVM']\naccs = [\n    np.mean(y_val_pred == y_val_lp),\n    np.mean(mlp_val_pred == y_val_lp),\n    np.mean(svm_val_pred == y_val_lp)\n]\n\nfor idx, (cm, title, ax, acc) in enumerate(zip(matrices, titles, axes, accs)):\n    cm_norm = cm.astype('float') / (cm.sum(axis=1)[:, np.newaxis] + 1e-8)\n    \n    im = ax.imshow(cm_norm, cmap='YlOrRd', aspect='auto', vmin=0, vmax=1)\n    ax.set_title(f'{title}\\nAccuracy: {float(acc):.4f}', fontsize=13, fontweight='bold', pad=15)\n    ax.set_xlabel('Predicted Class', fontsize=12, fontweight='bold')\n    ax.set_ylabel('True Class', fontsize=12, fontweight='bold')\n    \n    ax.set_xticks(range(min(num_classes, 10)))\n    ax.set_yticks(range(min(num_classes, 10)))\n    ax.set_xticklabels([f'C{i}' for i in range(min(num_classes, 10))], fontsize=10)\n    ax.set_yticklabels([f'C{i}' for i in range(min(num_classes, 10))], fontsize=10)\n    \n    cbar = plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n    cbar.set_label('Normalized Count', fontsize=11, fontweight='bold')\n\nplt.tight_layout()\nplt.show()\npng_path = os.path.join(OUTPUT_DIR, '04_confusion_matrices.png')\nfig.savefig(png_path, dpi=300, bbox_inches='tight')\nprint(f\"✓ Saved PNG: {png_path}\")\nplt.close()\n\nprint(\"\\n\" + \"-\"*100)\nprint(\"GRAPH 5: PER-CLASS PERFORMANCE HEATMAP - DISPLAY + SAVE PNG\")\nprint(\"-\"*100 + \"\\n\")\n\nfig, ax = plt.subplots(figsize=(14, 10))\nmetrics_data = np.column_stack([mlp_acc_pc, mlp_prec_pc, mlp_rec_pc, mlp_f1_pc])\n\nim = ax.imshow(metrics_data, cmap='RdYlGn', aspect='auto', vmin=0, vmax=1)\n\nclass_labels = [class_names[i] if i < len(class_names) else f'Class {i}' for i in range(num_classes)]\nax.set_yticks(range(num_classes))\nax.set_yticklabels(class_labels, fontsize=10)\nax.set_xticks(range(4))\nax.set_xticklabels(['Accuracy', 'Precision', 'Recall', 'F1-Score'], fontsize=11, fontweight='bold')\nax.set_title('Per-Class Performance Metrics (MLP - Best Classifier)', fontsize=14, fontweight='bold', pad=15)\n\nfor i in range(num_classes):\n    for j in range(4):\n        text = ax.text(j, i, f'{metrics_data[i, j]:.3f}',\n                      ha=\"center\", va=\"center\", \n                      color=\"white\" if metrics_data[i, j] < 0.5 else \"black\",\n                      fontweight='bold', fontsize=9)\n\ncbar = plt.colorbar(im, ax=ax)\ncbar.set_label('Score', fontsize=11, fontweight='bold')\n\nplt.tight_layout()\nplt.show()\npng_path = os.path.join(OUTPUT_DIR, '05_per_class_heatmap.png')\nfig.savefig(png_path, dpi=300, bbox_inches='tight')\nprint(f\"✓ Saved PNG: {png_path}\")\nplt.close()\n\nprint(\"\\n\" + \"-\"*100)\nprint(\"GRAPH 6: COMBINED ANALYSIS (Loss + Ranking + Summary) - DISPLAY + SAVE PNG\")\nprint(\"-\"*100 + \"\\n\")\n\nfig = plt.figure(figsize=(18, 10))\ngs = fig.add_gridspec(2, 2, hspace=0.35, wspace=0.3)\n\n# Loss trend (large)\nax1 = fig.add_subplot(gs[0, :])\nax1.plot(range(1, len(train_losses) + 1), train_losses, linewidth=3, color='#3498db', \n         marker='o', markersize=8, label='Training Loss')\nax1.fill_between(range(1, len(train_losses) + 1), train_losses, alpha=0.2, color='#3498db')\nax1.axhline(y=np.min(train_losses), color='r', linestyle='--', linewidth=2.5, \n            label=f'Best: {np.min(train_losses):.4f}')\nax1.set_xlabel('Epoch', fontsize=12, fontweight='bold')\nax1.set_ylabel('Loss', fontsize=12, fontweight='bold')\nax1.set_title('DINO Pretraining Loss Trend', fontsize=13, fontweight='bold')\nax1.grid(True, alpha=0.3)\nax1.legend(fontsize=11)\n\n# Classifier ranking\nax2 = fig.add_subplot(gs[1, 0])\nranking = sorted(comparison_data.items(), key=lambda x: x[1]['Accuracy'], reverse=True)\nrank_names = [name for name, _ in ranking]\nrank_accs = [metrics['Accuracy'] for _, metrics in ranking]\ncolors_rank = ['#FFD700', '#C0C0C0', '#CD7F32']\nbars_rank = ax2.barh(rank_names, rank_accs, color=colors_rank, edgecolor='black', linewidth=2)\nax2.set_xlabel('Accuracy', fontsize=11, fontweight='bold')\nax2.set_title('🏆 Classifier Ranking', fontsize=12, fontweight='bold')\nax2.set_xlim([0, 1])\nfor i, (bar, acc) in enumerate(zip(bars_rank, rank_accs)):\n    ax2.text(acc + 0.02, bar.get_y() + bar.get_height()/2, f'{acc:.4f}', \n            va='center', fontsize=11, fontweight='bold')\n\n# F1-Score\nax3 = fig.add_subplot(gs[1, 1])\nx_pos = np.arange(len(clf_names))\nbars_f1 = ax3.bar(x_pos, f1_scores, color=['#3498db', '#2ecc71', '#e74c3c'], \n                  edgecolor='black', linewidth=2, alpha=0.85)\nax3.set_xticks(x_pos)\nax3.set_xticklabels(clf_names, fontsize=10)\nax3.set_ylabel('F1-Score', fontsize=11, fontweight='bold')\nax3.set_title('F1-Score Comparison', fontsize=12, fontweight='bold')\nax3.set_ylim([0, 1])\nax3.grid(axis='y', alpha=0.3)\nfor bar, f1 in zip(bars_f1, f1_scores):\n    ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02, f'{f1:.4f}',\n            ha='center', va='bottom', fontsize=11, fontweight='bold')\n\nplt.tight_layout()\nplt.show()\npng_path = os.path.join(OUTPUT_DIR, '06_combined_analysis.png')\nfig.savefig(png_path, dpi=300, bbox_inches='tight')\nprint(f\"✓ Saved PNG: {png_path}\")\nplt.close()\n\nprint(\"\\n\" + \"=\"*100)\nprint(\"EXPORTING CSV FILES\")\nprint(\"=\"*100 + \"\\n\")\n\n# Get best classifier\nbest_clf_name = max(comparison_data.items(), key=lambda x: x[1]['Accuracy'])[0]\nbest_clf_accuracy = max(comparison_data.items(), key=lambda x: x[1]['Accuracy'])[1]['Accuracy']\n\n# 1. Classifier Comparison CSV\ncomparison_df = pd.DataFrame({\n    'Classifier': list(comparison_data.keys()),\n    'Accuracy': [comparison_data[clf]['Accuracy'] for clf in comparison_data.keys()],\n    'Precision': [comparison_data[clf]['Precision'] for clf in comparison_data.keys()],\n    'Recall': [comparison_data[clf]['Recall'] for clf in comparison_data.keys()],\n    'F1-Score': [comparison_data[clf]['F1'] for clf in comparison_data.keys()],\n})\n\ncomparison_csv = os.path.join(OUTPUT_DIR, 'classifier_comparison.csv')\ncomparison_df.to_csv(comparison_csv, index=False)\nprint(f\"✓ Saved CSV: classifier_comparison.csv\\n\")\nprint(comparison_df.to_string(index=False))\nprint()\n\n# 2. Per-Class Performance CSV\nper_class_df = pd.DataFrame({\n    'Class_Name': [class_names[i] if i < len(class_names) else f'Class {i}' for i in range(num_classes)],\n    'Class_ID': range(num_classes),\n    'Accuracy': mlp_acc_pc,\n    'Precision': mlp_prec_pc,\n    'Recall': mlp_rec_pc,\n    'F1-Score': mlp_f1_pc,\n})\n\nper_class_csv = os.path.join(OUTPUT_DIR, 'per_class_performance.csv')\nper_class_df.to_csv(per_class_csv, index=False)\nprint(f\"✓ Saved CSV: per_class_performance.csv\\n\")\nprint(f\"Rows: {len(per_class_df)}\\n\")\n\n# 3. Training Summary CSV\ntraining_summary_df = pd.DataFrame({\n    'Metric': [\n        'Total Images',\n        'Number of Classes',\n        'Feature Dimension',\n        'Epochs Trained',\n        'Initial Loss',\n        'Final Loss',\n        'Best Loss',\n        'Training Samples (80%)',\n        'Validation Samples (20%)',\n        'Best Classifier',\n        'Best Accuracy',\n    ],\n    'Value': [\n        len(train_dataset),\n        num_classes,\n        train_features.shape[1],\n        len(train_losses),\n        f'{train_losses[0]:.4f}',\n        f'{train_losses[-1]:.4f}',\n        f'{np.min(train_losses):.4f}',\n        X_train_lp.shape[0],\n        X_val_lp.shape[0],\n        best_clf_name,\n        f'{best_clf_accuracy:.4f}',\n    ]\n})\n\ntraining_csv = os.path.join(OUTPUT_DIR, 'training_summary.csv')\ntraining_summary_df.to_csv(training_csv, index=False)\nprint(f\"✓ Saved CSV: training_summary.csv\\n\")\nprint(training_summary_df.to_string(index=False))\nprint()\n\n# 4. Training Loss by Epoch CSV\nloss_df = pd.DataFrame({\n    'Epoch': range(1, len(train_losses) + 1),\n    'Loss': train_losses,\n})\n\nloss_csv = os.path.join(OUTPUT_DIR, 'training_loss_by_epoch.csv')\nloss_df.to_csv(loss_csv, index=False)\nprint(f\"✓ Saved CSV: training_loss_by_epoch.csv\")\nprint(f\"Epochs: {len(train_losses)}\\n\")\n\nprint(\"=\"*100)\nprint(\"FINAL SUMMARY REPORT\")\nprint(\"=\"*100 + \"\\n\")\n\nprint(\"📊 PRETRAINING SUMMARY:\")\nprint(f\"   • Model: Vision Transformer (DINO Self-Supervised)\")\nprint(f\"   • Epochs: {len(train_losses)}\")\nprint(f\"   • Initial Loss: {train_losses[0]:.4f}\")\nprint(f\"   • Best Loss: {np.min(train_losses):.4f} (Epoch {np.argmin(train_losses) + 1})\")\nprint(f\"   • Final Loss: {train_losses[-1]:.4f}\\n\")\n\nprint(\"🎯 DATASET STATISTICS:\")\nprint(f\"   • Total Images: {len(train_dataset)}\")\nprint(f\"   • Classes: {num_classes}\")\nprint(f\"   • Feature Dimension: {train_features.shape[1]}\")\nprint(f\"   • Training Split: {X_train_lp.shape[0]} samples (80%)\")\nprint(f\"   • Validation Split: {X_val_lp.shape[0]} samples (20%)\\n\")\n\nprint(\"🏆 CLASSIFIER PERFORMANCE RANKING:\\n\")\nfor idx, (name, metrics) in enumerate(ranking, 1):\n    medal = '🥇' if idx == 1 else '🥈' if idx == 2 else '🥉'\n    print(f\"   {medal} #{idx}. {name.upper()}\")\n    print(f\"      ├─ Accuracy:  {metrics['Accuracy']:.4f}\")\n    print(f\"      ├─ Precision: {metrics['Precision']:.4f}\")\n    print(f\"      ├─ Recall:    {metrics['Recall']:.4f}\")\n    print(f\"      └─ F1-Score:  {metrics['F1']:.4f}\\n\")\n\nprint(\"📁 OUTPUT FILES GENERATED:\")\nprint(f\"   ✓ PNG Files (6):\")\nprint(f\"      - 01_training_loss_curve.png\")\nprint(f\"      - 02_classifier_accuracy.png\")\nprint(f\"      - 03_all_metrics_comparison.png\")\nprint(f\"      - 04_confusion_matrices.png\")\nprint(f\"      - 05_per_class_heatmap.png\")\nprint(f\"      - 06_combined_analysis.png\")\nprint(f\"   ✓ CSV Files (4):\")\nprint(f\"      - classifier_comparison.csv\")\nprint(f\"      - per_class_performance.csv\")\nprint(f\"      - training_summary.csv\")\nprint(f\"      - training_loss_by_epoch.csv\\n\")\n\nprint(\"=\"*100)\nprint(\"✅ COMPLETE PIPELINE EXECUTED SUCCESSFULLY\")\nprint(\"=\"*100 + \"\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T10:26:42.014037Z","iopub.execute_input":"2025-12-03T10:26:42.014566Z","iopub.status.idle":"2025-12-03T10:26:50.035784Z","shell.execute_reply.started":"2025-12-03T10:26:42.014541Z","shell.execute_reply":"2025-12-03T10:26:50.034932Z"}},"outputs":[{"name":"stdout","text":"\n====================================================================================================\nCOMPLETE VISUALIZATION & EXPORT PIPELINE\n====================================================================================================\n\n\n----------------------------------------------------------------------------------------------------\nGRAPH 1: TRAINING LOSS CURVE - DISPLAY + SAVE PNG\n----------------------------------------------------------------------------------------------------\n\n✓ Saved PNG: /kaggle/working/01_training_loss_curve.png\n\n----------------------------------------------------------------------------------------------------\nGRAPH 2: CLASSIFIER ACCURACY COMPARISON - DISPLAY + SAVE PNG\n----------------------------------------------------------------------------------------------------\n\n✓ Saved PNG: /kaggle/working/02_classifier_accuracy.png\n\n----------------------------------------------------------------------------------------------------\nGRAPH 3: ALL METRICS COMPARISON (4-Subplot) - DISPLAY + SAVE PNG\n----------------------------------------------------------------------------------------------------\n\n✓ Saved PNG: /kaggle/working/03_all_metrics_comparison.png\n\n----------------------------------------------------------------------------------------------------\nGRAPH 4: CONFUSION MATRICES (3 Classifiers) - DISPLAY + SAVE PNG\n----------------------------------------------------------------------------------------------------\n\n✓ Saved PNG: /kaggle/working/04_confusion_matrices.png\n\n----------------------------------------------------------------------------------------------------\nGRAPH 5: PER-CLASS PERFORMANCE HEATMAP - DISPLAY + SAVE PNG\n----------------------------------------------------------------------------------------------------\n\n✓ Saved PNG: /kaggle/working/05_per_class_heatmap.png\n\n----------------------------------------------------------------------------------------------------\nGRAPH 6: COMBINED ANALYSIS (Loss + Ranking + Summary) - DISPLAY + SAVE PNG\n----------------------------------------------------------------------------------------------------\n\n✓ Saved PNG: /kaggle/working/06_combined_analysis.png\n\n====================================================================================================\nEXPORTING CSV FILES\n====================================================================================================\n\n✓ Saved CSV: classifier_comparison.csv\n\n  Classifier  Accuracy  Precision   Recall  F1-Score\nLinear Probe  0.288684   0.286236 0.286236  0.286236\n         MLP  0.358158   0.359819 0.359819  0.359819\n         SVM  0.107895   0.104425 0.104425  0.104425\n\n✓ Saved CSV: per_class_performance.csv\n\nRows: 38\n\n✓ Saved CSV: training_summary.csv\n\n                  Metric     Value\n            Total Images     19000\n       Number of Classes        38\n       Feature Dimension       384\n          Epochs Trained        10\n            Initial Loss  -43.0315\n              Final Loss -142.7732\n               Best Loss -143.6975\n  Training Samples (80%)     15200\nValidation Samples (20%)      3800\n         Best Classifier       MLP\n           Best Accuracy    0.3582\n\n✓ Saved CSV: training_loss_by_epoch.csv\nEpochs: 10\n\n====================================================================================================\nFINAL SUMMARY REPORT\n====================================================================================================\n\n📊 PRETRAINING SUMMARY:\n   • Model: Vision Transformer (DINO Self-Supervised)\n   • Epochs: 10\n   • Initial Loss: -43.0315\n   • Best Loss: -143.6975 (Epoch 3)\n   • Final Loss: -142.7732\n\n🎯 DATASET STATISTICS:\n   • Total Images: 19000\n   • Classes: 38\n   • Feature Dimension: 384\n   • Training Split: 15200 samples (80%)\n   • Validation Split: 3800 samples (20%)\n\n🏆 CLASSIFIER PERFORMANCE RANKING:\n\n   🥇 #1. MLP\n      ├─ Accuracy:  0.3582\n      ├─ Precision: 0.3598\n      ├─ Recall:    0.3598\n      └─ F1-Score:  0.3598\n\n   🥈 #2. LINEAR PROBE\n      ├─ Accuracy:  0.2887\n      ├─ Precision: 0.2862\n      ├─ Recall:    0.2862\n      └─ F1-Score:  0.2862\n\n   🥉 #3. SVM\n      ├─ Accuracy:  0.1079\n      ├─ Precision: 0.1044\n      ├─ Recall:    0.1044\n      └─ F1-Score:  0.1044\n\n📁 OUTPUT FILES GENERATED:\n   ✓ PNG Files (6):\n      - 01_training_loss_curve.png\n      - 02_classifier_accuracy.png\n      - 03_all_metrics_comparison.png\n      - 04_confusion_matrices.png\n      - 05_per_class_heatmap.png\n      - 06_combined_analysis.png\n   ✓ CSV Files (4):\n      - classifier_comparison.csv\n      - per_class_performance.csv\n      - training_summary.csv\n      - training_loss_by_epoch.csv\n\n====================================================================================================\n✅ COMPLETE PIPELINE EXECUTED SUCCESSFULLY\n====================================================================================================\n\n","output_type":"stream"}],"execution_count":40}]}